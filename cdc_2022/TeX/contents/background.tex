\section{Background}

This section provides a brief technical background on which the proposed
learning framework is based upon. 

\subsection{Passivity-Based Control}
\label{ssec:pbc}

Let $x \in \mathcal{X} \subset \mathbb{R}^{2n}$ denote the state of the robot.
%
The state $x$ is represented in terms of the generalized positions and momenta
$x = (q, p)$. 
%
With $M \succ 0$ denoting the symmetric, positive-definite mass matrix, the Hamiltonian
$H$ of the robot is expressed as 
%
\begin{equation}
    H(q,p) = \frac{1}{2} p^\top M^{-1}(q) p + V(q),
    \label{eq:system_hamiltonian}
\end{equation}
%
where $V(q)$ represents the potential energy. The system's equations of motion
can then be expressed as 
%
\begin{align}
    \begin{split}  
      \bmat{\dot{q} \\ \dot{p}} &= \bmat{0 & I_n \\ -I_n & 0}\bmat{\nabla_qH \\
      \nabla_pH} + \bmat{0 \\ G(q)}u, \\
      &\hspace{-0.15cm} y = G\textcolor{magenta}{(q)}^\top \dot{q},
    \end{split}
    \label{eq:hamiltonian_dynamics}
\end{align}
%
where $G(q) \in \mathbb{R}^{n \times m}$ is the input matrix, $I_n$ denotes the
$n \times n$ identity matrix, and $u \in \mathbb{R}^m$ is
the control input.
%
The system~\eqref{eq:hamiltonian_dynamics} is \textit{underactuated} if rank $G
= m < n$.



The main idea of passivity-based control (PBC)~\cite{van2000l2} is to design the
input $u$ with the objective of imposing a desired storage function $H_d:
\mathcal{X} \rightarrow \mathbb{R}$ on the closed-loop system, rendering it
passive and consequently stable.
%
% The standard formulation of PBC is to let the control action $u = \beta(x) + v$
% such that the closed-loop dynamics satisfies
%
In the standard formulation of PBC, the control comprises an
energy shaping term and a damping injection term:
%
\begin{equation}
  u = u_{es}(x) + u_{di}(x),
  \label{eq:ida-pbc_control}
\end{equation}
%
such that the closed loop dynamics satisfies
%
\[
  H_d(x(t)) - H_d(x(0)) = \int_0^t u_{di}^\top(\tau) y(\tau) \, \dd \tau - d^\star(x(t)),
\]
%
where $d^\star \geq 0$ is the desired damping dissipation. 
%
For mechanical systems, one solution to the PBC problem is of the form
%
\begin{align*}
  u_{es}(x) &= 
  % -\left( G^\top G  \right)^{-1} G^\top
  -G^{\dagger}
  \left( \nabla_q H_d - \nabla_q H \right), \\
  u_{di}(x) &= - K_{v} \, y,%\quad \mathbb{R}^{m \times m} \ni K_v \succ 0,
\end{align*}
%
where $G^\dagger = \left( G^\top G  \right)^{-1} G^\top$, and $K_v \succ 0$ is the
damping gain matrix. The choice for $H_d$ must satisfy
%
\[
  G^\bot \left( \nabla_q H_d - \nabla_q H \right) = 0,
\]
%
where $G^\perp G = 0$,
and $H_d$ has a minimum at the desired equilibrium $x^\star = (q^\star, 0)$. 
%
% The most straight-forward solution is to assign a
% quadratic potential energy such that the minimum is at $q^\star$, i.e., with $K_p \succ 0$,
% %
% \begin{equation}
%   H_d(q,p) = \frac{1}{2} p^\top M^{-1}(q) p + \frac{1}{2}(q - q^\star)^\top K_p (q - q^\star).
%   \label{eq:quadratic_potential}
% \end{equation}
% %
% There is, in general, an infinite number of choices for $H_d$ that achieves the
% objective of PBC. 
% %
% Control researchers have proposed several systematic methods to design a
% suitable $H_d$, leading to a variety of PBC techniques. 
% %
% Some extensions introduce additional algebraic structure to the system in order
% to improve performance and ease stability analysis for a family of dynamical
% systems.


% In the interconnection and damping assignment
% (IDA-PBC)~\cite{ortega2002stabilization}, the closed-loop dynamics to chosen to
% take on the port-controlled Hamiltonian (PCH) form:
% %
% \begin{equation}
%   \bmat{\dot{q} \\ \dot{p}}
%   =
% %   \bmat{J_d(q,p) - R_d(q,p)}
%   \bmat{0 & M^{-1}M_d \\ -M_dM^{-1} & J_2(q,p) - GK_vG^\top}
%   \bmat{\nabla_q H_d \\ \nabla_p H_d},
%   \label{eq:pch}
% \end{equation}
% %
% where $J_2 = -J_2^\top$. 
% % serves as free parameters to ease solving the required
% % PDEs~\eqref{eq:pde_main}, and $K_v \succ 0$ is the tunable gain for
% % damping injection.
% %
% The storage function $H_d$ is another Hamiltonian, which is quadratic in the
% system momenta:
% %
% \begin{equation}
%     H_d(q, p) = \frac{1}{2} p^\top M_d^{-1}(q) p + V_d(q),
%     \label{eq:desired_hamiltonian}
% \end{equation}
% %
% where $M_d(q) \succ 0$ is the closed-loop, positive definite mass matrix and
% $V_d: \mathbb{R}^n \to \mathbb{R} $ is the closed-loop potential energy function
% that satisfies
% %
% \begin{equation}
%   q^\star = \underset{q}{\textrm{argmin}} \; \; V_d(q).
%   \label{eq:argmin_Vd}
% \end{equation}
% %
% % The control law that achieves the objective of IDA-PBC comprises an
% % energy-shaping term and a damping injection term, i.e.
% % %
% % \begin{equation}
% %     u = u_{es}(q,p) + u_{di}(q,p).
% %     \label{eq:ida-pbc_control}
% % \end{equation}
% %
% The energy-shaping term of~\eqref{eq:ida-pbc_control} requires a solution to
% %
% \begin{equation}
%     Gu_{es} = \nabla_qH - M_dM^{-1} \nabla_qH_d + J_2M_d^{-1}p.
%     \label{eq:Gues}
% \end{equation}
% %
% If system is underactuated, $G$ is not invertible, and Equation~\eqref{eq:Gues}
% cannot be uniquely solved. This leads to the constraints that must be satisfied
% for any choice of $u_{es}$:
% %
% \begin{equation}
%   G^\perp \left\{ \nabla_qH - M_dM^{-1} \nabla_qH_d + J_2M_d^{-1}p \right\} = 0.
%   \label{eq:pde_main}
% \end{equation}
% %
% Equation~\eqref{eq:pde_main} is a set of nonlinear partial differential
% equations (PDE) parametrized by $M_d$, $V_d$, and $J_2$. 
% %
% The skew-symmetric matrix $J_2$ serves as free parameters to ease obtaining a
% solution to~\eqref{eq:pde_main}.
% %
% The success of the IDA-PBC approach hinges on the ability to solve this set of
% PDEs.
% %
% Once a solution is obtained, the energy shaping term of the control is
% %
% \begin{equation}
%   u_{es} = G^{\dagger} \left(\nabla_qH - M_dM^{-1} \nabla_qH_d + J_2M_d^{-1}p\right),
%   \label{eq:ues}
% \end{equation}
% %
% where $G^{\dagger} = \left(G^\top G\right)^{-1} G^\top$.
% %
% With $K_v \succ 0$ a user-selected gain matrix, the damping injection term is given as
% %
% \begin{equation}
%     u_{di} = -K_v G^\top \nabla_p H_d.
%     \label{eq:udi}
% \end{equation}

% \begin{prop}
%   The closed-loop Hamiltonian $H_d$ in IDA-PBC is, by construction, a Lyapunov
%   function for the closed-loop system. The time-derivative of $H_d$ is
%   \begin{align*}
%       \dot{H}_d 
%       &= \left( \nabla_{q} H_d \right)^\top \dot{q} + \left( \nabla_p H_d \right)^\top \dot{p} \\
%       &= -\left( \nabla_{p} H_d \right)^\top \left(J_2 - G K_v G^\top\right) \nabla_p H_d \\
%       &\leq -\lambda_{\textrm{min}} \{ K_v \} \abs{ \left( \nabla_p H_d \right)^\top G }^2 \leq 0,
%   \end{align*}
%   where the last inequality follows from $J_2 = -J_2^\top$ and $K_v \succ 0$.
%   Therefore, as long as $V_d$ is bounded from below and the
%   conditions~\eqref{eq:argmin_Vd} and~\eqref{eq:pde_main} are satisfied,
%   $(q^\star, 0)$ is a stable equilibrium of~\eqref{eq:pch}.
%   \label{prop:lyapunov}
% \end{prop}


Controllers designed using PBC techniques are based on a nominal
dynamical model~\eqref{eq:hamiltonian_dynamics}. 
%
For many applications, the uncertainties in system parameters are not
negligible. 
%
In this work, we attempt to improve the controller's robustness properties by
means of Bayesian inference, whose theory we briefly summarize in the following
subsection.


\subsection{Bayesian Inference}
\label{ssec:bays}

The objective of Bayesian learning is to generate a stochastic model that best
fits observed data. Let this stochastic model be represented by $m(x; \theta)$,
where $\theta$ is a multivariate random variable that parametrizes the model and
$x$ is the input. Given prior belief on the distribution of the parameters
$p(\theta)$, Bayesian learning finds a posterior distribution $p(\theta \mid
\mathbb{D})$ over $\theta$ that maximizes the likelihood of the model matching
the underlying source of the dataset~\cite{bishop2006pattern}. 


Bayesian learning provides various techniques to find the posterior distribution
over $\theta$, one of which is the Markov Chain Monte Carlo (MCMC) methods. MCMC
methods learn the exact posterior distribution by collecting samples of $\theta$
either through a random walk (e.g. Metropolis-Hastings) or by following the
gradient of the likelihood (e.g. Hamiltonian Monte Carlo). Unfortunately, MCMC
techniques have weak convergence properties for high-dimensional parameters.
Hence, we leverage variational inference (VI), a technique that approximates the
posterior $p(x \mid \theta)$ with the distribution $q(\theta;z)$ selected from
the conjugate family of the prior~\cite{cohen2016bayesian}.
%
% selects a specific form $q(\theta;z)$ for the posterior distribution and
% learns the distribution parameters $z$. 
%
This gradient-based method selects the distribution parameters $z$ of the
approximate posterior $q$ that maximize the evidence lower bound (\textsc{Elbo}),
$\mathcal{L}(x, z)$:
\begin{align}
  \begin{split}
  \mathcal{L}(x,z) &= \mathbb{E}_{\theta \sim q} \left[\log(p(x, \theta;z)) - \log(q(\theta;z)) \right], \\
  p(x, \theta;z) &= p(x \mid \theta;z)p(\theta),
  \end{split}
  \label{eq:elbo}
\end{align}
where $p(x \mid \theta;z)$ is the likelihood function. 

%
% The power of Bayesian learning lies in its
% ability to build a model and make predictions that integrate over
% uncertainties~\cite{tipping2003bayesian}. These predictions can be found by
% marginalizing the model over the posterior~\cite{jospin2020hands}.
% \begin{equation}
%   \hat{m} = \frac{1}{N} \sum_{\theta \sim q} m(x, \theta),
%   \label{eqn:marginalization}
% \end{equation} 
% where $N$ is the number of samples drawn from the posterior. 
%
% Moreover, Bayesian frameworks can quantify how confident we are in the model
% predictions through the variance of the predictive distribution, $p(m \mid x,
% \mathbb{D})$. 
%
% The variance of $p(m|x, \mathbb{D})$ is given
% by~\cite{jospin2020hands}
% \begin{equation}
%   \Sigma_{m \mid x,\mathbb{D}} = \frac{1}{N-1} \sum_{\theta \sim q} \vectornorm{m(x,\theta) - \frac{1}{N} \sum_{\theta \sim q} m(x, \theta)}^2.
%   \label{eqn:predictive_variance}
% \end{equation}
%

% Unlike deterministic models, whose parameters are given by point estimates,
% Bayesian learning can characterize the uncertainties in the prediction.

% %
% Deterministic model are parameterized by point estimates. Their predictions find
% an average estimate over the noisy dataset. On the other hand, Bayesian learning
% provided models that make stochastic predictions that reflect the uncertainties
% in the dataset. 


% The power of Bayesian learning lies in its ability to build a model and make
% predictions that integrate over uncertainties~\cite{tipping2003bayesian}. These
% predictions can be found by marginalizing the model over the
% posterior~\cite{jospin2020hands}.

%
Bayesian learning techniques can be made more powerful when combined with the
expressive power of Bayesian neural networks (BNN), whose weights and biases are
samples drawn from a posterior distribution~\cite{jospin2020hands}. The BNN
architecture comes with many advantages; unlike deterministic neural networks,
it can provide a model and characterize the uncertainty of predictions with a
small amount of data. The use of prior distribution also behaves like a
regularization term that prevents the model from overfitting to the training
data~\cite{tipping2003bayesian}. On the flip side, it is more complicated and
computationally expensive to learn probability distributions than point
estimates.

