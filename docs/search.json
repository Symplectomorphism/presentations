[
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "main",
    "section": "",
    "text": "Title: Data-Driven Passivity Based Control of Robotic Locomotion and Manipulation\nAbstract: The recent boom and success of machine learning methods has encouraged efforts in synthesizing controllers that leverage neural networks as function approximators. However, when such controllers are synthesized it is important to take precautions against their potential vulnerabilities against disturbances arising from model uncertainties or measurement noise. In this work we address the automatic robust data-driven controller synthesis problem for robotic manipulation and locomotion. We demonstrate the efficacy of our theoretical results in simulation and real-world experiments on a rimless-wheel and a cart-pole system that contains walls. Our approach performs repeated interactions with a nominal dynamical model to infer a contact-aware passivity-based controller, whose storage function is given by a fully-connected neural network. Contacts, impacts and Coulomb friction are modeled through the linear complementarity problem (LCP), and solved via Lemkeâ€™s algorithm, which allows us to take pertinent gradients for the data-driven technique. Additionally, we improve the robustness properties of the controller under model uncertainties, such as the rimless wheel traversing on uneven terrain, via Bayesian learning.\nBio: Aykut Satici holds a BSc and MSc of Mechatronics Engineering from Sabanci University in Turkey, an MSc of Mathematics, and Ph.D.Â in Electrical Engineering from the University of Texas at Dallas under Prof.Â Mark W. Spong. He worked as a postdoctoral associate at University of Naples, Federico II and at Massachusetts Institute of Technology. Dr.Â Satici is currently an assistant professor of Mechanical and Biomedical Engineering at Boise State University. He has actively contributed to the control, estimation, and robotics research communities for more than 15 years. His research output includes the optimal design of robotic manipulators, optimal control of uncrewed aerial vehicles, multi-agent robot control and estimation, differential geometric methods in nonlinear control, passivity-based control, and control synthesis with machine learning methods."
  },
  {
    "objectID": "main.html#data-driven-passivity-based-control",
    "href": "main.html#data-driven-passivity-based-control",
    "title": "main",
    "section": "Data-Driven Passivity-Based Control",
    "text": "Data-Driven Passivity-Based Control\n\n\nUniversity of Texas at Dallas Seminar\n\n\n\n\nPresenter: Aykut Satici, Ph.D.Â  Mechanical and Biomedical Engineering Department  Boise State University, Boise, Idaho, USA\n\n\nGraduate Students:  Wankun Sirichotiyakul ğŸ“  Nardos Ayele Ashenafi ğŸ“"
  },
  {
    "objectID": "main.html#peer-reviewed-contributions",
    "href": "main.html#peer-reviewed-contributions",
    "title": "main",
    "section": "Peer-Reviewed Contributions",
    "text": "Peer-Reviewed Contributions\n\n\n\nNeuralPbc\n\n\nISER 2020\n\n\nCCTA 2021\n\n\nACC 2022\n\n\nL-CSS 20221\n\n\n\nNeuralIdaPbc\n\n\nIJC 2021\n\n\nTACON 20221\n\n\n\n\n\n\nISER - International Symposium on Experimental Robotics\nCCTA - Conference on Control Technology and Applications\nACC - American Control Conference\nLCSS - Control Systems Letters\nIJC - International Journal of Control\nTACON - Transactions on Automatic Control\n\n\nUnder review"
  },
  {
    "objectID": "main.html#what-is-underactuation",
    "href": "main.html#what-is-underactuation",
    "title": "main",
    "section": "What is Underactuation?",
    "text": "What is Underactuation?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUnderactuation\n\n\n\nNo control input can generate acceleration in arbitrary direction\nControl problem becomes much more complicated"
  },
  {
    "objectID": "main.html#underactuated-robots",
    "href": "main.html#underactuated-robots",
    "title": "main",
    "section": "Underactuated Robots",
    "text": "Underactuated Robots\n\n\n\n\n\n\n\n\nWalking machines\n\n\n\n\nÂ \n\n\n\n\n\nFlying machines\n\n\n\n\n\n\n\n\n\n\n\nTorque-limited manipulators\n\n\n\n\nÂ \n\n\n\n\n\nNonprehensile manipulation"
  },
  {
    "objectID": "main.html#existing-methods",
    "href": "main.html#existing-methods",
    "title": "main",
    "section": "Existing Methods",
    "text": "Existing Methods\n\n\n\n\n\n\n\n\nÂ \n\n\n\nStrengths\n\nStability guarantees\nClosed-form policy\n\nWeaknesses\n\nModel uncertainties\nNeed to solve PDEs\n\n\n\n\n\n\n\n\n\n\nReinforcement learning \n\n\nÂ \n\n\n\nStrengths\n\nMore general\nUnknown dynamics OK\n\nWeaknesses\n\nSample complexity\nStability guarantees?"
  },
  {
    "objectID": "main.html#our-methods",
    "href": "main.html#our-methods",
    "title": "main",
    "section": "Our Methods",
    "text": "Our Methods\n\n\n\n\n\n\n\nÂ \n\n\nÂ \n\n\n\n\n\n\n\n\n\n\nÂ \n\n\n\nSystematic approach\nPrior domain knowledge\nStability is intrinsic\nModel uncertainty considerations possible"
  },
  {
    "objectID": "main.html#robustness-via-bayesian-learning",
    "href": "main.html#robustness-via-bayesian-learning",
    "title": "main",
    "section": "Robustness via Bayesian Learning",
    "text": "Robustness via Bayesian Learning\n\n\n\n\n\n\nSystem Parameter Uncertainty and Measurement Noise\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLess robust\n\n\n\n\n\n\n\n\n\n\n\nMore robust"
  },
  {
    "objectID": "main.html#dissipativity",
    "href": "main.html#dissipativity",
    "title": "main",
    "section": "Dissipativity",
    "text": "Dissipativity\n\nA dynamical system\nÎ£:{xÌ‡=f(x,u)y=h(x,u)xâˆˆğ’³âŠ‚â„2n,uâˆˆğ’°âŠ‚â„m\n\\Sigma: \\quad\n\\begin{cases}\n  \\dot{x} &= f(x,u) \\\\\n  y &= h(x,u)\n\\end{cases}\n\\quad x \\in \\mathcal{X} \\subset \\mathbb{R}^{2n}, \\, u \\in \\mathcal{U} \\subset \\mathbb{R}^{m} \n\nis dissipative with respect to some supply rate ss if there exists a storage function â„‹:ğ’³â†’â„+\\mathcal{H}: \\mathcal{X} \\to \\mathbb{R}^{+} such that\nâ„‹(x(t1))â‰¤â„‹(x(t0))+âˆ«t0t1s(u(t),y(t))dt\n\\mathcal{H}\\left(  x(t_1) \\right) \\leq  \\mathcal{H}\\left(  x(t_0) \\right) + \\int_{t_0}^{t_1} s(u(t), y(t)) \\, \\text{d}t\n\nfor all x(t0)=x0x(t_0) = x_0, all input uu, and all t1â‰¥t0t_1 \\geq t_0"
  },
  {
    "objectID": "main.html#dissipativity-1",
    "href": "main.html#dissipativity-1",
    "title": "main",
    "section": "Dissipativity",
    "text": "Dissipativity\nâ„‹(x(t1))â‰¤â„‹(x(t0))+âˆ«t0t1s(u(t),y(t))dt\n\\mathcal{H}\\left(  x(t_1) \\right) \\leq  \\mathcal{H}\\left(  x(t_0) \\right) + \\int_{t_0}^{t_1} s(u(t), y(t)) \\, \\text{d}t\n\n\n\n\nDissipation Inequality\n\n\n\n\nStored energy at t1t_1 is at most equal to stored energy at t0t_0, plus externally supplied energy s(u,y)s(u,y)\nNo generation of energy, only internal dissipation\nWith s(t)â‰¡0s(t) \\equiv 0, trajectories tend towards minimum of â„‹\\mathcal{H}"
  },
  {
    "objectID": "main.html#passivity",
    "href": "main.html#passivity",
    "title": "main",
    "section": "Passivity",
    "text": "Passivity\n\nThe system Î£\\Sigma is passive if it is dissipative with supply rate\ns=uâŠ¤y.s = u^\\top y.\nIt is output strictly passive if it is dissipative with supply rate\ns=uâŠ¤yâˆ’Î´âˆ¥yâˆ¥2,Î´&gt;0.s = u^\\top y - \\delta \\lVert y \\rVert^2, \\; \\delta &gt; 0.\nIt is input strictly passive if it is dissipative with supply rate\ns=uâŠ¤yâˆ’Î´âˆ¥uâˆ¥2,Î´&gt;0.s = u^\\top y - \\delta \\lVert u \\rVert^2, \\; \\delta &gt; 0."
  },
  {
    "objectID": "main.html#passive-system-example",
    "href": "main.html#passive-system-example",
    "title": "main",
    "section": "Passive System Example",
    "text": "Passive System Example\n\n\n\n\n\nKirchoffâ€™s law\nv=Ri+1Câˆ«0ti(Ï„)dÏ„+Ldidtviâˆ’Ri2=ddt(12C(âˆ«0ti(Ï„)dÏ„)2âŸğ’±+12Li2âŸğ’¯)\n\\begin{aligned}\nv &= Ri + \\frac{1}{C} \\int_{0}^{t} i(\\tau) \\, \\text{d}\\tau + L \\frac{\\text{d} i}{\\text{d} t} \\\\\nvi - Ri^2 &= \\frac{\\text{d}}{\\text{d} t} \\left( \n  \\underbrace{\\frac{1}{2C} \\left( \\int_{0}^{t} i(\\tau)\\, \\text{d} \\tau \\right)^2}_{\\mathcal{V}} + \n  \\underbrace{\\frac{1}{2} Li^2}_{\\mathcal{T}}  \n\\right)\n\\end{aligned}\n\n\n\nLet â„‹=ğ’±+ğ’¯\\mathcal{H} = \\mathcal{V} + \\mathcal{T}, integrate to obtain\nâ„‹(t)âŸavailableâˆ’â„‹(0)âŸinitial=âˆ«0tv(Ï„)i(Ï„)dÏ„âŸsuppliedâˆ’âˆ«0tRi2(Ï„)dÏ„âŸdissipated&lt;âˆ«0tv(Ï„)i(Ï„)dÏ„\n\\underbrace{\\mathcal{H}(t)}_{\\textrm{available}} -\n\\underbrace{\\mathcal{H}(0)}_{\\textrm{initial}} \n= \n\\underbrace{\\int_{0}^{t} v(\\tau)i(\\tau)\\, \\text{d} \\tau}_{\\textrm{supplied}} - \n\\underbrace{\\int_{0}^{t} Ri^2(\\tau)\\, \\text{d} \\tau}_{\\textrm{dissipated}}\n&lt;\n\\int_{0}^{t} v(\\tau) i(\\tau) \\, \\text{d} \\tau"
  },
  {
    "objectID": "main.html#stability-of-passive-systems",
    "href": "main.html#stability-of-passive-systems",
    "title": "main",
    "section": "Stability of Passive Systems",
    "text": "Stability of Passive Systems\n\nÎ£:{xÌ‡=f(x,u),f(0,0)=0,y=h(x,u),h(0,0)=0,\n\\Sigma: \\quad\n\\begin{cases}\n  \\dot{x} &= f(x,u), && f(0,0) = 0, \\\\\n  y &= h(x,u), && h(0,0) = 0,\n\\end{cases}\n\nuâŠ¤yâ‰¥â„‹Ì‡=âˆ‚â„‹âˆ‚xf(x,u),â„‹â‰¥0,yâ‰¡0âŸ¹xâ‰¡0u^{\\top} y \\geq \\dot{\\mathcal{H}} = \\frac{\\partial\\mathcal{H}}{\\partial x} f(x,u),\\quad \\mathcal{H} \\geq 0,\\quad y \\equiv 0 \\implies x \\equiv 0\n\n\n\nLemma (Khalil, 2002)\n\n\nThe origin of Î£\\Sigma is:\n\nstable if Î£\\Sigma is passive,\nasymptotically stable if Î£\\Sigma is output strictly passive,\nglobally asymptotically stable if Î£\\Sigma is output strictly passive and the storage function â„‹(x)â†’âˆ\\mathcal{H}(x) \\to \\infty as âˆ¥xâˆ¥â†’âˆ\\lVert x \\rVert \\to \\infty (radially unbounded)\n\n\n\n\n\n\nNotice that we only require that the function â„‹\\mathcal{H} be positive semidefinite and not necessarily positive definite as per usual Lyapunov conditions.\nObservability (detectability) ensures LaSalleâ€™s theorem works."
  },
  {
    "objectID": "main.html#passivity-based-control-pbc",
    "href": "main.html#passivity-based-control-pbc",
    "title": "main",
    "section": "Passivity-Based Control (PBC)",
    "text": "Passivity-Based Control (PBC)\n\nÎ£o:{xÌ‡=f(x)+g(x)u,y=h(x)\n\\Sigma_o: \\quad\n\\begin{cases}\n  \\dot{x} &= f(x) + g(x)u, \\\\\n  y &= h(x)\n\\end{cases}\n\nMain idea â€” Select u(x)=ues+udiu(x) = u_{es} + u_{di} that renders the closed-loop system passive.\nÎ£d:{xÌ‡=fd(x)+g(x)udi,fd:=f(x)+g(x)ues(x)yd=hd(x)\n\\Sigma_d: \\quad\n\\begin{cases}\n  \\dot{x} &= f_d(x) + g(x) u_{di}, \\quad f_d := f(x) + g(x) u_{es}(x) \\\\\n  y_d &= h_d(x)\n\\end{cases}\n\nControl problem is cast as a search for HdH_d and hdh_d s.t. HÌ‡dâ‰¤ydâŠ¤udi\\dot{H}_d \\leq y_d^\\top u_{di}"
  },
  {
    "objectID": "main.html#pbc-example---simple-pendulum",
    "href": "main.html#pbc-example---simple-pendulum",
    "title": "main",
    "section": "PBC Example - Simple Pendulum",
    "text": "PBC Example - Simple Pendulum\n\n\n\n\nSystem Dynamics\n\n\nH(q,p)=12Jâˆ’1p2+mgl(1âˆ’cosq)H(q,p) = \\frac{1}{2} J^{-1} p^2 + mgl (1 - \\cos q)\n[qÌ‡pÌ‡]=[âˆ’01âˆ’10][âˆ‡qHdâˆ‡pHd]+[0G]udi,y=qÌ‡\n\\begin{bmatrix} \\dot{q} \\\\ \\dot{p} \\end{bmatrix} = \n\\begin{bmatrix} \\phantom{-}0 & 1 \\\\ -1 & 0 \\end{bmatrix} \n\\begin{bmatrix} \\nabla_q H_{\\phantom{d}} \\\\ \\nabla_p H_{\\phantom{d}} \\end{bmatrix} +\n\\begin{bmatrix} 0 \\\\ G \\end{bmatrix} u_\\phantom{di},\n\\qquad y = \\dot{q}\n\n\nChoose u=ues+udiu = u_{es} + u_{di} that transforms system into a passive one with xâ‹†=(qâ‹†,0)x^\\star = (q^\\star, 0) \n\n\nGues=âˆ‡qHâˆ’âˆ‡qHd,Gudi=âˆ’GKDGâŠ¤âˆ‡pHdGu_{es} = \\nabla_q H - \\nabla_q H_d , \\quad Gu_{di} = -GK_D G^\\top \\nabla_p H_d\n\n\n\n[qÌ‡pÌ‡]=[âˆ’01âˆ’10][âˆ‡qHdâˆ‡pHd]+[0G]udi,y=qÌ‡\n\\begin{bmatrix} \\dot{q} \\\\ \\dot{p} \\end{bmatrix} = \n\\begin{bmatrix} \\phantom{-}0 & 1 \\\\ -1 & 0 \\end{bmatrix} \n\\begin{bmatrix} \\nabla_q H_d \\\\ \\nabla_p H_d \\end{bmatrix} +\n\\begin{bmatrix} 0 \\\\ G \\end{bmatrix} u_{di},\n\\qquad y = \\dot{q}\n\n\n\n[qÌ‡pÌ‡]=[âˆ’01âˆ’1âˆ’GKDGâŠ¤][âˆ‡qHdâˆ‡pHd],y=qÌ‡\n\\begin{bmatrix} \\dot{q} \\\\ \\dot{p} \\end{bmatrix} = \n\\begin{bmatrix} \\phantom{-}0 & 1 \\\\ -1 & -G K_D G^\\top \\end{bmatrix} \n\\begin{bmatrix} \\nabla_q H_d \\\\ \\nabla_p H_d \\end{bmatrix},\n\\qquad y = \\dot{q}"
  },
  {
    "objectID": "main.html#pbc-example---simple-pendulum-1",
    "href": "main.html#pbc-example---simple-pendulum-1",
    "title": "main",
    "section": "PBC Example - Simple Pendulum",
    "text": "PBC Example - Simple Pendulum\n\n\n\n\nControl Synthesis via PBC\n\n\nChoose u=ues+udiu = u_{es} + u_{di} that transforms system into a passive one with xâ‹†=(qâ‹†,0)x^\\star = (q^\\star, 0)\nGues=âˆ‡qHâˆ’âˆ‡qHd,Gudi=âˆ’GKDGâŠ¤âˆ‡pHdGu_{es} = \\nabla_q H - \\nabla_q H_d , \\quad Gu_{di} = -GK_D G^\\top \\nabla_p H_d\n[qÌ‡pÌ‡]=[âˆ’01âˆ’1âˆ’GKDGâŠ¤][âˆ‡qHdâˆ‡pHd],y=qÌ‡\n\\begin{bmatrix} \\dot{q} \\\\ \\dot{p} \\end{bmatrix} = \n\\begin{bmatrix} \\phantom{-}0 & 1 \\\\ -1 & -G K_D G^\\top \\end{bmatrix} \n\\begin{bmatrix} \\nabla_q H_d \\\\ \\nabla_p H_d \\end{bmatrix},\n\\qquad y = \\dot{q}\n\n\nHd(q,p)=12Jâˆ’1p2+Vd(q),Vd(q)=12KP(qâˆ’qâ‹†)2H_d(q,p) = \\frac{1}{2} J^{-1} p^2 + V_d(q), \\quad V_d(q) = \\frac{1}{2} K_{P} \\left( q - q^\\star \\right)^2\n\n\n\nHÌ‡d=âˆ’KD(Jâˆ’1p)2=yâŠ¤udiâ‰¤0\\dot{H}_d = -K_D \\left( J^{-1} p \\right)^2 = y^\\top u_{di} \\leq 0\n\n\nu=âˆ’mglsin(x)âˆ’KP(qâˆ’qâ‹†)âˆ’KDqÌ‡\\boxed{u = -mgl\\sin(x) - K_P(q - q^\\star) - K_D \\dot{q}}"
  },
  {
    "objectID": "main.html#our-methods-1",
    "href": "main.html#our-methods-1",
    "title": "main",
    "section": "Our Methods",
    "text": "Our Methods\n\n\n\n\nÂ \n\n\n\n\n\nÂ \n\n\n\n\n\n\n\n\n\n\n\n\nNeuralPbc\nNeuralIdaPbc\n\n\n\n\nHdH_d neural net\nHdH_d quadratic in pp\n\n\nSample state space\nSample configuration space\n\n\nNo stability certificate\nStability certificate\n\n\nMore flexible\nAs applicable as IdaPbc"
  },
  {
    "objectID": "main.html#bayesian-learning",
    "href": "main.html#bayesian-learning",
    "title": "main",
    "section": "Bayesian Learning",
    "text": "Bayesian Learning\n\np(Î¸âˆ£ğ’Ÿ)=p(ğ’Ÿâˆ£Î¸)âlikelihoodp(Î¸)âpriorâˆ«Î¸p(ğ’Ÿâˆ£Î¸â€²)p(Î¸â€²)dÎ¸â€²âŸevidenceâ‰ˆq(Î¸;z)âŸVI.\np(\\theta \\mid \\mathcal{D}) = \\frac{\\overbrace{p(\\mathcal{D} \\mid\n\\theta)}^{\\text{likelihood}}\\overbrace{p(\\theta)}^{\\text{prior}}}\n{\\underbrace{\\int_\\theta p(\\mathcal{D} \\mid \\theta^\\prime)p(\\theta^\\prime)\nd\\theta^\\prime}_{\\text{evidence}}} \\underbrace{\\approx q(\\theta;\nz)}_{\\text{VI}}.\n\n\n\n\n\n\n\n\nShow ELBO convergence.\n\n\n\n\n\n\n\nKL-divergence and ELBO\n\n\nDKL=ğ”¼Î¸âˆ¼q[logq(Î¸;z)p(Î¸âˆ£ğ’Ÿ)]=logp(ğ’Ÿ)âˆ’ğ”¼Î¸âˆ¼q[logp(ğ’Ÿâˆ£Î¸)p(Î¸)q(Î¸;z)]â„’(ğ’Ÿ;z)=ğ”¼Î¸âˆ¼q[logp(ğ’Ÿâˆ£Î¸)p(Î¸)âˆ’logq(Î¸;z)]\n\\begin{aligned}\nD_{\\text{KL}} &= \\mathbb{E}_{\\theta \\sim q}\\left[ \\log \\frac{q(\\theta;\nz)}{p(\\theta \\mid \\mathcal{D})}\\right] \\\\\n&= \\log p(\\mathcal{D}) - \\mathbb{E}_{\\theta \\sim q}\\left[ \\log\n\\frac{p(\\mathcal{D} \\mid \\theta) p(\\theta)}{q(\\theta; z)} \\right] \\\\\n\\mathcal{L}(\\mathcal{D}; z) &= \\mathbb{E}_{\\theta \\sim q}\\left[ \\log\np(\\mathcal{D} \\mid \\theta) p(\\theta) - \\log q(\\theta; z) \\right]\n\\end{aligned}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow prob. distribution\n\n\n\n\n\n\n\nPrediction through marginalization\n\n\nmÌ‚=1Nâˆ‘Î¸âˆ¼qm(x,Î¸).\n\\begin{aligned}\n\\hat{m} &= \\frac{1}{N}\\sum_{\\theta \\sim q} m(x, \\theta).\n\\end{aligned}"
  },
  {
    "objectID": "main.html#system-parameter-uncertainty",
    "href": "main.html#system-parameter-uncertainty",
    "title": "main",
    "section": "System Parameter Uncertainty",
    "text": "System Parameter Uncertainty\n\n\n\nScalar control system\nUncertain drift vector field: pâˆ¼ğ’©(pÌ‚,Ïƒp2)p \\sim \\mathcal{N}(\\hat{p}, \\sigma_p^2).\nNo measurement uncertainty\n\n\n\n\n\n\nÎ£:{xÌ‡=px+u,u(x)=Î¸x,x(0)=1.\n\\Sigma: \\quad\n\\begin{cases}\n  \\dot{x} &= px + u, \\\\\n  u(x) &= \\theta x, \\\\\n  x(0) &= 1.\n\\end{cases}\n x(t)=e(p+Î¸)t.\n  x(t) = e^{(p+\\theta)t}."
  },
  {
    "objectID": "main.html#performance-index",
    "href": "main.html#performance-index",
    "title": "main",
    "section": "Performance Index",
    "text": "Performance Index\n\n\n\n\n\nÎ£:{xÌ‡=px+u,u(x)=Î¸x,x(0)=1.\n\\Sigma: \\quad\n\\begin{cases}\n  \\dot{x} &= px + u, \\\\\n  u(x) &= \\theta x, \\\\\n  x(0) &= 1.\n\\end{cases}\n x(t)=e(p+Î¸)t.\n  x(t) = e^{(p+\\theta)t}.\n\n\n\nÂ \n\n\n\n\n\nQuadratic performance index\n\nqâ‰¥0q \\geq 0, r&gt;0r &gt; 0\n\nTT: control horizon\n\n\n\nğ’¥=âˆ«0T(12qx(t)2+12ru(t)2)dt.\n\\mathcal{J} = \\int_0^T \\left( \\frac{1}{2}qx(t)^2 + \\frac{1}{2}ru(t)^2  \\right)dt."
  },
  {
    "objectID": "main.html#infinite-horizon-best-performance",
    "href": "main.html#infinite-horizon-best-performance",
    "title": "main",
    "section": "Infinite-Horizon Best Performance",
    "text": "Infinite-Horizon Best Performance\n\n\n\n\nğ’¥=âˆ«0T(12qx(t)2+12ru(t)2)dt.\n\\mathcal{J} = \\int_0^T \\left( \\frac{1}{2}qx(t)^2 + \\frac{1}{2}ru(t)^2  \\right)dt.\n ğ’¥Tâ†’âˆ=âˆ’14q+rÎ¸2p+Î¸.\n\\mathcal{J}_{T \\to \\infty} = -\\frac{1}{4}\\frac{q+r \\theta^2}{p+\\theta}.\n\n\n\nÂ \n\n\n\n\nSolve for Î¸\\theta that minimizes ğ’¥âˆ\\mathcal{J}_\\infty: Î¸â‹†=g(p):=âˆ’pâˆ’p2+qr\\theta^\\star = g(p) := -p -\\sqrt{p^2+\\frac{q}{r}}.\n\n\n\n\n\n\n\nDeterministic\n\n\nÎ¸â‹†=g(pÌ‚):=âˆ’pÌ‚âˆ’pÌ‚2+qr\\theta^\\star = g(\\hat{p}) := -\\hat{p} -\\sqrt{\\hat{p}^2+\\frac{q}{r}}\n\n\n\n\n\nÂ \n\n\n\n\n\nProbabilistic\n\n\nfÎ¸â‹†(Î¸â‹†)=1Ïƒp2Ï€(12(1+qrÎ¸â‹†2))exp{âˆ’12Ïƒp2(q2rÎ¸â‹†âˆ’Î¸â‹†2âˆ’pÌ‚)2}\n\\begin{aligned}\nf_{\\theta^\\star}(\\theta^\\star) &= \\frac{1}{\\sigma_p \\sqrt{2\\pi}}\\left( \\\n\\frac{1}{2}\\left(1+\\frac{q}{r{\\theta^\\star}^2}\\right) \\right) \\\\\n&\\exp{\\left\\{ -\\frac{1}{2\\sigma_p^2}\\left( \\frac{q}{2r\\theta^\\star} -\n\\frac{\\theta^\\star}{2} - \\hat{p}  \\right)^2  \\right\\} }\n\\end{aligned}"
  },
  {
    "objectID": "main.html#infinite-horizon-best-performance-1",
    "href": "main.html#infinite-horizon-best-performance-1",
    "title": "main",
    "section": "Infinite-Horizon Best Performance",
    "text": "Infinite-Horizon Best Performance\n\n\n\n\n\n\n\nDeterministic\n\n\nÎ¸â‹†=g(pÌ‚):=âˆ’pÌ‚âˆ’pÌ‚2+qr\\theta^\\star = g(\\hat{p}) := -\\hat{p} -\\sqrt{\\hat{p}^2+\\frac{q}{r}}\n\n\n\n\n\nÂ \n\n\n\n\n\nProbabilistic\n\n\nfÎ¸â‹†(Î¸â‹†)=1Ïƒp2Ï€(12(1+qrÎ¸â‹†2))exp{âˆ’12Ïƒp2(q2rÎ¸â‹†âˆ’Î¸â‹†2âˆ’pÌ‚)2}\n\\begin{aligned}\nf_{\\theta^\\star}(\\theta^\\star) &= \\frac{1}{\\sigma_p \\sqrt{2\\pi}}\\left( \\\n\\frac{1}{2}\\left(1+\\frac{q}{r{\\theta^\\star}^2}\\right) \\right) \\\\\n&\\exp{\\left\\{ -\\frac{1}{2\\sigma_p^2}\\left( \\frac{q}{2r\\theta^\\star} -\n\\frac{\\theta^\\star}{2} - \\hat{p}  \\right)^2  \\right\\} }\n\\end{aligned}"
  },
  {
    "objectID": "main.html#conditional-expectation",
    "href": "main.html#conditional-expectation",
    "title": "main",
    "section": "Conditional Expectation",
    "text": "Conditional Expectation\n\n\nğ”¼[ğ’¥âˆ£p]=âˆ’14q+rÎ¸2p+Î¸[Î¸2Ïƒ2T+(1âˆ’e2T(p+Î¸))(1+12Î¸2Ïƒ2p+Î¸)]\n\\mathbb{E}[\\mathcal{J} \\mid p] =\n-\\frac{1}{4}\\frac{q+r\\theta^2}{p+\\theta}\\left[ \\theta^2 \\sigma^2 T +\n\\left(1-e^{2 T (p+\\theta)}\\right) \\left(1+\\frac{1}{2}\\frac{\\theta^2\n\\sigma^2}{p+\\theta}\\right) \\right]\n\n\n\n\n\n\nProof\n\n\nSubstituting the solution of the SDE into the performance measure yields\nğ’¥=âˆ’14q+rÎ¸2p+Î¸(1+e2T(p+Î¸))+(q+rÎ¸2)Î¸Ïƒâˆ«0Te(p+Î¸)tâˆ«0te(p+Î¸)(tâˆ’s)dWsdt+12(q+rÎ¸2)Î¸2Ïƒ2âˆ«0T(âˆ«0te(p+Î¸)(tâˆ’s)dWs)2dt\n\\begin{aligned} \\mathcal{J} =\n        & -\\frac{1}{4}\\frac{q+r\\theta^2}{p+\\theta}\\left(1 +\n        e^{2T(p+\\theta)}\\right) + \n        (q+r\\theta^2)\\theta\\sigma \\int_0^T\n        e^{(p+\\theta)t} \\int_0^t e^{(p+\\theta)(t-s)}dW_s\n        dt \\; + \\\\ &\\frac{1}{2}(q+r\\theta^2)\\theta^2\n        \\sigma^2 \\int_0^T \\left( \\int_0^t\n        e^{(p+\\theta)(t-s)} dW_s  \\right)^2 dt \n\\end{aligned}\n\nThe conditional expectation of this quantity given the system parameter pp under the distribution induced by the Wiener process may be computed in closed-form using Ito calculus.\nğ”¼W[ğ’¥âˆ£p]=âˆ’14q+rÎ¸2p+Î¸(1âˆ’e2T(p+Î¸))+(q+rÎ¸2)Î¸Ïƒâˆ«0Te(p+Î¸)tğ”¼W[âˆ«0te(p+Î¸)(tâˆ’s)dWs|p]dt+12(q+rÎ¸)2Î¸2Ïƒ2âˆ«0Tğ”¼W[(âˆ«0te(p+Î¸)(tâˆ’s)dWs)2|p]dt=âˆ’14q+rÎ¸2p+Î¸(1âˆ’e2T(p+Î¸))+12(q+rÎ¸2)Î¸2Ïƒ2âˆ«0T(âˆ«0te2(p+Î¸)(tâˆ’s)ds)dt=âˆ’14q+rÎ¸2p+Î¸(1âˆ’e2T(p+Î¸))+12(q+rÎ¸2)Î¸2Ïƒ2âˆ«0Tâˆ’12(p+Î¸)(1âˆ’e2T(p+Î¸))dt=âˆ’14q+rÎ¸2p+Î¸[Î¸2Ïƒ2T+(1âˆ’e2T(p+Î¸))(1+12Î¸2Ïƒ2p+Î¸)].\n\\begin{aligned} \n\\mathbb{E}_W\\left[\\mathcal{J} \\mid p \\right] &= -\\frac{1}{4}\\frac{q+r\\theta^2}{p+\\theta}\\left(1 - e^{2T(p+\\theta)}\\right) +\n        (q+r\\theta^2)\\theta\\sigma\\int_0^Te^{(p+\\theta)t}\\mathbb{E}_W\\left[\\int_0^t\n        e^{(p+\\theta)(t-s)} dW_s~\\Big\\rvert p\\right] dt + \\\\\n        &\\frac{1}{2}(q+r\\theta)^2\\theta^2\\sigma^2\\int_0^T\\mathbb{E}_W\\left[\\left(\\int_0^t\n        e^{(p+\\theta)(t-s)} dW_s \\right)^2~\\bigg\\rvert p\\right] dt \\\\\n        &=-\\frac{1}{4}\\frac{q+r\\theta^2}{p+\\theta}\\left(1 -\n        e^{2T(p+\\theta)}\\right) + \n        \\frac{1}{2}(q+r\\theta^2)\\theta^2\\sigma^2\\int_0^T\\left(\\int_0^t\n        e^{2(p+\\theta)(t-s)} ds \\right) dt \\\\ \n        &=-\\frac{1}{4}\\frac{q+r\\theta^2}{p+\\theta}\\left(1 - e^{2T(p+\\theta)}\\right) + \n        \\frac{1}{2}(q+r\\theta^2)\\theta^2\\sigma^2\\int_0^T\n        -\\frac{1}{2(p+\\theta)}\\left(1 - e^{2T(p+\\theta)}\\right) dt \\\\ \n        &=-\\frac{1}{4}\\frac{q+r\\theta^2}{p+\\theta} \\left[ \\theta^2 \\sigma^2 T +\n        \\left(1 - e^{2T(p+\\theta)}\\right) \\left(1 +\n        \\frac{1}{2}\\frac{\\theta^2\\sigma^2}{p+\\theta}\\right)\\right]. \n\\end{aligned}\n\n\nğŸŸ§"
  },
  {
    "objectID": "main.html#optimal-controller",
    "href": "main.html#optimal-controller",
    "title": "main",
    "section": "Optimal Controller",
    "text": "Optimal Controller\n\n\n\n\nOptimal controller |Î¸â‹†||\\theta^\\star| minimizing ğ”¼ğ’¥\\mathbb{E}\\mathcal{J}\n\n\n\nMinimal expected cost ğ”¼ğ’¥\\mathbb{E}\\mathcal{J}"
  },
  {
    "objectID": "main.html#optimal-controller-1",
    "href": "main.html#optimal-controller-1",
    "title": "main",
    "section": "Optimal Controller",
    "text": "Optimal Controller\n\n\n\n\n\nOptimal controller |Î¸â‹†||\\theta^\\star| minimizing ğ”¼ğ’¥\\mathbb{E}\\mathcal{J}\n\n\n\n\n\nMinimal expected cost ğ”¼ğ’¥\\mathbb{E}\\mathcal{J}\n\n\n\n\n\nOptimal control parameter a nontrivial function of Ïƒ\\sigma and Ïƒp\\sigma_p.\nBayesian learning strikes the right trade-off."
  },
  {
    "objectID": "main.html#motivation-1",
    "href": "main.html#motivation-1",
    "title": "main",
    "section": "Motivation",
    "text": "Motivation\n\nControl synthesis in PBC: Gues=âˆ‡qHâˆ’âˆ‡qHd\nGu_{es} = \\nabla_q H - \\nabla_q H_d\n\n\nIf underactuated, GG is not invertible\n\nChoice of uesu_{es} must satisfy nonlinear PDE\nQuadratic potential most likely not viable\n\nIncorporate performance objective into design of HdH_d?"
  },
  {
    "objectID": "main.html#neuralpbc-problem-statement",
    "href": "main.html#neuralpbc-problem-statement",
    "title": "main",
    "section": "NeuralPbc Problem Statement",
    "text": "NeuralPbc Problem Statement\n\nConsider the mechanical system\n[qÌ‡pÌ‡]=[âˆ’01âˆ’10][âˆ‡qHdâˆ‡pHd]+[0G]udi\n\\begin{bmatrix} \\dot{q} \\\\ \\dot{p} \\end{bmatrix} = \n\\begin{bmatrix} \\phantom{-}0 & 1 \\\\ -1 & 0 \\end{bmatrix} \n\\begin{bmatrix} \\nabla_q H_{\\phantom{d}} \\\\ \\nabla_p H_{\\phantom{d}} \\end{bmatrix} +\n\\begin{bmatrix} 0 \\\\ G \\end{bmatrix} u_\\phantom{di}\n\nControl task: stabilize desired equilibrium xâ‹†=(qâ‹†,0)x^\\star = (q^\\star, 0)\n\n\nu=ues+udi=Gâ€ (âˆ‡qHâˆ’âˆ‡qHd)âˆ’KDGâŠ¤âˆ‡pHdu = u_{es} + u_{di} = G^{\\dagger} \\left( \\nabla_q H  - \\nabla_q H_d \\right)  - K_D G^\\top \\nabla_p H_d \n\n\nu=ues+udi=âˆ’Gâ€ âˆ‡qHdÎ¸âˆ’KDGâŠ¤âˆ‡pHdÎ¸u = u_{es} + u_{di} = - G^{\\dagger} \\nabla_q H_d^{\\theta}  - K_D G^\\top \\nabla_p H_d^{\\theta} \n\n\nChoosing a suitable HdH_d is not trivial\n\nParameterize HdH_d by a neural network HdÎ¸H_d^\\theta, and relax control task to bringing xx to a small neighborhood of xâ‹†x^\\star\n\n\n\nInstead of asking for asymptotic stabilization, we only require that trajectories pass thru a nbhd of xâ‹†x^\\star\nThis is reasonable because we know how to stabilize a fixed point, e.g.Â stabilize the linearization of the system using LQR\nThis allows us to find approximations for HdÎ¸H_d^\\theta using learning techniques"
  },
  {
    "objectID": "main.html#neuralpbc-problem-statement-1",
    "href": "main.html#neuralpbc-problem-statement-1",
    "title": "main",
    "section": "NeuralPbc Problem Statement",
    "text": "NeuralPbc Problem Statement\n\n\n\n\nminimizeÎ¸J(Î¸,x0)=âˆ«0Tâ„“(Ï•,uÎ¸,Î¸)dtsubject to[qÌ‡pÌ‡]=[0Iâˆ’I0][âˆ‡qHâˆ‡pH]+[0G]uÎ¸uÎ¸=âˆ’Gâ€ âˆ‡qHdÎ¸âˆ’KDGâŠ¤âˆ‡pHdÎ¸\n\\begin{aligned}\n\\underset{\\theta}{\\text{minimize}} && J(\\theta, x_0) &= \\int_{0}^{T} \\ell \\left(\\phi,u^\\theta,\\theta\\right)\\, \\text{d} t \\\\\n\\text{subject to} &&\n\\begin{bmatrix}\n  \\dot{q} \\\\ \\dot{p}\n\\end{bmatrix} &=\n\\begin{bmatrix}\n  0 & I \\\\ -I & 0\n\\end{bmatrix}\n\\begin{bmatrix} \\nabla_q H \\\\ \\nabla_p H \\end{bmatrix} + \n\\begin{bmatrix}\n  0 \\\\ G\n\\end{bmatrix} u^{\\theta}\n\\\\\n&& u^\\theta &= - G^{\\dagger}\\nabla_q H_d^{\\theta}  - K_D G^\\top \\nabla_p H_d^{\\theta}\n\\end{aligned}\n\n\n\n\n\nInjecting control task into loss function design\nBackprop through closed-loop trajectories\nSampling the state space efficiently"
  },
  {
    "objectID": "main.html#neuralpbc-loss-function",
    "href": "main.html#neuralpbc-loss-function",
    "title": "main",
    "section": "NeuralPbc Loss Function",
    "text": "NeuralPbc Loss Function\n\nJ(Î¸,x0)=âˆ«0Tâ„“(Ï•,uÎ¸,Î¸)dt\nJ(\\theta, x_0) = \\int_{0}^{T} \\ell \\left(\\phi,u^\\theta,\\theta\\right)\\, \\text{d} t\n\nâ„“â‰œâ„“set(Î³)+â„“âŠ¥(Î³,u)\\ell \\triangleq \\ell_{\\text{set}}(\\gamma) + \\ell_{\\bot}(\\gamma,u) where\n\nÏ•\\phi is the flow of the equation of motion\nÎ³\\gamma is the closed-loop trajectory starting from x0x_0\nTT is the time horizon (hyperparameter)"
  },
  {
    "objectID": "main.html#neuralpbc-loss-function-1",
    "href": "main.html#neuralpbc-loss-function-1",
    "title": "main",
    "section": "NeuralPbc Loss Function",
    "text": "NeuralPbc Loss Function\n\nâ„“â‰œâ„“set(Î³)+â„“âŠ¥(Î³,u)\\ell \\triangleq \\ell_{\\text{set}}(\\gamma) + \\ell_{\\bot}(\\gamma,u)\n\n\n\nSet Distance Loss â„“set\\ell_{\\text{set}}\n\n\nPenalizes when closed-loop trajectory Î³\\gamma under the current control law is far away from a neighborhood ğ’®\\mathcal{S} of xâ‹†x^\\star\n\n\n\n\n\n\nâ„“set(x)=inft{âˆ¥aâˆ’bâˆ¥:aâˆˆÎ³(t),bâˆˆğ’®}\\ell_{\\text{set}}(x) = \\underset{t}{\\inf} \\left\\{ \\lVert a-b \\rVert : a \\in \\gamma(t), b \\in \\mathcal{S}\\right\\} * The set ğ’®\\mathcal{S} may be chosen as * A ball around xâ‹†x^\\star * Estimated region of attraction * No additional loss if any point in Î³\\gamma is in ğ’®\\mathcal{S}"
  },
  {
    "objectID": "main.html#neuralpbc-loss-function-2",
    "href": "main.html#neuralpbc-loss-function-2",
    "title": "main",
    "section": "NeuralPbc Loss Function",
    "text": "NeuralPbc Loss Function\n\nâ„“â‰œâ„“set(Î³)+â„“âŠ¥(Î³,u)\\ell \\triangleq \\ell_{\\text{set}}(\\gamma) + \\ell_{\\bot}(\\gamma,u)\n\n\n\nTransversal Distance Loss â„“âŠ¥\\ell_{\\bot}\n\n\nMeasures how close Î³\\gamma is to Î³â‹†\\gamma^\\star (expert trajectory) using transverse coordinates xâŠ¥x_\\bot\n\n\n\n\n\n\n\nCoordinate transformation\n\nÏ„âˆˆâ„\\tau \\in \\mathbb{R} a surrogate for time\nxâŠ¥âˆˆâ„2nâˆ’1x_{\\bot} \\in \\mathbb{R}^{2n-1} quantify how far away the current state is from Î³â‹†\\gamma^\\star\n\nBy construction xâŠ¥â†’0â‡”Î³=Î³â‹†x_{\\bot} \\to 0 \\iff \\gamma = \\gamma^\\star\n\nâ„“âŠ¥=xâŠ¥âŠ¤QxâŠ¥+uâŠ¤Ru,Qâ‰½0,Râ‰»0\\ell_{\\bot} = x_\\bot^\\top Q x_\\bot + u^\\top R u, \\, Q \\succeq 0, \\, R \\succ 0\n\nNo preferred orbit? Q=0Q = 0\n\n\n\n\n\n\n\n\n\nWe can find a coordinate transformation such that 1 coordinate Ï„\\tau is along the desired orbit and acts as surrogate for time\nThe remaining coordinates xâŠ¥x_{\\bot} quantify how far away the current state is from the desired trajectory"
  },
  {
    "objectID": "main.html#backprop-through-ode-solutions",
    "href": "main.html#backprop-through-ode-solutions",
    "title": "main",
    "section": "Backprop through ODE Solutions",
    "text": "Backprop through ODE Solutions\n\nWe need âˆ‚J/âˆ‚Î¸\\partial J / \\partial \\theta, which depends ODE solutions\n\nğŸ˜¿ Combining autodiff with numerical ODE solvers\n\n\nğŸ˜¿ Adjoint sensitivity method: solve the adjoint problem backward in time dÎ»dt=âˆ’Î»âˆ‚fâˆ‚x,âˆ‚Jâˆ‚Î¸=Î»(t0)âˆ‚fâˆ‚x\\frac{\\text{d}\\lambda}{\\text{d}t} = -\\lambda \\frac{\\partial f}{\\partial x}, \\quad \\frac{\\partial J}{\\partial \\theta} = \\lambda(t_0) \\frac{\\partial f}{\\partial x}\n\n\nğŸ˜º Adjoint methods + autodiff implemented in DiffEqFlux.jl\n\n\n\nPlain autodiff causes errors due to numerical ODE integration, high memory consumption\nAdjoint methods requires storing many passes of the adjoint problem, again high memory consumption\nDiffEqFlux combines the two, avoiding multiple passes through clever implementation, fast an efficient"
  },
  {
    "objectID": "main.html#neuralpbc-sampling-state-space",
    "href": "main.html#neuralpbc-sampling-state-space",
    "title": "main",
    "section": "NeuralPbc Sampling State Space",
    "text": "NeuralPbc Sampling State Space\n\nLearned policy uÎ¸u^\\theta need to perform well for a wide range of x0x_0\n\n\nJ(Î¸,x0)=âˆ«0Tâ„“(Ï•,uÎ¸,Î¸)dtJ(\\theta, x_0) = \\int_{0}^{T} \\ell \\left(\\phi,u^\\theta,\\theta\\right)\\, \\text{d} t\n\n\n\nJ(Î¸)=ğ”¼x0âˆ¼p(ğ±0)[âˆ«0Tâ„“(Ï•(t,x0),uÎ¸,Î¸)dt]J(\\theta) = \\mathbb{E}_{x_0 \\sim p(\\mathbf{x}_0)} \\left[ \\int_{0}^{T} \\ell \\left(\\phi(t,x_0),u^\\theta,\\theta\\right)\\, \\text{d} t \\right]\n\n\nSample state space with technique based on DAgger1\n\n\nSimulating system under application of uÎ¸u^\\theta\nCollect samples from the regions of state-space visited by uÎ¸u^\\theta\n\n\n\n\nUse dynamics to guide the collection of samples\n\n\nRoss, S., Gordon, G. J., & Bagnell, J. A. (2011). No-regret reductions for imitation learning and structured prediction. In AISTATS."
  },
  {
    "objectID": "main.html#neuralpbc-algorithm",
    "href": "main.html#neuralpbc-algorithm",
    "title": "main",
    "section": "NeuralPbc Algorithm ğŸ“‰",
    "text": "NeuralPbc Algorithm ğŸ“‰"
  },
  {
    "objectID": "main.html#bayesian-solution",
    "href": "main.html#bayesian-solution",
    "title": "main",
    "section": "Bayesian Solution",
    "text": "Bayesian Solution\n\nÂ \n\nComputing ELBO â„’(ğ’Ÿ;z)=ğ”¼Î¸âˆ¼q[logp(ğ’Ÿâˆ£Î¸)p(Î¸)âˆ’logq(Î¸;z)] \\mathcal{L}(\\mathcal{D};z) = \\mathbb{E}_{\\theta \\sim q}\\left[ \\log p(\\mathcal{D} \\mid \\theta)p(\\theta) - \\log q(\\theta; z)  \\right]  requires: Â \n\nLikelihood: p(âˆ¥â„“set(Î³)+â„“âŠ¥(Î³,u)âˆ¥2âˆ£Î¸)=ğ’©(0,s). p\\left( \\lVert \\ell_{\\text{set}}(\\gamma) + \\ell_\\bot(\\gamma, u) \\rVert^2 \\mid \\theta \\right) = \\mathcal{N}(0, s). \n\n\nPrior:\n\n\nUninformed\n\n\nDeterministic"
  },
  {
    "objectID": "main.html#comparison-of-methods",
    "href": "main.html#comparison-of-methods",
    "title": "main",
    "section": "Comparison of Methods",
    "text": "Comparison of Methods\n\nÂ \n\n\n\nAdvantages âœ”ï¸ and Disadvantages âŒ\n\n\n\n\n\n\n\n\n\n\nCase\nDeterministic\nBayesian\n\n\n\n\nRobustness\nâŒ\nâœ”ï¸\n\n\nComputation cost\nâœ”ï¸\nâŒ\n\n\nModel selection\nâŒ\nâœ”ï¸\n\n\nPrior knowledge\nâœ”ï¸\nâœ”ï¸âœ”ï¸\n\n\nOverfitting\nâŒ\nâœ”ï¸"
  },
  {
    "objectID": "main.html#energy-shaping-pendulum-swing-up",
    "href": "main.html#energy-shaping-pendulum-swing-up",
    "title": "main",
    "section": "Energy-Shaping Pendulum Swing-Up",
    "text": "Energy-Shaping Pendulum Swing-Up"
  },
  {
    "objectID": "main.html#energy-shaping-pendulum-swing-up-1",
    "href": "main.html#energy-shaping-pendulum-swing-up-1",
    "title": "main",
    "section": "Energy-Shaping Pendulum Swing-Up",
    "text": "Energy-Shaping Pendulum Swing-Up\n\n\n\n\n\n\n\nDeterministic training vs.Â Bayesian training under parameter uncertainty and measurement noise.\nMeasurement noise: Ïµq=5Ã—104\\epsilon_q = 5 \\times 10^4 rad., ÏµqÌ‡=5Ã—102\\epsilon_{\\dot{q}} = 5 \\times 10^2 rad/s."
  },
  {
    "objectID": "main.html#neuralpbc-experiments",
    "href": "main.html#neuralpbc-experiments",
    "title": "main",
    "section": "NeuralPbc Experiments",
    "text": "NeuralPbc Experiments\n\nBenchmark underactuated control problems:\n\n\n\n\nCart-pole\n\n\nInertia-Wheel Pendulum (IWP)\n\n\nAcrobot"
  },
  {
    "objectID": "main.html#learned-storage-function",
    "href": "main.html#learned-storage-function",
    "title": "main",
    "section": "Learned storage function",
    "text": "Learned storage function\n\n\n\nObservations\n\nHdÎ¸H_d^\\theta has a local minimum at xâ‹†x^\\star, control law uÎ¸u^\\theta commands the force in the expected direction"
  },
  {
    "objectID": "main.html#comparison-with-energy-shapingastrom",
    "href": "main.html#comparison-with-energy-shapingastrom",
    "title": "main",
    "section": "Comparison with Energy Shaping1",
    "text": "Comparison with Energy Shaping1\n\n\nK. J. Ã…strÃ¶m and K. Furuta, â€œSwinging up a pendulum by energy control,â€ Automatica, vol.Â 36, no. 2, pp.Â 287â€“295, 2000."
  },
  {
    "objectID": "main.html#motivation-2",
    "href": "main.html#motivation-2",
    "title": "main",
    "section": "Motivation",
    "text": "Motivation\n\nNeuralPbc is flexible, but guaranteeing stability is hard\nAdditional structure of IdaPbc facilitates stability analysis\n\n\n[qÌ‡pÌ‡]=[0Iâˆ’I0][âˆ‡qHâˆ‡pH]+[0G]u \\begin{bmatrix} \\dot{q} \\\\ \\dot{p} \\end{bmatrix} = \\begin{bmatrix}0 & I \\\\ -I & 0\\end{bmatrix} \\begin{bmatrix} \\nabla_q H \\\\ \\nabla_p H  \\end{bmatrix} + \\begin{bmatrix} 0 \\\\ G \\end{bmatrix} u  \nClosed-loop port-Hamiltonian dynamics:\n\n[qÌ‡pÌ‡]=[0Mâˆ’1Mdâˆ’MdMâˆ’1J2(q,p)âˆ’GKvGâŠ¤][âˆ‡qHdâˆ‡pHd]\n\\begin{bmatrix} \\dot{q} \\\\ \\dot{p} \\end{bmatrix}\n=\n\\begin{bmatrix}0 & M^{-1}M_d \\\\ -M_dM^{-1} & J_2(q,p) - GK_vG^\\top\\end{bmatrix}\n\\begin{bmatrix} \\nabla_q H_d \\\\ \\nabla_p H_d \\end{bmatrix}\n  \nHd=12pâŠ¤Md(q)âˆ’1p+Vd(q),Mdâ‰»0H_d = \\frac{1}{2} p^{\\top} M_d(q)^{-1} p + V_d(q),\\, M_d \\succ 0\n\n\nFurther structure not only facilitates stability analysis but also restricts the search to a pd matrix MdM_d and VdV_d.\nThis search may be performed solely on the configuration space."
  },
  {
    "objectID": "main.html#idapbc-background",
    "href": "main.html#idapbc-background",
    "title": "main",
    "section": "IdaPbc Background",
    "text": "IdaPbc Background\n\n[qÌ‡pÌ‡]=[0Mâˆ’1Mdâˆ’MdMâˆ’1J2(q,p)âˆ’GKvGâŠ¤][âˆ‡qHdâˆ‡pHd] \\begin{bmatrix} \\dot{q} \\\\ \\dot{p} \\end{bmatrix} = \\begin{bmatrix}0 & M^{-1}M_d \\\\ -M_dM^{-1} & J_2(q,p) - GK_vG^\\top\\end{bmatrix} \\begin{bmatrix} \\nabla_q H_d \\\\ \\nabla_p H_d \\end{bmatrix} \nHd=12pâŠ¤Md(q)âˆ’1p+Vd(q),Mdâ‰»0H_d = \\frac{1}{2} p^{\\top} M_d(q)^{-1} p + V_d(q),\\, M_d \\succ 0\n\n\n\n\n\n\nStability results\n\n\nHÌ‡d=(âˆ‡pHd)âŠ¤(âˆ’GKvGâŠ¤)âˆ‡pHdâ‰¤âˆ’Î»min{Kv}âˆ¥(âˆ‡pHd)âŠ¤Gâˆ¥2â‰¤0\\begin{aligned}\\dot{H}_d &= \\left( \\nabla_p H_d \\right)^{\\top} \\left(-G K_v G^{\\top}\\right) \\nabla_p H_d \\\\ &\\leq -\\lambda_{\\textrm{min}} \\{ K_v \\} \\left\\| \\left( \\nabla_p H_d \\right)^{\\top} G \\right\\|^2 \\leq 0 \\end{aligned}\nWith qâ‹†=argminVd(q)q^\\star = \\arg \\min V_d(q), we have xâ†’xâ‹†=(qâ‹†,0)x \\to x^\\star = (q^\\star, 0)\n\n\n\n\n\n\n\n\nControl synthesis\n\n\nChoose u=ues+udiu = u_{es} + u_{di} where Gues=âˆ‡qHâˆ’MdMâˆ’1âˆ‡qHd+J2Mdâˆ’1pâˆ‡pâŠ¤udi=âˆ’KvGâŠ¤âˆ‡pHdâˆ¥(âˆ‡p)âŠ¤âˆ¥2\n\\begin{aligned} \nGu_{es} &= \\nabla_{q} H - M_{d}M^{-1} \\nabla_{q} H_{d} \\\\\n&\\quad\\; + J_{2} M_{d}^{-1} p \\phantom{\\nabla_{p}^{\\top}} \\\\\nu_{di} &= -K_v G^\\top \\nabla_p H_d \\phantom{\\left\\|\\left(\\nabla_p\\right)^{\\top} \\right\\|^2} \n\\end{aligned}"
  },
  {
    "objectID": "main.html#idapbc-via-optimization",
    "href": "main.html#idapbc-via-optimization",
    "title": "main",
    "section": "IdaPbc via Optimization",
    "text": "IdaPbc via Optimization\n\n\n\n\nÂ \n\n\n\n\n\nminimizeMd,J2,Vd0subject to0=GâŠ¥{âˆ‡qHâˆ’MdMâˆ’1âˆ‡qHd+J2Mdâˆ’1p}Hd=12pâŠ¤Md(q)âˆ’1p+Vd(q)Md=MdâŠ¤â‰»0J2=âˆ’J2âŠ¤qâ‹†=argminqVd(q)\n\\begin{aligned}\n\\underset{M_d,\\,J_2,\\,V_d}{\\text{minimize}} && 0 &  \\\\\n\\text{subject to} &&\n0 &= G^{\\bot}\\left\\{ \\nabla_{q} H - M_{d}M^{-1} \\nabla_{q} H_{d} + J_{2} M_{d}^{-1} p  \\right\\}\n\\\\\n&& H_d &= \\frac{1}{2} p^{\\top} M_d(q)^{-1} p + V_d(q)\n\\\\\n&& M_d &= M_d^\\top \\succ 0\n\\\\\n&& J_2 &= -J_2^\\top\n\\\\\n&& q^\\star &= \\underset{q}{\\arg \\min} \\, V_d(q)\n\\end{aligned}\n\n\n\n\n\n\nÂ \n\n\n\n\nInfinite-dimensionalâ€”closed-form solution is difficult"
  },
  {
    "objectID": "main.html#neuralidapbc-2",
    "href": "main.html#neuralidapbc-2",
    "title": "main",
    "section": "NeuralIdaPbc",
    "text": "NeuralIdaPbc"
  },
  {
    "objectID": "main.html#neuralidapbc-problem-statement",
    "href": "main.html#neuralidapbc-problem-statement",
    "title": "main",
    "section": "NeuralIdaPbc Problem Statement",
    "text": "NeuralIdaPbc Problem Statement\n\n\n\n\nÂ \n\n\n\n\n\nminimizeÎ¸J(Î¸)=âˆ¥GâŠ¥{âˆ‡qHâˆ’MdÎ¸Mâˆ’1âˆ‡qHdÎ¸+J2Î¸(MdÎ¸)âˆ’1p}âˆ¥2subject toHdÎ¸=12pâŠ¤(MdÎ¸)âˆ’1p+VdÎ¸(q)MdÎ¸(q)=(MdÎ¸(q))âŠ¤â‰»0J2Î¸(q,p)=âˆ’(J2Î¸(q,p))âŠ¤qâ‹†=argminqVdÎ¸(q)\n\\begin{aligned}\n\\underset{\\theta}{\\text{minimize}} && J(\\theta) &= \\left\\lVert G^{\\bot} \\left\\{ \\nabla_{q} H - M_{d}^{\\theta}M^{-1} \\nabla_{q} H_{d}^{\\theta} + J_{2}^{\\theta} \\left(M_{d}^{\\theta}\\right)^{-1} p \\right\\} \\right\\rVert^2  \\\\\n\\text{subject to} \n&& H_d^{\\theta} &= \\frac{1}{2} p^{\\top} \\left( M_{d}^{\\theta} \\right)^{-1} p + V_{d}^{\\theta}(q)\n\\\\\n&& M_d^{\\theta}(q) &= \\left(M_d^{\\theta}(q)\\right)^\\top \\succ 0\n\\\\\n&& J_{2}^{\\theta}(q,p) &= -\\left(J_{2}^{\\theta}(q,p)\\right)^\\top\n\\\\\n&& q^\\star &= \\underset{q}{\\arg \\min} \\, V_{d}^{\\theta} (q)\n\\end{aligned}\n\n\n\n\n\n\nÂ \n\n\n\n\n\n\n\nFinite-dimensional search\nSample configuration space\n\n\n\nÂ \n\n\n\nController uu is a continuous function of JJ"
  },
  {
    "objectID": "main.html#neuralidapbc-constraints",
    "href": "main.html#neuralidapbc-constraints",
    "title": "main",
    "section": "NeuralIdaPbc Constraints",
    "text": "NeuralIdaPbc Constraints\n\n\nMdÎ¸=(MdÎ¸)âŠ¤â‰»0M_d^{\\theta} = \\left(M_d^{\\theta}\\right)^{\\top} \\succ 0\n\n\nJ2Î¸=âˆ’(J2Î¸)âŠ¤J_{2}^{\\theta} = -\\left(J_{2}^{\\theta}\\right)^{\\top}\nqâ‹†=argminqVdÎ¸(q)q^\\star = \\underset{q}{\\arg \\min} \\, V_{d}^{\\theta} (q)\n\n\n\n\n\nPositive-definiteness of the desired mass matrix\n\n\n\nCholesky decomposition MdÎ¸(q)=LÎ¸(q)LÎ¸âŠ¤(q)M_d^\\theta(q) = L_{\\theta}(q) L_{\\theta}^{\\top}(q)\nComponents of the lower-triangular matrix LÎ¸(q)L_\\theta(q) are outputs of a neural network"
  },
  {
    "objectID": "main.html#neuralidapbc-constraints-1",
    "href": "main.html#neuralidapbc-constraints-1",
    "title": "main",
    "section": "NeuralIdaPbc Constraints",
    "text": "NeuralIdaPbc Constraints\n\n\nMdÎ¸=(MdÎ¸)âŠ¤â‰»0M_d^{\\theta} = \\left(M_d^{\\theta}\\right)^{\\top} \\succ 0\n\n\nJ2Î¸=âˆ’(J2Î¸)âŠ¤J_{2}^{\\theta} = -\\left(J_{2}^{\\theta}\\right)^{\\top}\n\n\nqâ‹†=argminqVdÎ¸(q)q^\\star = \\underset{q}{\\arg \\min} \\, V_{d}^{\\theta} (q)\n\n\n\n\n\nSkew symmetry of J2Î¸(q,p)J_2^\\theta(q,p)\n\n\n\nDecompose a square matrix into symmetric and skew-symmetric parts J2Î¸(q,p)=AÎ¸(q,p)âˆ’AÎ¸âŠ¤(q,p)J_2^\\theta(q,p) = A_{\\theta}(q,p) -  A_{\\theta}^{\\top}(q,p)\nComponents of the square matrix AÎ¸(q,p)A_\\theta(q,p) are output of a neural network"
  },
  {
    "objectID": "main.html#neuralidapbc-constraints-2",
    "href": "main.html#neuralidapbc-constraints-2",
    "title": "main",
    "section": "NeuralIdaPbc Constraints",
    "text": "NeuralIdaPbc Constraints\n\n\nMdÎ¸=(MdÎ¸)âŠ¤â‰»0M_d^{\\theta} = \\left(M_d^{\\theta}\\right)^{\\top} \\succ 0 J2Î¸=âˆ’(J2Î¸)âŠ¤J_{2}^{\\theta} = -\\left(J_{2}^{\\theta}\\right)^{\\top}\n\n\nqâ‹†=argminqVdÎ¸(q)q^\\star = \\underset{q}{\\arg \\min} \\, V_{d}^{\\theta} (q)\n\n\n\n\n\nBoundedness of VdÎ¸V_d^\\theta\n\n\n\nVdÎ¸(q)V_d^\\theta(q) bounded from below with isolated minimum at qâ‹†q^\\star \nParameterize VdÎ¸V_d^\\theta by a sums-of-square (SoS) polynomial\nVdÎ¸(q)&gt;0,qâ‰ qâ‹†V_d^\\theta(q) &gt; 0,\\, q \\neq q^\\star"
  },
  {
    "objectID": "main.html#sos-decomposition",
    "href": "main.html#sos-decomposition",
    "title": "main",
    "section": "SoS Decomposition",
    "text": "SoS Decomposition\n\n\n\n\nTheorem (Choi, 1995)\n\n\nA polynomial Pâˆˆâ„[x]P \\in \\mathbb{R}[x] of degree 2d2d has a SoS decomposition â‡”\\Leftrightarrow âˆƒQâ‰»0\\exists Q \\succ 0 such that, with Î¼(x)=[1x1â‹¯xnx1x2â‹¯xnd]\\mu(x) = \\begin{bmatrix} 1 & x_1 & \\cdots & x_n & x_1 x_2 & \\cdots & x_n^d\\end{bmatrix}, we have P(x)=Î¼(x)âŠ¤QÎ¼(x)P(x) = \\mu(x)^\\top Q \\mu(x)\n\n\n\n\n\n\n\nExample\n\n\nx12+2x12x2+5x12x22+4x1x22+x22=Î¼(x)âŠ¤(110152021)Î¼(x)=Î¼(x)âŠ¤(100120010)(100120010)âŠ¤Î¼(x)\\begin{aligned} x_1^2 + 2x_1^2x_2 + 5x_1^2x_2^2 + 4x_1x_2^2 + x_2^2  &= \\mu(x)^{\\top} \\begin{pmatrix} 1 & 1 & 0 \\\\ 1 & 5 & 2 \\\\ 0 & 2 & 1 \\end{pmatrix} \\mu(x) \\\\ &= \\mu(x)^{\\top} \\begin{pmatrix} 1 & 0 & 0 \\\\ 1 & 2 & 0 \\\\ 0 & 1 & 0 \\end{pmatrix} \\begin{pmatrix}   1 & 0 & 0 \\\\ 1 & 2 & 0 \\\\ 0 & 1 & 0 \\end{pmatrix}^{\\top} \\mu(x) \\end{aligned}"
  },
  {
    "objectID": "main.html#neuralidapbc-experiments",
    "href": "main.html#neuralidapbc-experiments",
    "title": "main",
    "section": "NeuralIdaPbc Experiments",
    "text": "NeuralIdaPbc Experiments\n\nFollowed the experiments performed in IdaPbc paper1\n\nInertia-wheel pendulum (IWP)\nBall-beam system\n\nR. Ortega, M. W. Spong, F. GÃ³mez-Estern, and G. Blankenstein, â€œStabilization of a class of underactuated mechanical systems via interconnection and damping assignment,â€ IEEE transactions on automatic control, vol.Â 47, no. 8, pp. 1218â€“1233, 2002."
  },
  {
    "objectID": "main.html#simulated-iwp-experiments",
    "href": "main.html#simulated-iwp-experiments",
    "title": "main",
    "section": "Simulated IWP experiments",
    "text": "Simulated IWP experiments\n\n\n\n\n\n\n\nComparison of control effort expenditure\n\n\n\n\n\n\n\n\n\nNeuralPbc\nNeuralIdaPbc\nIdaPbc"
  },
  {
    "objectID": "main.html#deterministic-vs.-bayesian-training",
    "href": "main.html#deterministic-vs.-bayesian-training",
    "title": "main",
    "section": "Deterministic vs.Â Bayesian Training",
    "text": "Deterministic vs.Â Bayesian Training\n\n\n\n\nPerformance metric: ğ’¥=âˆ«0T(12qx(t)2+12ru(t)2)dt\\mathcal{J} = \\int_0^T \\left( \\frac{1}{2}qx(t)^2 + \\frac{1}{2}ru(t)^2 \\right)dt.\n\nÂ \n\nSimulated dynamics\ndx=[qÌ‡1q2Ì‡1I1(mglsinq1âˆ’uÎ¸âˆ’b1qÌ‡1)1I2(uÎ¸âˆ’b2qÌ‡2)]dt+âˆ‡xuÎ¸(x)ÏƒdWt.\n\\begin{aligned}\ndx &= \\begin{bmatrix}\n\\dot{q}_1 \\\\ \\dot{q_2} \\\\ \\frac{1}{I_1}\\left(m g l \\sin{q_1} - u^\\theta -\nb_1\\dot{q}_1\\right) \\\\ \\frac{1}{I_2}\\left(u^\\theta -b_2 \\dot{q}_2 \\right)\n\\end{bmatrix} dt \\\\\n&+ \\nabla_xu^\\theta(x) \\sigma dW_t.\n\\end{aligned}"
  },
  {
    "objectID": "main.html#deterministic-vs.-bayesian-training-1",
    "href": "main.html#deterministic-vs.-bayesian-training-1",
    "title": "main",
    "section": "Deterministic vs.Â Bayesian Training",
    "text": "Deterministic vs.Â Bayesian Training\n\n\n\n\n\nSubtracting rings from the wheel\n\ndecreases wheel mass\ndecreases wheel and pendulum inertia\nmoves the center of mass\n\n\n\n\n\n\n\n\n\nParameter vector Î¶\\zeta\nI1I_1\nI2I_2\nmglm g l\nError\n\n\n\n\nNominal\n0.04550.0455\n0.004250.00425\n1.7951.795\n00\n\n\n3 rings\n0.04170.0417\n0.003300.00330\n1.5771.577\n0.1220.122\n\n\n2 rings\n0.03780.0378\n0.002350.00235\n1.3581.358\n0.2430.243\n\n\n1 rings\n0.03400.0340\n0.001410.00141\n1.1401.140\n0.3650.365"
  },
  {
    "objectID": "main.html#ball-beam-experiments",
    "href": "main.html#ball-beam-experiments",
    "title": "main",
    "section": "Ball-beam experiments",
    "text": "Ball-beam experiments"
  },
  {
    "objectID": "main.html#closing-thoughts-and-future-directions",
    "href": "main.html#closing-thoughts-and-future-directions",
    "title": "main",
    "section": "Closing Thoughts and Future Directions",
    "text": "Closing Thoughts and Future Directions\nPBC + machine learning techniques âœ¨\n\n\nWe uncovered the engineering foundations for combining them\nTransparent connection to stability analysis (NeuralIdaPbc)\nExtensive experimental results in simulation and on hardware\n\n\nFuture directionsâ€”applications in:\n\n\nDynamical models with uncertainity\nHybrid dynamical systems (walking machines)"
  },
  {
    "objectID": "main.html#data-driven-control-through-contact",
    "href": "main.html#data-driven-control-through-contact",
    "title": "main",
    "section": "Data-Driven Control Through Contact",
    "text": "Data-Driven Control Through Contact\n\n\n\nÂ \n\n\n\nminq(Î¸)J(Ï•(t;x0,u),u)subject toM(x)dxâˆ’h(x,xÌ‡,u)dtâˆ’dÎ›=0,u(x;Î¸)=ğ’Ÿ{F(x;Î¸)},Î¶âˆ¼ğ’©(Î¶0,Î£Î¶),Î¸âˆ¼q(Î¸),\n\\begin{aligned}\n\\underset{q(\\theta) }{\\text{min}} \n&&\\quad J(&\\phi(t; x_0, u), u) \\\\\n\\text{subject to} \n&&\\quad M(x) dx &- h(x, \\dot{x}, u) dt - d\\Lambda= 0, \\\\\n&&\\quad u(x; \\theta) &= \\mathcal{D}\\{F(x; \\theta)\\}, \\\\\n&&\\quad \\zeta &\\sim \\mathcal{N}(\\zeta_0, \\Sigma_{\\zeta}), \\\\\n&&\\quad \\theta &\\sim q(\\theta),\n\\end{aligned} \n\n\n\n\n\n\n\n\n\n\nImpacts and friction modelled through measure differential inclusions.\nUsually solved through linear complementarity problems (convex optimization).\nData-driven PBC designed to be robust against uncertainties (e.g.Â surface friction)."
  },
  {
    "objectID": "main.html#acknowledgements",
    "href": "main.html#acknowledgements",
    "title": "main",
    "section": "Acknowledgements",
    "text": "Acknowledgements"
  },
  {
    "objectID": "main.html#neuralpbc-publications",
    "href": "main.html#neuralpbc-publications",
    "title": "main",
    "section": "NeuralPbc Publications",
    "text": "NeuralPbc Publications\n\nThis work is published in ISER 20201, CCTA 20212\nW. Sirichotiyakul and A. C. Satici, â€œData-driven design of energy-shaping controllers for swing-up control of underactuated robots,â€ in International Symposium on Experimental Robotics. Springer, 2020, pp.Â 323-333.W. Sirichotiyakul and A. C. Satici, â€œCombining energy-shaping control of dynamical systems with data-driven approaches,â€ in 2021 IEEE Conference on Control Technology and Applications (CCTA). IEEE, 2021, pp.Â 1121-1127."
  },
  {
    "objectID": "main.html#neuralpbc-publications-1",
    "href": "main.html#neuralpbc-publications-1",
    "title": "main",
    "section": "NeuralPbc Publications",
    "text": "NeuralPbc Publications\n\nThis work also provides a foundation for an ongoing research that investigate the improvement of robustness properties of NeuralPbc1,2\nW. Sirichotiyakul, N. A. Ashenafi, and A. C. Satici, â€œRobust Data-Driven Passivity-Based Control of Underactuated Systems via Neural Approximators and Bayesian Inference,â€ in 2022 American Control Conference, ACC. IEEE, Accepted for publication January 2022.N. A. Ashenafi, W. Sirichotiyakul, and A. C. Satici, â€œRobust Passivity-Based Control of Underactuated Systems via Neural Approximators and Bayesian In ference,â€ in 2022 Conference on Decision and Control, CDC. IEEE. (Submitted for review March 2022)."
  },
  {
    "objectID": "main.html#neuralidapbc-publications",
    "href": "main.html#neuralidapbc-publications",
    "title": "main",
    "section": "NeuralIdaPbc Publications",
    "text": "NeuralIdaPbc Publications\n\nThis work is published in the International Journal of Control1\nÂ \nNeuralIdaPbc is the basis for an ongoing research that investigate the improvement of robustness properties2\nW. Sirichotiyakul and A. C. Satici, â€œData-Driven Passivity-Based Control of Underactuated Mechanical Systems via Interconnection and Damping Assignment,â€ in International Journal of Control. (Accepted for publication March 2022)W. Sirichotiyakul, N. A. Ashenafi, and A. C. Satici, â€œRobust Interconnection and Damping Assignment Passivity-Based Control via Neural Bayesian Inference,â€ in IEEE Transactions on Automatic Control. (Submitted for review April 2022)"
  },
  {
    "objectID": "main.html#diffeqflux.jl-demo",
    "href": "main.html#diffeqflux.jl-demo",
    "title": "main",
    "section": "DiffEqFlux.jl Demo",
    "text": "DiffEqFlux.jl Demo\n\nLearning xÌ‡=f(x)\\dot{x} = f(x) where ff is a neural network\nRegress on MSE between trajectory of ff and data"
  },
  {
    "objectID": "main.html#neuralidapbc-main-problem",
    "href": "main.html#neuralidapbc-main-problem",
    "title": "main",
    "section": "NeuralIdaPbc Main Problem",
    "text": "NeuralIdaPbc Main Problem\n\nminimizeÎ¸J(Î¸)=âˆ¥GâŠ¥{âˆ‡qHâˆ’MdÎ¸Mâˆ’1âˆ‡qHdÎ¸+J2Î¸(MdÎ¸)âˆ’1p}âˆ¥2subject toHdÎ¸=12pâŠ¤(MdÎ¸)âˆ’1p+VdÎ¸(q)MdÎ¸(q)=(MdÎ¸(q))âŠ¤â‰»0J2Î¸(q,p)=âˆ’(J2Î¸(q,p))âŠ¤qâ‹†=argminqVdÎ¸(q)\\begin{aligned} \\underset{\\theta}{\\text{minimize}} && J(\\theta) &= \\left\\lVert G^{\\bot} \\left\\{ \\nabla_{q} H - M_{d}^{\\theta}M^{-1} \\nabla_{q} H_{d}^{\\theta} + J_{2}^{\\theta} \\left(M_{d}^{\\theta}\\right)^{-1} p \\right\\} \\right\\rVert^2  \\\\ \\text{subject to}  && H_d^{\\theta} &= \\frac{1}{2} p^{\\top} \\left( M_{d}^{\\theta} \\right)^{-1} p + V_{d}^{\\theta}(q) \\\\ && M_d^{\\theta}(q) &= \\left(M_d^{\\theta}(q)\\right)^\\top \\succ 0 \\\\ && J_{2}^{\\theta}(q,p) &= -\\left(J_{2}^{\\theta}(q,p)\\right)^\\top \\\\ && q^\\star &= \\underset{q}{\\arg \\min} \\, V_{d}^{\\theta} (q) \\end{aligned}\n\n\n\n\n\n\nNeuralIdaPbc\n\n\n\nSolve nonlinear PDEs using neural networks and SoS polynomials\nSurrogates of MdM_d, J2J_2, VdV_d are constrained by construction\n\n\n\n\n\n\n\n\n\n\nPinn\n\n\n\nSolve nonlinear PDEs using neural networks\nSolution surrogates are constrained via penalty term in loss function"
  },
  {
    "objectID": "main.html#sos-polynomials",
    "href": "main.html#sos-polynomials",
    "title": "main",
    "section": "SoS Polynomials",
    "text": "SoS Polynomials\n\nIs p(x)p(x) nonnegative for all xx? p(x)=4x12+x1x2âˆ’4x22âˆ’2.1x14+4x24+13x16+1.0316p(x) = 4x_1^2 + x_1x_2 - 4x_2^2 - 2.1x_1^4 + 4x_2^4 + \\frac{1}{3}x_1^6 + 1.0316\\;\n\np(x)=(0.116x12+0.01x1x2âˆ’2x22+1.015)2+(âˆ’0.569x13+1.938x1+0.244x2)2+(0.224x12+0.666x1x2+0.029x22+0.026)2+(âˆ’0.188x12+0.063x1x2âˆ’0.006x22+0.009)2+(0.099x13+0.029x1+0.004x2)2+(0.009x12x2)2\\begin{aligned} p(x) = &\\left(0.116x_1^2 + 0.01x_1x_2 - 2x_2^2 + 1.015\\right)^2 \\\\ & + \\; \\left(-0.569x_1^3 + 1.938x_1 + 0.244x_2\\right)^2 \\\\ & + \\; \\left(0.224x_1^2 + 0.666x_1x_2 + 0.029x_2^2 + 0.026\\right)^2 \\\\ & + \\; \\left(-0.188x_1^2 + 0.063x_1x_2 - 0.006x_2^2 + 0.009\\right)^2 \\\\ & + \\; \\left(0.099x_1^3 + 0.029x_1 + 0.004x_2\\right)^2 + \\left(0.009x_1^2x_2\\right)^2 \\end{aligned}\n\n\n\nData-Driven Passivity-Based Control â€¢ Aykut C. Satici"
  },
  {
    "objectID": "main.html#neuralidapbc-1",
    "href": "main.html#neuralidapbc-1",
    "title": "main",
    "section": "NeuralIdaPbc",
    "text": "NeuralIdaPbc"
  },
  {
    "objectID": "main.html#acknowledgments",
    "href": "main.html#acknowledgments",
    "title": "main",
    "section": "Acknowledgments",
    "text": "Acknowledgments"
  }
]