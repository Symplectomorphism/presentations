[
  {
    "objectID": "main.html#data-driven-passivity-based-control-of-robotic-locomotion-and-manipulation",
    "href": "main.html#data-driven-passivity-based-control-of-robotic-locomotion-and-manipulation",
    "title": "main",
    "section": "Data-Driven Passivity-Based Control of Robotic Locomotion and Manipulation",
    "text": "Data-Driven Passivity-Based Control of Robotic Locomotion and Manipulation\n\n\nUniversity of Texas at Dallas Seminar\n\n\n\n\nPresenter: Aykut Satici, Ph.D.Â  Mechanical and Biomedical Engineering  Boise State University, Boise, Idaho, USA\n\n\nGraduate Students:  Chris Dagher ğŸ“  Wankun Sirichotiyakul ğŸ“  Nardos Ayele Ashenafi ğŸ“"
  },
  {
    "objectID": "main.html#hybrid-systems",
    "href": "main.html#hybrid-systems",
    "title": "main",
    "section": "Hybrid Systems",
    "text": "Hybrid Systems\n\n\nExhibit both continuous state flow and discrete state transitions\n\n\n\n\nExamples: room temperature control, contact-rich robots\n\n\n\n\nWe tackle two main challenges in the control of contact-rich robots\n\n\n\n\n\n\n\n\nWalking machines\n\n\n\n\n\n\n\n\nManipulators"
  },
  {
    "objectID": "main.html#challenge-1-mode-changes",
    "href": "main.html#challenge-1-mode-changes",
    "title": "main",
    "section": "Challenge 1: Mode Changes",
    "text": "Challenge 1: Mode Changes\n\n\n\n\n\n\n\n\n\n\nContacts cause instantaneous changes in the dynamics and states.\nPotential contacts grow exponentially, making controller inference difficult."
  },
  {
    "objectID": "main.html#challenge-1-proposed-method",
    "href": "main.html#challenge-1-proposed-method",
    "title": "main",
    "section": "Challenge 1: Proposed Method",
    "text": "Challenge 1: Proposed Method\n \n\nOur method uses data-driven technique to automatically learn a mixture of expert controller and the switching conditionals.\n\n\n\nWe infer contact-aware controllers by training on trajectories generated from contact models.\n\nContact-aware controllers minimize the adverse effects of contacts or even take advantage of them."
  },
  {
    "objectID": "main.html#challenge-2-operating-under-uncertain-conditions",
    "href": "main.html#challenge-2-operating-under-uncertain-conditions",
    "title": "main",
    "section": "Challenge 2: Operating under Uncertain Conditions",
    "text": "Challenge 2: Operating under Uncertain Conditions"
  },
  {
    "objectID": "main.html#challenge-2-existing-methods",
    "href": "main.html#challenge-2-existing-methods",
    "title": "main",
    "section": "Challenge 2: Existing Methods",
    "text": "Challenge 2: Existing Methods\n\n\n\n\n\nReinforcement learning \n\n\nÂ \n\n\n\nStrengths\n\nMore general\nUnknown dynamics OK\n\nWeaknesses\n\nSample complexity\nStability guarantees?\n\n\n\n\n\n\n\n\n\n\nBayesian Neural Passivity-based Control \n\n\nÂ \n\n\n\nStrengths\n\nStability guarantees\nClosed-form policy\nReasons about model uncertainties"
  },
  {
    "objectID": "main.html#robustness-via-bayesian-learning",
    "href": "main.html#robustness-via-bayesian-learning",
    "title": "main",
    "section": "Robustness via Bayesian Learning",
    "text": "Robustness via Bayesian Learning\n\n\n\n\n\n\nSystem Parameter Uncertainty and Measurement Noise\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLess robust\n\n\n\n\n\n\n\n\n\n\n\nMore robust"
  },
  {
    "objectID": "main.html#mixture-of-experts-moe-old-faithful",
    "href": "main.html#mixture-of-experts-moe-old-faithful",
    "title": "main",
    "section": "Mixture of Experts (MOE): Old Faithful",
    "text": "Mixture of Experts (MOE): Old Faithful\n\nObjective: learn two expert Gaussian models that represent dataset ğ”»={(x1,y1),â€¦,(xN,yN)}\\mathbb{D} = \\{(x_1, y_1), \\dots, (x_N, y_N) \\}\n\n\n\n\n\nThe experts are chosen as F(x;Î¸)={ğ’©1(Î¼1,Ïƒ1),ğ’©2(Î¼2,Ïƒ2)}Î¸={(Î¼1,Ïƒ1),(Î¼2,Ïƒ2)}\\begin{align*}\nF(x;\\theta) &= \\{\\mathcal{N}_1(\\mu_1, \\sigma_1), \\mathcal{N}_2(\\mu_2, \\sigma_2)\\} \\\\\n\\theta &= \\{(\\mu_1, \\sigma_1), (\\mu_2, \\sigma_2) \\}\n\\end{align*}\n\nPrediction is a weighted-average of experts\n\n\n\n\n\n\n\n\n\n\n\nThe gating network is a neural net ğ(x|Ïˆ)=[P1(x|Ïˆ),P2(x|Ïˆ)]\\mathbf{P}(x | \\psi) = [P_1(x | \\psi), P_2(x | \\psi) ]\n\nDivides the input space into partitions\n\n\n\n\n\nExpectation Maximization: maximizes log likelihood ln{P(ğ”»|Î¸,Ïˆ)}=âˆ‘j=1Nlnâˆ‘i=1NF12Ï€Ïƒi2exp(âˆ’12(yjâˆ’Î¼i)2Ïƒi2)Pi(xj,Ïˆ)\n\\ln \\{P(\\mathbb{D} | \\theta, \\psi) \\} = \\sum_{j=1}^{N} \\ln \\sum_{i=1}^{N_F} \\frac{1}{\\sqrt{2 \\pi \\sigma_i^2}} \\exp \\left( -\\frac{1}{2}\\frac{(y_j - \\mu_i)^2}{\\sigma_i^2} \\right) P_i(x_j, \\psi)"
  },
  {
    "objectID": "main.html#mixture-of-experts-controller-1",
    "href": "main.html#mixture-of-experts-controller-1",
    "title": "main",
    "section": "Mixture of Experts Controller",
    "text": "Mixture of Experts Controller\n\n\n\nObjective: learn contact-aware mixture of experts controller and a gating network\n\n\n\n\nAll the experts and the gating network are given by neural nets\nWe pose the search over the parameters Ïˆ,Î¸\\psi, \\theta as the following optimization problem\n\n\n\n\nOptimization Problem\n\n\nminimizeÏˆ,Î¸âˆ«0Tâ„“(x(t),u)â…†t,subject toM(q)â…†qÌ‡+h(x;Ïˆ,Î¸)â…†tâˆ’â…†R=0,u={Fi(x;Î¸i)|iâˆ¼Categorical(ğ(x|Ïˆ))}.\\begin{align*}\n    \\begin{aligned}\n        \\underset{\\psi, \\theta}{\\textrm{minimize}} \n        & & & \\int_0^T \\ell (x(t),u) \\dd t , \\\\%\n        \\textrm{subject to}\n        & & & M(q) \\dd \\dot{q} + h(x; \\psi, \\theta)\\dd t - \\dd R  = 0,\\\\%\n        & & & u = \\{F_i(x; \\theta_i) \\; | \\; i  \\sim \\text{Categorical} (\\mathbf{P}(x| \\psi)) \\}.\n    \\end{aligned}\n\\end{align*}"
  },
  {
    "objectID": "main.html#training",
    "href": "main.html#training",
    "title": "main",
    "section": "Training",
    "text": "Training\n\n\n\nTraining procedure:\n\nStart from initial parameters (Ïˆ,Î¸)(\\psi, \\theta)\nSample initial state x0x_0\nGenerate trajectories Ï•(x0,u,T)\\phi(x_0, u, T) using current parameters iâˆ¼Categorical(ğ(x|Ïˆ))u(x;Ïˆ,Î¸)=Fi(x;Î¸i)M(q)â…†qÌ‡+h(x;Ïˆ,Î¸)â…†tâˆ’â…†R=0 (Moreauâ€™s time stepping)\\begin{gather*}\ni  \\sim \\text{Categorical} (\\mathbf{P}(x| \\psi)) \\\\\nu(x; \\psi, \\theta) = F_i(x; \\theta_i) \\\\\nM(q) \\dd \\dot{q} + h(x; \\psi, \\theta) \\dd t - \\dd R  = 0 \\text{ (Moreau's time stepping)}\n\\end{gather*}\nAssign a running cost â„“\\ell to the trajectories based on performance\nUpdate parameters (Ïˆ,Î¸)(\\psi, \\theta) to minimize running cost"
  },
  {
    "objectID": "main.html#performance-objective",
    "href": "main.html#performance-objective",
    "title": "main",
    "section": "Performance Objective",
    "text": "Performance Objective\n\nminimizeÏˆ,Î¸âˆ«0Tâ„“(x(t),u)â…†t,subject toM(q)â…†qÌ‡+h(x;Ïˆ,Î¸)â…†tâˆ’â…†R=0,u={Fi(x;Î¸i)|iâˆ¼Categorical(ğ(x|Ïˆ))}.\\begin{align*}\n    \\begin{aligned}\n        \\underset{\\psi, \\theta}{\\textrm{minimize}} \n        & & & \\int_0^T \\ell (x(t),u) \\dd t , \\\\%\n        \\textrm{subject to}\n        & & & M(q) \\dd \\dot{q} + h(x; \\psi, \\theta)\\dd t - \\dd R  = 0,\\\\%\n        & & & u = \\{F_i(x; \\theta_i) \\; | \\; i  \\sim \\text{Categorical} (\\mathbf{P}(x| \\psi)) \\}.\n    \\end{aligned}\n\\end{align*}\n\n\nAccumulated loss: total quadratic loss from desired state x*x^* â„“(x,u)=12(xâˆ’x*)âŠ¤ğ’¬(xâˆ’x*)+12uâŠ¤â„›uğ’¬â‰»0,â„›â‰½0\\begin{gather*}\n\\ell(x, u) = \\frac{1}{2}(x - x^*)^\\top \\mathcal{Q} (x - x^*) + \\frac{1}{2} u^\\top \\mathcal{R} u \\\\\n\\mathcal{Q} \\succ 0, \\mathcal{R} \\succeq 0\n\\end{gather*}\n\n\n\nThe corresponding likelihood function is\n\n\n\nln{P(ğ”»|Î¸,Ïˆ)}=âˆ‘j=1Nlnâˆ‘i=1NF12Ï€Ïƒi2exp(âˆ’12(yjâˆ’Î¼i)2Ïƒi2)Pi(xj,Ïˆ)\n\\ln \\{P(\\mathbb{D} | \\theta, \\psi) \\} = \\sum_{j=1}^{N} \\ln \\sum_{i=1}^{N_F} \\frac{1}{\\sqrt{2 \\pi \\sigma_i^2}} \\exp \\left( -\\frac{1}{2}\\frac{(y_j - \\mu_i)^2}{\\sigma_i^2} \\right) P_i(x_j, \\psi)\n\n\n\nln{P(Ï•|Î¸,Ïˆ)}=âˆ‘t=0Tlnâˆ‘i=1NF12Ï€s2exp(âˆ’12â„“(x(t+Î”t),Fi)2s2)Pi(x(t),Ïˆ)\n\\ln \\{P(\\phi | \\theta, \\psi) \\} = \\sum_{t=0}^{T} \\ln \\sum_{i=1}^{N_F} \\frac{1}{\\sqrt{2 \\pi s^2}} \\exp \\left( -\\frac{1}{2}\\frac{\\ell (x(t+\\Delta t), F_i )^2}{s^2} \\right) P_i(x(t), \\psi)"
  },
  {
    "objectID": "main.html#state-sampling",
    "href": "main.html#state-sampling",
    "title": "main",
    "section": "State Sampling",
    "text": "State Sampling\nObjective: meet performance for various initial states"
  },
  {
    "objectID": "main.html#cartpole-with-wall-barriers",
    "href": "main.html#cartpole-with-wall-barriers",
    "title": "main",
    "section": "Cartpole with wall barriers",
    "text": "Cartpole with wall barriers\n\n\n\n\n\nNotice LQR fails due to the impact from the wall\nMOE controller training\n\nthere are three deep-net experts Fi(x;Î¸i)F_i(x;\\theta_i)\nthe gating network is also a neural net"
  },
  {
    "objectID": "main.html#results",
    "href": "main.html#results",
    "title": "main",
    "section": "Results",
    "text": "Results\n\nThe contact-aware MOE controller\n\nleverages the impacts from the wall\nswitches to a policy that rapidly brakes to assist in the catching process"
  },
  {
    "objectID": "main.html#conclusions",
    "href": "main.html#conclusions",
    "title": "main",
    "section": "Conclusions",
    "text": "Conclusions\n \n\nWe provide a data-driven control design that automatically learns several policies and the necessary switching scheme.\nThe framework leverages the switching controllers to stabilize the multi-modal dynamical system.\nThe gating network successsfully parameterizes the control-switching conditionals that achieves the desired performance."
  },
  {
    "objectID": "main.html#dissipativity",
    "href": "main.html#dissipativity",
    "title": "main",
    "section": "Dissipativity",
    "text": "Dissipativity\n\nA dynamical system\nÎ£:{xÌ‡=f(x,u)y=h(x,u)xâˆˆğ’³âŠ‚â„2n,uâˆˆğ’°âŠ‚â„m\n\\Sigma: \\quad\n\\begin{cases}\n  \\dot{x} &= f(x,u) \\\\\n  y &= h(x,u)\n\\end{cases}\n\\quad x \\in \\mathcal{X} \\subset \\mathbb{R}^{2n}, \\, u \\in \\mathcal{U} \\subset \\mathbb{R}^{m} \n\nis dissipative with respect to some supply rate ss if there exists a storage function â„‹:ğ’³â†’â„+\\mathcal{H}: \\mathcal{X} \\to \\mathbb{R}^{+} such that\nâ„‹(x(t1))â‰¤â„‹(x(t0))+âˆ«t0t1s(u(t),y(t))dt\n\\mathcal{H}\\left(  x(t_1) \\right) \\leq  \\mathcal{H}\\left(  x(t_0) \\right) + \\int_{t_0}^{t_1} s(u(t), y(t)) \\, \\text{d}t\n\nfor all x(t0)=x0x(t_0) = x_0, all input uu, and all t1â‰¥t0t_1 \\geq t_0"
  },
  {
    "objectID": "main.html#dissipativity-and-passivity",
    "href": "main.html#dissipativity-and-passivity",
    "title": "main",
    "section": "Dissipativity and Passivity",
    "text": "Dissipativity and Passivity\nâ„‹(x(t1))â‰¤â„‹(x(t0))+âˆ«t0t1s(u(t),y(t))dt\n\\mathcal{H}\\left(  x(t_1) \\right) \\leq  \\mathcal{H}\\left(  x(t_0) \\right) + \\int_{t_0}^{t_1} s(u(t), y(t)) \\, \\text{d}t\n\n\n\n\nDissipation Inequality\n\n\n\nStored energy at t1t_1 is at most equal to stored energy at t0t_0, plus externally supplied energy s(u,y)s(u,y).\nNo generation of energy, only internal dissipation.\nWith s(t)â‰¡0s(t) \\equiv 0, trajectories tend towards minimum of â„‹\\mathcal{H}.\n\n\n\n\n\n\n\nPassivity\n\n\nThe system Î£\\Sigma is passive if it is dissipative with supply rate\ns=uâŠ¤y.s = u^\\top y.\nIt is output strictly passive if it is dissipative with supply rate\ns=uâŠ¤yâˆ’Î´âˆ¥yâˆ¥2,Î´&gt;0.s = u^\\top y - \\delta \\lVert y \\rVert^2, \\; \\delta &gt; 0.\nIt is input strictly passive if it is dissipative with supply rate\ns=uâŠ¤yâˆ’Î´âˆ¥uâˆ¥2,Î´&gt;0.s = u^\\top y - \\delta \\lVert u \\rVert^2, \\; \\delta &gt; 0."
  },
  {
    "objectID": "main.html#stability-of-passive-systems",
    "href": "main.html#stability-of-passive-systems",
    "title": "main",
    "section": "Stability of Passive Systems",
    "text": "Stability of Passive Systems\n\nÎ£:{xÌ‡=f(x,u),f(0,0)=0,y=h(x,u),h(0,0)=0,\n\\Sigma: \\quad\n\\begin{cases}\n  \\dot{x} &= f(x,u), && f(0,0) = 0, \\\\\n  y &= h(x,u), && h(0,0) = 0,\n\\end{cases}\n\nuâŠ¤yâ‰¥â„‹Ì‡=âˆ‚â„‹âˆ‚xf(x,u),â„‹â‰¥0,yâ‰¡0âŸ¹xâ‰¡0u^{\\top} y \\geq \\dot{\\mathcal{H}} = \\frac{\\partial\\mathcal{H}}{\\partial x} f(x,u),\\quad \\mathcal{H} \\geq 0,\\quad y \\equiv 0 \\implies x \\equiv 0\n\n\n\nLemma (Khalil, 2002)\n\n\nThe origin of Î£\\Sigma is:\n\nstable if Î£\\Sigma is passive,\nasymptotically stable if Î£\\Sigma is output strictly passive,\nglobally asymptotically stable if Î£\\Sigma is output strictly passive and the storage function â„‹(x)â†’âˆ\\mathcal{H}(x) \\to \\infty as âˆ¥xâˆ¥â†’âˆ\\lVert x \\rVert \\to \\infty (radially unbounded)\n\n\n\n\n\n\nNotice that we only require that the function â„‹\\mathcal{H} be positive semidefinite and not necessarily positive definite as per usual Lyapunov conditions.\nObservability (detectability) ensures LaSalleâ€™s theorem works."
  },
  {
    "objectID": "main.html#passivity-based-control-pbc",
    "href": "main.html#passivity-based-control-pbc",
    "title": "main",
    "section": "Passivity-Based Control (PBC)",
    "text": "Passivity-Based Control (PBC)\n\nÎ£o:{xÌ‡=f(x)+g(x)u,y=h(x)\n\\Sigma_o: \\quad\n\\begin{cases}\n  \\dot{x} &= f(x) + g(x)u, \\\\\n  y &= h(x)\n\\end{cases}\n\nMain idea â€” Select u(x)=ues+udiu(x) = u_{es} + u_{di} that renders the closed-loop system passive.\nÎ£d:{xÌ‡=fd(x)+g(x)udi,fd:=f(x)+g(x)ues(x)yd=hd(x)\n\\Sigma_d: \\quad\n\\begin{cases}\n  \\dot{x} &= f_d(x) + g(x) u_{di}, \\quad f_d := f(x) + g(x) u_{es}(x) \\\\\n  y_d &= h_d(x)\n\\end{cases}\n\nControl problem is cast as a search for HdH_d and hdh_d s.t. HÌ‡dâ‰¤ydâŠ¤udi\\dot{H}_d \\leq y_d^\\top u_{di}"
  },
  {
    "objectID": "main.html#pbc-example---simple-pendulum",
    "href": "main.html#pbc-example---simple-pendulum",
    "title": "main",
    "section": "PBC Example - Simple Pendulum",
    "text": "PBC Example - Simple Pendulum\n\n\n\n\nSystem Dynamics\n\n\nH(q,p)=12Jâˆ’1p2+mgl(1âˆ’cosq)H(q,p) = \\frac{1}{2} J^{-1} p^2 + mgl (1 - \\cos q)\n[qÌ‡pÌ‡]=[âˆ’01âˆ’10][âˆ‡qHdâˆ‡pHd]+[0G]udi,y=qÌ‡\n\\begin{bmatrix} \\dot{q} \\\\ \\dot{p} \\end{bmatrix} = \n\\begin{bmatrix} \\phantom{-}0 & 1 \\\\ -1 & 0 \\end{bmatrix} \n\\begin{bmatrix} \\nabla_q H_{\\phantom{d}} \\\\ \\nabla_p H_{\\phantom{d}} \\end{bmatrix} +\n\\begin{bmatrix} 0 \\\\ G \\end{bmatrix} u_\\phantom{di},\n\\qquad y = \\dot{q}\n\n\nChoose u=ues+udiu = u_{es} + u_{di} that transforms system into a passive one with xâ‹†=(qâ‹†,0)x^\\star = (q^\\star, 0) \n\n\nGues=âˆ‡qHâˆ’âˆ‡qHd,Gudi=âˆ’GKDGâŠ¤âˆ‡pHdGu_{es} = \\nabla_q H  - \\nabla_q H_d , \\quad Gu_{di} = -GK_D G^\\top \\nabla_p H_d\n\n\n\n[qÌ‡pÌ‡]=[âˆ’01âˆ’10][âˆ‡qHdâˆ‡pHd]+[0G]udi,y=qÌ‡\n\\begin{bmatrix} \\dot{q} \\\\ \\dot{p} \\end{bmatrix} = \n\\begin{bmatrix} \\phantom{-}0 & 1 \\\\ -1 & 0 \\end{bmatrix} \n\\begin{bmatrix} \\nabla_q H_d \\\\ \\nabla_p H_d \\end{bmatrix} +\n\\begin{bmatrix} 0 \\\\ G \\end{bmatrix} u_{di},\n\\qquad y = \\dot{q}\n\n\n\n[qÌ‡pÌ‡]=[âˆ’01âˆ’1âˆ’GKDGâŠ¤][âˆ‡qHdâˆ‡pHd],y=qÌ‡\n\\begin{bmatrix} \\dot{q} \\\\ \\dot{p} \\end{bmatrix} = \n\\begin{bmatrix} \\phantom{-}0 & 1 \\\\ -1 & -G K_D G^\\top \\end{bmatrix} \n\\begin{bmatrix} \\nabla_q H_d \\\\ \\nabla_p H_d \\end{bmatrix},\n\\qquad y = \\dot{q}"
  },
  {
    "objectID": "main.html#pbc-example---simple-pendulum-1",
    "href": "main.html#pbc-example---simple-pendulum-1",
    "title": "main",
    "section": "PBC Example - Simple Pendulum",
    "text": "PBC Example - Simple Pendulum\n\n\n\n\nControl Synthesis via PBC\n\n\nChoose u=ues+udiu = u_{es} + u_{di} that transforms system into a passive one with xâ‹†=(qâ‹†,0)x^\\star =  (q^\\star, 0)\nGues=âˆ‡qHâˆ’âˆ‡qHd,Gudi=âˆ’GKDGâŠ¤âˆ‡pHdGu_{es} = \\nabla_q H  - \\nabla_q H_d , \\quad Gu_{di} = -GK_D G^\\top \\nabla_p H_d\n[qÌ‡pÌ‡]=[âˆ’01âˆ’1âˆ’GKDGâŠ¤][âˆ‡qHdâˆ‡pHd],y=qÌ‡\n\\begin{bmatrix} \\dot{q} \\\\ \\dot{p} \\end{bmatrix} = \n\\begin{bmatrix} \\phantom{-}0 & 1 \\\\ -1 & -G K_D G^\\top \\end{bmatrix} \n\\begin{bmatrix} \\nabla_q H_d \\\\ \\nabla_p H_d \\end{bmatrix},\n\\qquad y = \\dot{q}\n\n\nHd(q,p)=12Jâˆ’1p2+Vd(q),Vd(q)=12KP(qâˆ’qâ‹†)2H_d(q,p) = \\frac{1}{2} J^{-1} p^2 + V_d(q), \\quad V_d(q) = \\frac{1}{2} K_{P} \\left( q - q^\\star \\right)^2\n\n\n\nHÌ‡d=âˆ’KD(Jâˆ’1p)2=yâŠ¤udiâ‰¤0\\dot{H}_d = -K_D \\left( J^{-1} p \\right)^2 = y^\\top u_{di} \\leq 0\n\n\nu=âˆ’mglsin(x)âˆ’KP(qâˆ’qâ‹†)âˆ’KDqÌ‡\\boxed{u = -mgl\\sin(x) - K_P(q - q^\\star) - K_D \\dot{q}}"
  },
  {
    "objectID": "main.html#our-methods",
    "href": "main.html#our-methods",
    "title": "main",
    "section": "Our Methods",
    "text": "Our Methods\n\n\n\n\nÂ \n\n\n\n\n\nÂ \n\n\n\n\n\n\n\n\n\n\n\n\nNeuralPbc\nNeuralIdaPbc\n\n\n\n\nHdH_d neural net\nHdH_d quadratic in pp\n\n\nSample state space\nSample configuration space\n\n\nNo stability certificate\nStability certificate\n\n\nMore flexible\nAs applicable as IdaPbc"
  },
  {
    "objectID": "main.html#robustness-via-bayesian-learning-1",
    "href": "main.html#robustness-via-bayesian-learning-1",
    "title": "main",
    "section": "Robustness via Bayesian Learning",
    "text": "Robustness via Bayesian Learning\n\n\n\n\n\n\nSystem Parameter Uncertainty and Measurement Noise\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLess robust\n\n\n\n\n\n\n\n\n\n\n\nMore robust"
  },
  {
    "objectID": "main.html#system-parameter-uncertainty",
    "href": "main.html#system-parameter-uncertainty",
    "title": "main",
    "section": "System Parameter Uncertainty",
    "text": "System Parameter Uncertainty\n\n\n\nScalar control system\nUncertain drift vector field: pâˆ¼ğ’©(pÌ‚,Ïƒp2)p \\sim\n\\mathcal{N}(\\hat{p}, \\sigma_p^2).\nNo measurement uncertainty\n\n\n\n\n\n\nÎ£:{xÌ‡=px+u,u(x)=Î¸x,x(0)=1.\n\\Sigma: \\quad\n\\begin{cases}\n  \\dot{x} &= px + u, \\\\\n  u(x) &= \\theta x, \\\\\n  x(0) &= 1.\n\\end{cases}\n x(t)=e(p+Î¸)t.\n  x(t) = e^{(p+\\theta)t}."
  },
  {
    "objectID": "main.html#performance-index",
    "href": "main.html#performance-index",
    "title": "main",
    "section": "Performance Index",
    "text": "Performance Index\n\n\n\n\n\nÎ£:{xÌ‡=px+u,u(x)=Î¸x,x(0)=1.\n\\Sigma: \\quad\n\\begin{cases}\n  \\dot{x} &= px + u, \\\\\n  u(x) &= \\theta x, \\\\\n  x(0) &= 1.\n\\end{cases}\n x(t)=e(p+Î¸)t.\n  x(t) = e^{(p+\\theta)t}.\n\n\n\nÂ \n\n\n\n\n\nQuadratic performance index\n\nqâ‰¥0q \\geq 0, r&gt;0r &gt; 0\n\nTT: control horizon\n\n\n\nğ’¥=âˆ«0T(12qx(t)2+12ru(t)2)dt.\n\\mathcal{J} = \\int_0^T \\left( \\frac{1}{2}qx(t)^2 + \\frac{1}{2}ru(t)^2  \\right)dt."
  },
  {
    "objectID": "main.html#infinite-horizon-best-performance",
    "href": "main.html#infinite-horizon-best-performance",
    "title": "main",
    "section": "Infinite-Horizon Best Performance",
    "text": "Infinite-Horizon Best Performance\n\n\n\n\nğ’¥=âˆ«0T(12qx(t)2+12ru(t)2)dt.\n\\mathcal{J} = \\int_0^T \\left( \\frac{1}{2}qx(t)^2 + \\frac{1}{2}ru(t)^2  \\right)dt.\n ğ’¥Tâ†’âˆ=âˆ’14q+rÎ¸2p+Î¸.\n\\mathcal{J}_{T \\to \\infty} = -\\frac{1}{4}\\frac{q+r \\theta^2}{p+\\theta}.\n\n\n\nÂ \n\n\n\n\nSolve for Î¸\\theta that minimizes ğ’¥âˆ\\mathcal{J}_\\infty: Î¸â‹†=g(p):=âˆ’pâˆ’p2+qr\\theta^\\star = g(p) :=\n-p -\\sqrt{p^2+\\frac{q}{r}}.\n\n\n\n\n\n\n\nDeterministic\n\n\nÎ¸â‹†=g(pÌ‚):=âˆ’pÌ‚âˆ’pÌ‚2+qr\\theta^\\star = g(\\hat{p}) := -\\hat{p} -\\sqrt{\\hat{p}^2+\\frac{q}{r}}\n\n\n\n\n\nÂ \n\n\n\n\n\nProbabilistic\n\n\nfÎ¸â‹†(Î¸â‹†)=1Ïƒp2Ï€(12(1+qrÎ¸â‹†2))exp{âˆ’12Ïƒp2(q2rÎ¸â‹†âˆ’Î¸â‹†2âˆ’pÌ‚)2}\n\\begin{aligned}\nf_{\\theta^\\star}(\\theta^\\star) &= \\frac{1}{\\sigma_p \\sqrt{2\\pi}}\\left( \\\n\\frac{1}{2}\\left(1+\\frac{q}{r{\\theta^\\star}^2}\\right) \\right) \\\\\n&\\exp{\\left\\{ -\\frac{1}{2\\sigma_p^2}\\left( \\frac{q}{2r\\theta^\\star} -\n\\frac{\\theta^\\star}{2} - \\hat{p}  \\right)^2  \\right\\} }\n\\end{aligned}"
  },
  {
    "objectID": "main.html#infinite-horizon-best-performance-1",
    "href": "main.html#infinite-horizon-best-performance-1",
    "title": "main",
    "section": "Infinite-Horizon Best Performance",
    "text": "Infinite-Horizon Best Performance\n\n\n\n\n\n\n\nDeterministic\n\n\nÎ¸â‹†=g(pÌ‚):=âˆ’pÌ‚âˆ’pÌ‚2+qr\\theta^\\star = g(\\hat{p}) := -\\hat{p} -\\sqrt{\\hat{p}^2+\\frac{q}{r}}\n\n\n\n\n\nÂ \n\n\n\n\n\nProbabilistic\n\n\nfÎ¸â‹†(Î¸â‹†)=1Ïƒp2Ï€(12(1+qrÎ¸â‹†2))exp{âˆ’12Ïƒp2(q2rÎ¸â‹†âˆ’Î¸â‹†2âˆ’pÌ‚)2}\n\\begin{aligned}\nf_{\\theta^\\star}(\\theta^\\star) &= \\frac{1}{\\sigma_p \\sqrt{2\\pi}}\\left( \\\n\\frac{1}{2}\\left(1+\\frac{q}{r{\\theta^\\star}^2}\\right) \\right) \\\\\n&\\exp{\\left\\{ -\\frac{1}{2\\sigma_p^2}\\left( \\frac{q}{2r\\theta^\\star} -\n\\frac{\\theta^\\star}{2} - \\hat{p}  \\right)^2  \\right\\} }\n\\end{aligned}"
  },
  {
    "objectID": "main.html#conditional-expectation",
    "href": "main.html#conditional-expectation",
    "title": "main",
    "section": "Conditional Expectation",
    "text": "Conditional Expectation\n\n\nğ”¼[ğ’¥âˆ£p]=âˆ’14q+rÎ¸2p+Î¸[Î¸2Ïƒ2T+(1âˆ’e2T(p+Î¸))(1+12Î¸2Ïƒ2p+Î¸)]\n\\mathbb{E}[\\mathcal{J} \\mid p] =\n-\\frac{1}{4}\\frac{q+r\\theta^2}{p+\\theta}\\left[ \\theta^2 \\sigma^2 T +\n\\left(1-e^{2 T (p+\\theta)}\\right) \\left(1+\\frac{1}{2}\\frac{\\theta^2\n\\sigma^2}{p+\\theta}\\right) \\right]\n\n\n\n\n\n\nProof\n\n\nSubstituting the solution of the SDE into the performance measure yields\nğ’¥=âˆ’14q+rÎ¸2p+Î¸(1+e2T(p+Î¸))+(q+rÎ¸2)Î¸Ïƒâˆ«0Te(p+Î¸)tâˆ«0te(p+Î¸)(tâˆ’s)dWsdt+12(q+rÎ¸2)Î¸2Ïƒ2âˆ«0T(âˆ«0te(p+Î¸)(tâˆ’s)dWs)2dt\n\\begin{aligned} \\mathcal{J} =\n        & -\\frac{1}{4}\\frac{q+r\\theta^2}{p+\\theta}\\left(1 +\n        e^{2T(p+\\theta)}\\right) + \n        (q+r\\theta^2)\\theta\\sigma \\int_0^T\n        e^{(p+\\theta)t} \\int_0^t e^{(p+\\theta)(t-s)}dW_s\n        dt \\; + \\\\ &\\frac{1}{2}(q+r\\theta^2)\\theta^2\n        \\sigma^2 \\int_0^T \\left( \\int_0^t\n        e^{(p+\\theta)(t-s)} dW_s  \\right)^2 dt \n\\end{aligned}\n\nThe conditional expectation of this quantity given the system parameter pp under the distribution induced by the Wiener process may be computed in closed-form using Ito calculus.\nğ”¼W[ğ’¥âˆ£p]=âˆ’14q+rÎ¸2p+Î¸(1âˆ’e2T(p+Î¸))+(q+rÎ¸2)Î¸Ïƒâˆ«0Te(p+Î¸)tğ”¼W[âˆ«0te(p+Î¸)(tâˆ’s)dWs|p]dt+12(q+rÎ¸)2Î¸2Ïƒ2âˆ«0Tğ”¼W[(âˆ«0te(p+Î¸)(tâˆ’s)dWs)2|p]dt=âˆ’14q+rÎ¸2p+Î¸(1âˆ’e2T(p+Î¸))+12(q+rÎ¸2)Î¸2Ïƒ2âˆ«0T(âˆ«0te2(p+Î¸)(tâˆ’s)ds)dt=âˆ’14q+rÎ¸2p+Î¸(1âˆ’e2T(p+Î¸))+12(q+rÎ¸2)Î¸2Ïƒ2âˆ«0Tâˆ’12(p+Î¸)(1âˆ’e2T(p+Î¸))dt=âˆ’14q+rÎ¸2p+Î¸[Î¸2Ïƒ2T+(1âˆ’e2T(p+Î¸))(1+12Î¸2Ïƒ2p+Î¸)].\n\\begin{aligned} \n\\mathbb{E}_W\\left[\\mathcal{J} \\mid p \\right] &= -\\frac{1}{4}\\frac{q+r\\theta^2}{p+\\theta}\\left(1 - e^{2T(p+\\theta)}\\right) +\n        (q+r\\theta^2)\\theta\\sigma\\int_0^Te^{(p+\\theta)t}\\mathbb{E}_W\\left[\\int_0^t\n        e^{(p+\\theta)(t-s)} dW_s~\\Big\\rvert p\\right] dt + \\\\\n        &\\frac{1}{2}(q+r\\theta)^2\\theta^2\\sigma^2\\int_0^T\\mathbb{E}_W\\left[\\left(\\int_0^t\n        e^{(p+\\theta)(t-s)} dW_s \\right)^2~\\bigg\\rvert p\\right] dt \\\\\n        &=-\\frac{1}{4}\\frac{q+r\\theta^2}{p+\\theta}\\left(1 -\n        e^{2T(p+\\theta)}\\right) + \n        \\frac{1}{2}(q+r\\theta^2)\\theta^2\\sigma^2\\int_0^T\\left(\\int_0^t\n        e^{2(p+\\theta)(t-s)} ds \\right) dt \\\\ \n        &=-\\frac{1}{4}\\frac{q+r\\theta^2}{p+\\theta}\\left(1 - e^{2T(p+\\theta)}\\right) + \n        \\frac{1}{2}(q+r\\theta^2)\\theta^2\\sigma^2\\int_0^T\n        -\\frac{1}{2(p+\\theta)}\\left(1 - e^{2T(p+\\theta)}\\right) dt \\\\ \n        &=-\\frac{1}{4}\\frac{q+r\\theta^2}{p+\\theta} \\left[ \\theta^2 \\sigma^2 T +\n        \\left(1 - e^{2T(p+\\theta)}\\right) \\left(1 +\n        \\frac{1}{2}\\frac{\\theta^2\\sigma^2}{p+\\theta}\\right)\\right]. \n\\end{aligned}\n\n\nğŸŸ§"
  },
  {
    "objectID": "main.html#optimal-controller",
    "href": "main.html#optimal-controller",
    "title": "main",
    "section": "Optimal Controller",
    "text": "Optimal Controller\n\n\n\n\nOptimal controller |Î¸â‹†||\\theta^\\star| minimizing ğ”¼ğ’¥\\mathbb{E}\\mathcal{J}\n\n\n\nMinimal expected cost ğ”¼ğ’¥\\mathbb{E}\\mathcal{J}"
  },
  {
    "objectID": "main.html#optimal-controller-1",
    "href": "main.html#optimal-controller-1",
    "title": "main",
    "section": "Optimal Controller",
    "text": "Optimal Controller\n\n\n\n\n\nOptimal controller |Î¸â‹†||\\theta^\\star| minimizing ğ”¼ğ’¥\\mathbb{E}\\mathcal{J}\n\n\n\n\n\nMinimal expected cost ğ”¼ğ’¥\\mathbb{E}\\mathcal{J}\n\n\n\n\n\nOptimal control parameter a nontrivial function of Ïƒ\\sigma and Ïƒp\\sigma_p.\nBayesian learning strikes the right trade-off."
  },
  {
    "objectID": "main.html#robustness-via-bayesian-learning-2",
    "href": "main.html#robustness-via-bayesian-learning-2",
    "title": "main",
    "section": "Robustness via Bayesian Learning",
    "text": "Robustness via Bayesian Learning\n\n\n\n\n\nNeuralPbc assumes a nominal model xÌ‡=f(x,u)\\dot{x} = f(x, u)\nThe trained controller must not overfit on the observations generated from the nominal model\n\n\n\n\n\n\n\n\n\nOur method: HdH_d is a Bayesian neural network\n\nachieves the performance objective for samples Î¸âˆ¼P(Î¸|ğ”»)\\theta \\sim P(\\theta | \\mathbb{D})\nsearches for ensemble of parameters that meet the desired performance P(Î¸âˆ£ğ”»)=P(ğ”»âˆ£Î¸)âlikelihoodP(Î¸)âpriorâˆ«Î¸P(ğ”»âˆ£Î¸â€²)P(Î¸â€²)dÎ¸â€²âŸevidence.\n  P(\\theta \\mid \\mathbb{D}) = \\frac{\\overbrace{P(\\mathbb{D} \\mid\n  \\theta)}^{\\text{likelihood}}\\overbrace{P(\\theta)}^{\\text{prior}}}\n  {\\underbrace{\\int_\\theta P(\\mathbb{D} \\mid \\theta^\\prime)P(\\theta^\\prime)\n  d\\theta^\\prime}_{\\text{evidence}}}."
  },
  {
    "objectID": "main.html#training-stochastic-models",
    "href": "main.html#training-stochastic-models",
    "title": "main",
    "section": "Training Stochastic Models",
    "text": "Training Stochastic Models\n\n\n\n\n\n\nBayesian Inference\n\n\nmaximizeP(Î¸|ğ”»)P(ğ”»|Î¸)P(Î¸),subject toÎ¸âˆ¼P(Î¸|ğ”»),ğ”»={(x1,y1),â€¦,(xN,yN)}.\n\\begin{aligned}\n\\underset{P(\\theta | \\mathbb{D})}{\\text{maximize}} &&& P(\\mathbb{D} | \\theta) P(\\theta), \\\\\n\\text{subject to} &&\n& \\theta \\sim P(\\theta | \\mathbb{D}), \\\\\n&& \\mathbb{D} &= \\{(x_1, y_1), \\dots, (x_N, y_N) \\}.\n\\end{aligned}\n\n\n\n\n\n\n\n\n\n\nBayesian Inference\n\n\nmaximizeP(Î¸|ğ”»)âˆj=1Nğ’©(âˆ¥F(xj;Î¸)âˆ’yjâˆ¥|0,s1)ğ’©(âˆ¥Î¸âˆ’Î¸0âˆ¥|0,s2),subject toÎ¸âˆ¼P(Î¸|ğ”»),ğ”»={(x1,y1),â€¦,(xN,yN)}.\n\\begin{aligned}\n\\underset{P(\\theta | \\mathbb{D})}{\\text{maximize}} && \\prod_{j=1}^{N} \\mathcal{N}&(\\| F(x_j; \\theta) -  y_j \\| \\; | \\; 0, s_1) \\mathcal{N}(\\| \\theta - \\theta_0 \\| \\; | \\; 0, s_2), \\\\\n\\text{subject to} &&\n& \\theta \\sim P(\\theta | \\mathbb{D}), \\\\\n&& \\mathbb{D} &= \\{(x_1, y_1), \\dots, (x_N, y_N) \\}.\n\\end{aligned}\n\n\n\n\n\n\n\n\n\n\nBayesian Inference\n\n\nmaximizezâ„’(ğ”»,z)=ğ”¼Î¸âˆ¼Q[ln(P(ğ”»âˆ£Î¸)P(Î¸))âˆ’ln(Q(Î¸;z))],subject toÎ¸âˆ¼Q(Î¸;z),ğ”»={(x1,y1),â€¦,(xN,yN)}.\n\\begin{aligned}\n\\underset{z}{\\text{maximize}} && \\mathcal{L}(\\mathbb{D},z) &= \\mathbb{E}_{\\theta \\sim Q} \\left[\\ln(P(\\mathbb{D} \\mid \\theta)P(\\theta)) - \\ln(Q(\\theta;z)) \\right], \\\\\n\\text{subject to} &&\n& \\theta \\sim Q(\\theta;z), \\\\\n&& \\mathbb{D} &= \\{(x_1, y_1), \\dots, (x_N, y_N) \\}.\n\\end{aligned}\n\n\n\n\n\n\n\n\n\nVariational Inference: approximates the posterior P(Î¸|ğ”»)P(\\theta | \\mathbb{D}) with a pre-selected distribution Q(Î¸;z)Q(\\theta; z)\nObjective: collect NÎ¸N_\\theta samples from the current posterior Q(Î¸;z)Q(\\theta; z) and maximize Elbo â„’(ğ”»,z)=ğ”¼Î¸âˆ¼Q[ln(P(ğ”»âˆ£Î¸)P(Î¸))âˆ’ln(Q(Î¸;z))]\n\\mathcal{L}(\\mathbb{D},z) = \\mathbb{E}_{\\theta \\sim Q} \\left[\\ln(P(\\mathbb{D} \\mid \\theta)P(\\theta)) - \\ln(Q(\\theta;z)) \\right]"
  },
  {
    "objectID": "main.html#bayesian-neuralpbc-1",
    "href": "main.html#bayesian-neuralpbc-1",
    "title": "main",
    "section": "Bayesian NeuralPbc",
    "text": "Bayesian NeuralPbc\n\n\n\n\n\n\nNeuralPbc Optimization Problem\n\n\nminimizeÎ¸J(Ï•,uÎ¸)=ğ”¼x0âˆˆğ’ŸN[â„“(Ï•(x0,u,T),u)],subject to[qÌ‡pÌ‡]=[0Iâˆ’I0][âˆ‡qHâˆ‡pH]+[0Î©]uÎ¸,uÎ¸=Î©â€ (âˆ‡qHâˆ’âˆ‡qHdÎ¸).\n\\begin{aligned}\n\\underset{\\theta}{\\text{minimize}} && J(\\phi, u^\\theta) &= \\mathbb{E}_{x_0 \\in \\mathcal{D}_N}[ \\ell( \\phi(x_0, u, T), u) ], \\\\\n\\text{subject to} &&\n\\begin{bmatrix}\n  \\dot{q} \\\\ \\dot{p}\n\\end{bmatrix} &=\n\\begin{bmatrix}\n  0 & I \\\\ -I & 0\n\\end{bmatrix}\n\\begin{bmatrix} \\nabla_q H \\\\ \\nabla_p H \\end{bmatrix} + \n\\begin{bmatrix}\n  0 \\\\ \\Omega\n\\end{bmatrix} u^{\\theta},\n\\\\\n&& u^\\theta &= \\Omega^{\\dagger}(\\nabla_q H  - \\nabla_q H_d^\\theta).\n\\end{aligned}\n\n\n\n\n\n\n\n\n\nBayesian NeuralPbc Optimization Problem\n\n\nminimizezJ(Ï•,uÎ¸)=ğ”¼x0âˆˆğ’ŸN[â„“(Ï•(x0,u,T),u)],subject to[qÌ‡pÌ‡]=[0Iâˆ’I0][âˆ‡qHâˆ‡pH]+[0Î©]uÎ¸,uÎ¸=Î©â€ (âˆ‡qHâˆ’âˆ‡qHdÎ¸),Î¸âˆ¼Q(Î¸;z).\n\\begin{aligned}\n    \\underset{z}{\\text{minimize}} && J(\\phi, u^\\theta) &= \\mathbb{E}_{x_0 \\in \\mathcal{D}_N}[ \\ell( \\phi(x_0, u, T), u) ], \\\\\n    \\text{subject to} &&\n    \\begin{bmatrix}\n    \\dot{q} \\\\ \\dot{p}\n    \\end{bmatrix} &=\n    \\begin{bmatrix}\n    0 & I \\\\ -I & 0\n    \\end{bmatrix}\n    \\begin{bmatrix} \\nabla_q H \\\\ \\nabla_p H \\end{bmatrix} + \n    \\begin{bmatrix}\n    0 \\\\ \\Omega\n    \\end{bmatrix} u^{\\theta},\n    \\\\\n    && u^\\theta &= \\Omega^{\\dagger}(\\nabla_q H  - \\nabla_q H_d^\\theta),\\\\\n    && \\theta &\\sim Q(\\theta; z).\n\\end{aligned} \n\n\n\n\n\n\n\n\nThe parameter zz of the posterior Q(Î¸;z)Q(\\theta;z) is inferred from running cost J(Ï•,uÎ¸)J(\\phi, u^\\theta)\nHdÎ¸H_d^\\theta is a Bayesian neural network (BNN)"
  },
  {
    "objectID": "main.html#uncertainty-modeling",
    "href": "main.html#uncertainty-modeling",
    "title": "main",
    "section": "Uncertainty Modeling",
    "text": "Uncertainty Modeling\n\nWe provide more structure to the variance of the Bayesian controllers\n\n\n\n\nBayesian NeuralPbc Optimization Problem\n\n\nminimizezJ(Ï•,uÎ¸)=ğ”¼x0âˆˆğ’ŸN[â„“(Ï•(x0,u,T),u)],subject toâ…†x=([âˆ’âˆ‡pHâˆ’âˆ‡qH]+[0Î©]uÎ¸(x))â…†t+âˆ‡xu(x)â…†Wt,uÎ¸=Î©â€ (âˆ‡qHâˆ’âˆ‡qHdÎ¸),Î¸âˆ¼Q(Î¸;z),psâˆ¼ğ’©(pÌ‚s,Ïƒp).\n\\begin{aligned}\n    \\underset{z}{\\text{minimize}} && J(\\phi, u^\\theta) &= \\mathbb{E}_{x_0 \\in \\mathcal{D}_N}[ \\ell( \\phi(x_0, u, T), u) ], \\\\\n    \\text{subject to} &&\n    \\dd x &= \\left(\n        \\begin{bmatrix}\\phantom{-}\\nabla_p H \\\\-\\nabla_q H \\end{bmatrix} + \\begin{bmatrix} 0 \\\\ \\Omega \\end{bmatrix} u^{\\theta}(x) \\right) \\dd t + \\nabla_x u(x) \\dd W_t, \\\\\n    && u^\\theta &= \\Omega^{\\dagger}(\\nabla_q H  - \\nabla_q H_d^\\theta),\\\\\n    && \\theta &\\sim Q(\\theta; z), \\\\\n    && p_s &\\sim \\mathcal{N}(\\hat{p}_s, \\sigma_p).\n\\end{aligned} \n\n\n\n\n\nObjective: maximize Elbo\n\nâ„’(J,z)=ğ”¼Î¸âˆ¼Q[ln(P(Jâˆ£Î¸)P(Î¸))âˆ’ln(Q(Î¸;z))]P(J|Î¸)=ğ’©(J|0,s).\\begin{gather*}\n  \\mathcal{L}(J,z) = \\mathbb{E}_{\\theta \\sim Q} \\left[\\ln(P(J \\mid \\theta)P(\\theta)) - \\ln(Q(\\theta;z)) \\right] \\\\ \n  P(J | \\theta) = \\mathcal{N}(J \\; | \\; 0, s).\n\\end{gather*}"
  },
  {
    "objectID": "main.html#neuralpbc-hybrid-system",
    "href": "main.html#neuralpbc-hybrid-system",
    "title": "main",
    "section": "NeuralPbc: Hybrid System",
    "text": "NeuralPbc: Hybrid System\n\n\n\n\n\n\n\nPassive Smooth System\n\n\nH(x(t1))â‰¤H(x(t0))+âˆ«t0t1s(u(t),y(t))dt\nH\\left(  x(t_1) \\right) \\leq  H\\left(  x(t_0) \\right) + \\int_{t_0}^{t_1} s(u(t), y(t)) \\, \\text{d}t\n\n\n\n\n\n\nÂ \n\n\n\n\n\nPassive Hybrid System\n\n\nH(x(t1))â‰¤H(x(t0))+âˆ«t0t1s(u(t),y(t))dtH(x+)â‰¤H(xâˆ’)\\begin{gather*}\nH\\left(  x(t_1) \\right) \\leq  H\\left(  x(t_0) \\right) + \\int_{t_0}^{t_1} s(u(t), y(t)) \\, \\text{d}t \\\\\nH(x^+) \\leq H(x^-)\n\\end{gather*}\n\n\n\n\n\n\n\n\n\n\nNeuralPbc for contact-rich system\n\n\nminimizeÎ¸J(Ï•,uÎ¸)=ğ”¼x0âˆˆğ’ŸN[â„“(Ï•(x0,u,T),u)],subject toM(q)â…†qÌ‡+h(q,qÌ‡,Î¸)â…†tâˆ’â…†R=0,uÎ¸=Î©â€ (âˆ‡qHâˆ’âˆ‡qHd).\\begin{aligned}\n    \\underset{\\theta}{\\textrm{minimize}} \n    & & J(\\phi, u^\\theta) &= \\mathbb{E}_{x_0 \\in \\mathcal{D}_N}[ \\ell( \\phi(x_0, u, T), u) ], \\\\%\n    \\textrm{subject to}\n    & & M(q) &\\dd \\dot{q} + h(q, \\dot{q}, \\theta)\\dd t - \\dd R  = 0,\\\\%\n    & & u^{\\theta} &= \\Omega^{\\dagger}(\\nabla_q H  - \\nabla_q H_d).%\n\\end{aligned}"
  },
  {
    "objectID": "main.html#bayesian-neuralpbc-hybrid-system",
    "href": "main.html#bayesian-neuralpbc-hybrid-system",
    "title": "main",
    "section": "Bayesian NeuralPbc: Hybrid System",
    "text": "Bayesian NeuralPbc: Hybrid System\n\n\n\nNeuralPbc for contact-rich system\n\n\nminimizezJ(Ï•,u)=ğ”¼x0âˆˆğ’ŸN[â„“(Ï•(x0,uÎ¸,T),uÎ¸)],subject toM(q)â…†qÌ‡+h(q,qÌ‡,Î¸)â…†tâˆ’â…†R=0,uÎ¸=Î©â€ (âˆ‡qHâˆ’âˆ‡qHdÎ¸),psâˆ¼ğ•Œ(pmin,pmax),Î¸âˆ¼Q(Î¸;z).\\begin{aligned}\n    \\underset{z}{\\textrm{minimize}} \n    & & & J(\\phi, u) = \\mathbb{E}_{x_0 \\in \\mathcal{D}_N}[\\ell(\\phi(x_0, u^\\theta, T), u^\\theta)], \\\\\n    \\textrm{subject to}\n    & & M(q) &\\dd \\dot{q} + h(q, \\dot{q}, \\theta)\\dd t - \\dd R  = 0,\\\\\n    & & u^{\\theta} &= \\Omega^{\\dagger}(\\nabla_q H  - \\nabla_q H_d^\\theta), \\\\\n    & & p_s &\\sim \\mathbb{U}(p_{min}, p_{max}), \\\\\n    & & \\theta &\\sim Q(\\theta; z).\n\\end{aligned}"
  },
  {
    "objectID": "main.html#deterministic-vs.-bayesian",
    "href": "main.html#deterministic-vs.-bayesian",
    "title": "main",
    "section": "Deterministic vs.Â Bayesian",
    "text": "Deterministic vs.Â Bayesian\n\n\n\n\n\n\n\n\n\n\n\nSubtracting rings from the wheel\n\ndecreases wheel mass\ndecreases wheel and pendulum inertia\nmoves the center of mass"
  },
  {
    "objectID": "main.html#rimless-wheel",
    "href": "main.html#rimless-wheel",
    "title": "main",
    "section": "Rimless Wheel",
    "text": "Rimless Wheel\n\n\nPerformance objective: achieve hip speed xÌ‡c*=1\\dot{x}_c^* = 1m/s JT=âˆ‘t=0Tâˆ¥xÌ‡c*âˆ’xÌ‡c(t;Î¸)âˆ¥\\begin{align*}\n  J_T = \\sum_{t=0}^{T} \\| \\dot{x}_c^* - \\dot{x}_c(t; \\theta) \\|\n\\end{align*}\nUncertainty in elevation under each spoke psâˆ¼ğ•Œ(0cm,2cm)\np_s \\sim \\mathbb{U}(0 \\textrm{cm}, 2\\textrm{cm})"
  },
  {
    "objectID": "main.html#deterministic-vs-bayesian",
    "href": "main.html#deterministic-vs-bayesian",
    "title": "main",
    "section": "Deterministic vs Bayesian",
    "text": "Deterministic vs Bayesian\n\n\n\n\n\n\n\n\npsâˆ¼ğ•Œ(0,pmax)pmax=[0,0.5,1,1.5,2]cmJT=âˆ‘t=0Tâˆ¥xÌ‡c*âˆ’xÌ‡c(t;Î¸)âˆ¥\\begin{align*}\np_s &\\sim \\mathbb{U}(0, p_{max})  \\\\\np_{max} &= [0, 0.5, 1, 1.5, 2] \\textrm{cm} \\\\\nJ_T &= \\sum_{t=0}^{T} \\| \\dot{x}_c^* - \\dot{x}_c(t; \\theta) \\|\n\\end{align*}"
  },
  {
    "objectID": "main.html#conclusions-1",
    "href": "main.html#conclusions-1",
    "title": "main",
    "section": "Conclusions",
    "text": "Conclusions\n \n\n\nMOE controller: multi-modal controller for multi-modal dynamics\nNeuralPbc + Bayesian inference = robust controller with stability properties"
  },
  {
    "objectID": "main.html#future-work",
    "href": "main.html#future-work",
    "title": "main",
    "section": "Future work",
    "text": "Future work\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) State partition according to NN\n\n\n\n\n\n\n\n\n\n\n\n(b) Experimental set up\n\n\n\n\n\n\n\nFigureÂ 1: NSF Award #2330794"
  },
  {
    "objectID": "main.html#acknowledgments",
    "href": "main.html#acknowledgments",
    "title": "main",
    "section": "Acknowledgments",
    "text": "Acknowledgments"
  },
  {
    "objectID": "main.html#neuralpbc-publications",
    "href": "main.html#neuralpbc-publications",
    "title": "main",
    "section": "NeuralPbc Publications",
    "text": "NeuralPbc Publications\n\nThis work is published in ISER 20201, CCTA 20212\nW. Sirichotiyakul and A. C. Satici, â€œData-driven design of energy-shaping controllers for swing-up control of underactuated robots,â€ in International Symposium on Experimental Robotics. Springer, 2020, pp.Â 323-333.W. Sirichotiyakul and A. C. Satici, â€œCombining energy-shaping control of dynamical systems with data-driven approaches,â€ in 2021 IEEE Conference on Control Technology and Applications (CCTA). IEEE, 2021, pp.Â 1121-1127."
  },
  {
    "objectID": "main.html#neuralpbc-publications-1",
    "href": "main.html#neuralpbc-publications-1",
    "title": "main",
    "section": "NeuralPbc Publications",
    "text": "NeuralPbc Publications\n\nThis work also provides a foundation for an ongoing research that investigate the improvement of robustness properties of NeuralPbc1,2\nW. Sirichotiyakul, N. A. Ashenafi, and A. C. Satici, â€œRobust Data-Driven Passivity-Based Control of Underactuated Systems via Neural Approximators and Bayesian Inference,â€ in 2022 American Control Conference, ACC. IEEE, Accepted for publication January 2022.N. A. Ashenafi, W. Sirichotiyakul, and A. C. Satici, â€œRobust Passivity-Based Control of Underactuated Systems via Neural Approximators and Bayesian In ference,â€ in 2022 Conference on Decision and Control, CDC. IEEE. (Submitted for review March 2022)."
  },
  {
    "objectID": "main.html#neuralidapbc-publications",
    "href": "main.html#neuralidapbc-publications",
    "title": "main",
    "section": "NeuralIdaPbc Publications",
    "text": "NeuralIdaPbc Publications\n\nThis work is published in the International Journal of Control1\nÂ \nNeuralIdaPbc is the basis for an ongoing research that investigate the improvement of robustness properties2\nW. Sirichotiyakul and A. C. Satici, â€œData-Driven Passivity-Based Control of Underactuated Mechanical Systems via Interconnection and Damping Assignment,â€ in International Journal of Control. (Accepted for publication March 2022)W. Sirichotiyakul, N. A. Ashenafi, and A. C. Satici, â€œRobust Interconnection and Damping Assignment Passivity-Based Control via Neural Bayesian Inference,â€ in IEEE Transactions on Automatic Control. (Submitted for review April 2022)"
  },
  {
    "objectID": "main.html#diffeqflux.jl-demo",
    "href": "main.html#diffeqflux.jl-demo",
    "title": "main",
    "section": "DiffEqFlux.jl Demo",
    "text": "DiffEqFlux.jl Demo\n\nLearning xÌ‡=f(x)\\dot{x} = f(x) where ff is a neural network\nRegress on MSE between trajectory of ff and data"
  },
  {
    "objectID": "main.html#neuralidapbc-main-problem",
    "href": "main.html#neuralidapbc-main-problem",
    "title": "main",
    "section": "NeuralIdaPbc Main Problem",
    "text": "NeuralIdaPbc Main Problem\n\nminimizeÎ¸J(Î¸)=âˆ¥GâŠ¥{âˆ‡qHâˆ’MdÎ¸Mâˆ’1âˆ‡qHdÎ¸+J2Î¸(MdÎ¸)âˆ’1p}âˆ¥2subject toHdÎ¸=12pâŠ¤(MdÎ¸)âˆ’1p+VdÎ¸(q)MdÎ¸(q)=(MdÎ¸(q))âŠ¤â‰»0J2Î¸(q,p)=âˆ’(J2Î¸(q,p))âŠ¤qâ‹†=argminqVdÎ¸(q)\\begin{aligned} \\underset{\\theta}{\\text{minimize}} && J(\\theta) &= \\left\\lVert G^{\\bot} \\left\\{ \\nabla_{q} H - M_{d}^{\\theta}M^{-1} \\nabla_{q} H_{d}^{\\theta} + J_{2}^{\\theta} \\left(M_{d}^{\\theta}\\right)^{-1} p \\right\\} \\right\\rVert^2  \\\\ \\text{subject to}  && H_d^{\\theta} &= \\frac{1}{2} p^{\\top} \\left( M_{d}^{\\theta} \\right)^{-1} p + V_{d}^{\\theta}(q) \\\\ && M_d^{\\theta}(q) &= \\left(M_d^{\\theta}(q)\\right)^\\top \\succ 0 \\\\ && J_{2}^{\\theta}(q,p) &= -\\left(J_{2}^{\\theta}(q,p)\\right)^\\top \\\\ && q^\\star &= \\underset{q}{\\arg \\min} \\, V_{d}^{\\theta} (q) \\end{aligned}\n\n\n\n\n\n\nNeuralIdaPbc\n\n\n\nSolve nonlinear PDEs using neural networks and SoS polynomials\nSurrogates of MdM_d, J2J_2, VdV_d are constrained by construction\n\n\n\n\n\n\n\n\n\n\nPinn\n\n\n\nSolve nonlinear PDEs using neural networks\nSolution surrogates are constrained via penalty term in loss function"
  },
  {
    "objectID": "main.html#sos-polynomials",
    "href": "main.html#sos-polynomials",
    "title": "main",
    "section": "SoS Polynomials",
    "text": "SoS Polynomials\n\nIs p(x)p(x) nonnegative for all xx? p(x)=4x12+x1x2âˆ’4x22âˆ’2.1x14+4x24+13x16+1.0316p(x) = 4x_1^2 + x_1x_2 - 4x_2^2 - 2.1x_1^4 + 4x_2^4 + \\frac{1}{3}x_1^6 + 1.0316\\;\n\np(x)=(0.116x12+0.01x1x2âˆ’2x22+1.015)2+(âˆ’0.569x13+1.938x1+0.244x2)2+(0.224x12+0.666x1x2+0.029x22+0.026)2+(âˆ’0.188x12+0.063x1x2âˆ’0.006x22+0.009)2+(0.099x13+0.029x1+0.004x2)2+(0.009x12x2)2\\begin{aligned} p(x) = &\\left(0.116x_1^2 + 0.01x_1x_2 - 2x_2^2 + 1.015\\right)^2 \\\\ & + \\; \\left(-0.569x_1^3 + 1.938x_1 + 0.244x_2\\right)^2 \\\\ & + \\; \\left(0.224x_1^2 + 0.666x_1x_2 + 0.029x_2^2 + 0.026\\right)^2 \\\\ & + \\; \\left(-0.188x_1^2 + 0.063x_1x_2 - 0.006x_2^2 + 0.009\\right)^2 \\\\ & + \\; \\left(0.099x_1^3 + 0.029x_1 + 0.004x_2\\right)^2 + \\left(0.009x_1^2x_2\\right)^2 \\end{aligned}\n\n\n\n\nData-Driven Passivity-Based Control â€¢ Aykut C. Satici"
  }
]