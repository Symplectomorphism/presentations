[
  {
    "objectID": "main.html#robust-sensing-and-learning-control-of-contact-rich-robots",
    "href": "main.html#robust-sensing-and-learning-control-of-contact-rich-robots",
    "title": "main",
    "section": "Robust Sensing and Learning Control of Contact-Rich Robots",
    "text": "Robust Sensing and Learning Control of Contact-Rich Robots\n\n\n\n UT Dallas Seminar\n\n\n\n\n\n\n\n\n\n\n\n\nPresenter:  Aykut Satici, Ph.D.  Associate Professor  Director, Robot Control Lab  Mechanical and Biomed. Eng.  Boise, Idaho, USA\n\n\n\n\n\n\n\n\n\nGraduate Students:  Wankun Sirichotiyakul 🎓  Nardos Ayele Ashenafi 🎓  Alex Peterson 🎓  Chandika Silva 🎓  Chris Dagher 🎓"
  },
  {
    "objectID": "main.html#sabanci-university-rehabilitation-robotics",
    "href": "main.html#sabanci-university-rehabilitation-robotics",
    "title": "main",
    "section": "Sabanci University: Rehabilitation Robotics",
    "text": "Sabanci University: Rehabilitation Robotics"
  },
  {
    "objectID": "main.html#ut-dallas-multi-robot-cooperation-and-geometric-control",
    "href": "main.html#ut-dallas-multi-robot-cooperation-and-geometric-control",
    "title": "main",
    "section": "UT Dallas: Multi-Robot Cooperation and Geometric Control",
    "text": "UT Dallas: Multi-Robot Cooperation and Geometric Control"
  },
  {
    "objectID": "main.html#university-of-naples-federico-ii-pb-and-geometric-control",
    "href": "main.html#university-of-naples-federico-ii-pb-and-geometric-control",
    "title": "main",
    "section": "University of Naples Federico II: PB and Geometric Control",
    "text": "University of Naples Federico II: PB and Geometric Control"
  },
  {
    "objectID": "main.html#massachusetts-institute-of-technology-soft-robotics",
    "href": "main.html#massachusetts-institute-of-technology-soft-robotics",
    "title": "main",
    "section": "Massachusetts Institute of Technology: Soft Robotics",
    "text": "Massachusetts Institute of Technology: Soft Robotics"
  },
  {
    "objectID": "main.html#boise-state-university-robust-data-driven-control-of-robotic-contact",
    "href": "main.html#boise-state-university-robust-data-driven-control-of-robotic-contact",
    "title": "main",
    "section": " Boise State University: Robust Data-Driven Control of Robotic Contact",
    "text": "Boise State University: Robust Data-Driven Control of Robotic Contact\n\n\n\nVideo\n\n\nVideo"
  },
  {
    "objectID": "main.html#loosening-up-chess-and-basketball",
    "href": "main.html#loosening-up-chess-and-basketball",
    "title": "main",
    "section": "Loosening up: Chess and Basketball",
    "text": "Loosening up: Chess and Basketball\n\n\n\n\nVideo"
  },
  {
    "objectID": "main.html#the-surge-in-reliance-upon-robotic-systems",
    "href": "main.html#the-surge-in-reliance-upon-robotic-systems",
    "title": "main",
    "section": "The Surge in Reliance Upon Robotic Systems",
    "text": "The Surge in Reliance Upon Robotic Systems\n\n\n\n\n\nWarehouse automation\n\n\n\n\nAutonomous vehicles\n\n\n\n\nDrones for first responders\n\n\n\n\nUtility drones\n\n\n\n\n\nRobotics becoming ever more ubiquitous, and increasing the requirement of robust sensing and control.\n\n\n\n\n\n\n\nVideo\n\n\n\nVideo\n\n\n\nVideo\n\n\n\n\nVideo"
  },
  {
    "objectID": "main.html#robustness-against-contact-under-uncertainty",
    "href": "main.html#robustness-against-contact-under-uncertainty",
    "title": "main",
    "section": "Robustness against Contact under Uncertainty",
    "text": "Robustness against Contact under Uncertainty\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n \n\n\n\n\n \n\n\n\n\n\n\n \n\n\n\n\nVideo"
  },
  {
    "objectID": "main.html#robustness-against-contact-under-uncertainty-1",
    "href": "main.html#robustness-against-contact-under-uncertainty-1",
    "title": "main",
    "section": "Robustness against Contact under Uncertainty",
    "text": "Robustness against Contact under Uncertainty"
  },
  {
    "objectID": "main.html#robustness-against-contact-under-uncertainty-2",
    "href": "main.html#robustness-against-contact-under-uncertainty-2",
    "title": "main",
    "section": "Robustness against Contact under Uncertainty",
    "text": "Robustness against Contact under Uncertainty"
  },
  {
    "objectID": "main.html#robustness-against-contact-and-uncertainty",
    "href": "main.html#robustness-against-contact-and-uncertainty",
    "title": "main",
    "section": "Robustness against Contact and Uncertainty",
    "text": "Robustness against Contact and Uncertainty\n\n\n\n\n\n\n\n\n\n\n\n\nNeed to design both robust state estimation and controllers.\nDomain randomization and Bayesian learning help for controller design.\nGTSAM and optimization over factor graphs help for state estimation."
  },
  {
    "objectID": "main.html#existing-vs.-proposed-control-synthesis-methods",
    "href": "main.html#existing-vs.-proposed-control-synthesis-methods",
    "title": "main",
    "section": "Existing vs. Proposed Control Synthesis Methods",
    "text": "Existing vs. Proposed Control Synthesis Methods\n\n\n\n\n\nReinforcement learning (similarly Decision Transformers) \n\n\n \n\n\n\nStrengths\n\nMore general\nUnknown dynamics OK\n\nWeaknesses\n\nSample complexity\nStability guarantees?\n\n\n\n\n\n\n\n\n\n\nBayesian Neural Passivity-based Control \n\n\n \n\n\n\nStrengths\n\nStability guarantees\nClosed-form policy\nReasons about model uncertainties"
  },
  {
    "objectID": "main.html#robustness-via-bayesian-learning",
    "href": "main.html#robustness-via-bayesian-learning",
    "title": "main",
    "section": "Robustness via Bayesian Learning",
    "text": "Robustness via Bayesian Learning\n\n\n\n\n\n\nSystem Parameter Uncertainty and Measurement Noise\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLess robust\n\n\n\n\n\n\n\n\n\n\n\nMore robust"
  },
  {
    "objectID": "main.html#robust-localization-w.r.t.-power-lines-in-sparse-environments",
    "href": "main.html#robust-localization-w.r.t.-power-lines-in-sparse-environments",
    "title": "main",
    "section": "Robust Localization w.r.t. Power Lines in Sparse Environments",
    "text": "Robust Localization w.r.t. Power Lines in Sparse Environments\n\n\n\nThe ground has a uniform texture.\nThere are too few utility poles or immediate fences.\nThere are no trees or other geometries.\nGPS provides absolute position, need relative pose to power lines!\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInsufficient landmarks\n\n\nAny vision-based estimation mechanism will not perform reliably and robustly for drone localization.\n\n\n\n\n\n\n\n\n\n\n\nElectromagnetic field around the power lines\n\n\nIf we can get reliable measurements, then we can devise a distance and bearing factor exploiting this field."
  },
  {
    "objectID": "main.html#electric-and-magnetic-field-around-three-phase-power-lines",
    "href": "main.html#electric-and-magnetic-field-around-three-phase-power-lines",
    "title": "main",
    "section": "Electric and Magnetic Field around Three-Phase Power Lines",
    "text": "Electric and Magnetic Field around Three-Phase Power Lines\n\n\n\n\n\nEM Field near Three-Phase Power Lines\n\n\nQuasi-static approximation to Maxwell’s equations yields (\\(\\mathbf{q} = (x, z)\\) is the location of the sensor)\n\\[\n\\bar{E}^2(\\mathbf{q}) = \\frac{1}{2}\\sum_{\\alpha=1}^3\\left(e_\\alpha^2 -\n\\sum_{\\alpha^\\prime &gt; \\alpha}^3 c_{\\alpha\\alpha^\\prime}e_\\alpha e_{\\alpha^\\prime} \\right),\n\\]\nwhere \\(e_\\alpha = \\frac{\\xi}{r_\\alpha} = \\frac{\\beta c \\mu_0 I_0}{2\\pi}\\frac{1}{r_\\alpha}\\) is the peak electric field magnitude and \\(c_{\\alpha\\alpha^\\prime} = \\cos{\\left(\\theta_\\alpha - \\theta_{\\alpha^\\prime}\\right)}\\).\n\n\n\n\n\n\n\n\n\n\n\n\n\nFrom total rms energy considerations, it can be shown that \\(\\bar{B} = \\sqrt{\\mu_0 \\varepsilon_0} \\bar{E}\\)."
  },
  {
    "objectID": "main.html#gradient-of-the-electric-field-around-three-phase-power-lines",
    "href": "main.html#gradient-of-the-electric-field-around-three-phase-power-lines",
    "title": "main",
    "section": "Gradient of the Electric Field around Three-Phase Power Lines",
    "text": "Gradient of the Electric Field around Three-Phase Power Lines\n\n\n\n\n\nGradient of the rms Electric Field\n\n\n\\[\\begin{align*}\n&\\nabla_{\\mathbf{q}} \\bar{E}(\\mathbf{q}) = 2\\bar{E}\\nabla_{\\mathbf{q}}\\bar{E} \\\\\n&\\phantom{12}= \\frac{1}{2\\xi}\\sum_{\\alpha=1}^3 e_\\alpha \\begin{bmatrix}\n  -2e_\\alpha^2c_\\alpha + \\sum_{\\alpha^\\prime \\neq \\alpha} e_{\\alpha^\\prime}^2 \\cos{\\left(\\theta_\\alpha - 2\\theta_{\\alpha^\\prime}\\right)}\\\\\n  2e_\\alpha^2c_\\alpha + \\sum_{\\alpha^\\prime \\neq \\alpha} e_{\\alpha^\\prime}^2 \\sin{\\left(\\theta_\\alpha - 2\\theta_{\\alpha^\\prime}\\right)}\n\\end{bmatrix}\n\\end{align*}\\]\n\n\n\n\n\n\nLemma: Direction of the gradient\n\n\nThe gradient \\(\\nabla_{\\mathbf{q}} \\bar{E}(\\mathbf{q})\\) points into the convex hull (triangle) formed by the transmission wires for every \\(\\mathbf{q}\\)."
  },
  {
    "objectID": "main.html#navigating-the-drone-to-one-of-the-power-lines",
    "href": "main.html#navigating-the-drone-to-one-of-the-power-lines",
    "title": "main",
    "section": "Navigating the Drone to One of the Power Lines",
    "text": "Navigating the Drone to One of the Power Lines\n\n\n\n\n\nPotential Function and its Gradient\n\n\nDefine the potential function \\(V(\\mathbf{q}) = \\frac{1}{\\bar{E}^2(\\mathbf{q})}\\). Its gradient is \\[\n\\nabla_{\\mathbf{q}}V(\\mathbf{q}) = -\\frac{2}{\\bar{E}^3}\\nabla_{\\mathbf{q}}\\bar{E}(\\mathbf{q})\n\\] Further, \\(\\lVert \\nabla_{\\mathbf{q}}V(\\mathbf{q}) \\rVert = O\\left(\\frac{1}{\\bar{E}}\\right)\\) as \\(\\bar{E} \\rightarrow \\infty\\) (or \\(r_\\alpha \\rightarrow 0\\)).\n\n\n\n\n\n\nLemma: Critical points of \\(V(\\mathbf{q})\\)\n\n\n\nGenerically \\(V\\) has \\(5\\) isolated critical points, \\(3\\) of which are global minima and have \\(r_\\alpha = 0\\).\nApplying Poincaré-Hopf theorem on the convex hull of the power lines yields the remaining 2 are saddle points!\n\n\n\n\n\n\n\n\n\nFollowing \\(\\nabla_{\\mathbf{q}}V(\\mathbf{q})\\) navigates the drone to one of the power lines."
  },
  {
    "objectID": "main.html#robust-localization-with-gtsam-sensor-fusion-library",
    "href": "main.html#robust-localization-with-gtsam-sensor-fusion-library",
    "title": "main",
    "section": "Robust Localization with GTSAM: Sensor Fusion Library",
    "text": "Robust Localization with GTSAM: Sensor Fusion Library\n\n\n\nFactors depict constaints on the poses as:\n\nprior state: \\(f_0(x_1)\\)\nodometry relation: \\(f_i(x_i, x_{i+1}; o_i)\\)\nobservations: \\(f_i(x_i;z_i)\\).\n\n\n\n\n\n\n\\[\n\\begin{aligned}\np(\\mathbf{x} | \\mathbf{o}) \\propto p(x_1) \\prod_{i=2}^{3} p(x_i | x_{i-1}, o_i)\\\\\n% f(\\mathbf{x}) = \\arg\\max_{\\mathbf{x}}  f_0(x_1) \\prod_{i=1}^{2} f_i(x_i, x_{i+1}; o_i)\n\\end{aligned}\n\\]\n\n\n\n\\[\n\\begin{aligned}\np(\\mathbf{x} | \\mathbf{o}, \\mathbf{z}) \\propto p(x_1) \\prod_{i=2}^{3} p(x_i | x_{i-1}, o_i) p(z_i | x_i) \\\\\n% f(\\mathbf{x}) = \\arg\\max_{\\mathbf{x}}  f_0(x_1) \\prod_{i=1}^{2} f_i(x_i, x_{i+1}; o_i)  g_i(x_i; z_i)\n\\end{aligned}\n\\]\n\n\n\n\\[\n\\begin{aligned}\np(\\mathbf{x} | \\mathbf{o}, \\mathbf{l}) \\propto p(x_1) \\prod_{i=2}^{3} p(x_i | x_{i-1}, o_i) p(l_i | x_i) \\\\\n% f(\\mathbf{x}) = \\arg\\max_{\\mathbf{x}}  f_0(x_1) \\prod_{i=1}^{2} f_i(x_i, x_{i+1}; o_i)  h_i(x_i; l_i)\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "main.html#gtsam-meets-gradient-of-the-electric-field",
    "href": "main.html#gtsam-meets-gradient-of-the-electric-field",
    "title": "main",
    "section": "GTSAM meets Gradient of the Electric Field",
    "text": "GTSAM meets Gradient of the Electric Field\n\n\n\n\n\n\\(\\nabla_{\\mathbf{q}}\\bar{E}(\\mathbf{q})\\) points towards the convex hull\n\n\nThe unit vector along this gradient may be used as a bearing factor in GTSAM at any point \\(\\mathbf{q}\\) during navigation!\n\nTurns the convex hull of the power lines into a landmark."
  },
  {
    "objectID": "main.html#stable-contact-and-manipulation-over-power-lines",
    "href": "main.html#stable-contact-and-manipulation-over-power-lines",
    "title": "main",
    "section": "Stable Contact and Manipulation over Power Lines",
    "text": "Stable Contact and Manipulation over Power Lines\n\n\n\n\nWe are implementing passivity-based controllers (data-driven or otherwise) for manipulation over power lines."
  },
  {
    "objectID": "main.html#dissipativity",
    "href": "main.html#dissipativity",
    "title": "main",
    "section": "Dissipativity",
    "text": "Dissipativity\n\n\n\n\n \n\n\n\n\nA dynamical system % \\[\n\\Sigma: \\quad\n\\begin{cases}\n  \\dot{x} &= f(x,u) \\\\\n  y &= h(x,u)\n\\end{cases}\n\\quad x \\in \\mathcal{X} \\subset \\mathbb{R}^{2n}, \\, u \\in \\mathcal{U} \\subset \\mathbb{R}^{m}\n\\] is dissipative with respect to some supply rate \\(s\\) if there exists a storage function \\(\\mathcal{H}: \\mathcal{X} \\to \\mathbb{R}^{+}\\) such that % \\[\n\\mathcal{H}\\left(  x(t_1) \\right) \\leq  \\mathcal{H}\\left(  x(t_0) \\right) + \\int_{t_0}^{t_1} s(u(t), y(t)) \\, \\text{d}t\n\\] % for all \\(x(t_0) = x_0\\), all input \\(u\\), and all \\(t_1 \\geq t_0\\)."
  },
  {
    "objectID": "main.html#dissipativity-and-passivity",
    "href": "main.html#dissipativity-and-passivity",
    "title": "main",
    "section": "Dissipativity and Passivity",
    "text": "Dissipativity and Passivity\n\\[\n\\mathcal{H}\\left(  x(t_1) \\right) \\leq  \\mathcal{H}\\left(  x(t_0) \\right) + \\int_{t_0}^{t_1} s(u(t), y(t)) \\, \\text{d}t\n\\]\n\n\n\nDissipation Inequality\n\n\n\nStored energy at \\(t_1\\) is at most equal to stored energy at \\(t_0\\), plus externally supplied energy \\(s(u,y)\\).\nNo generation of energy, only internal dissipation.\n\n\n\n\n\n\n\n\nPassivity\n\n\nThe system \\(\\Sigma\\) is passive if it is dissipative with supply rate\n\\[s = u^\\top y.\\]\nIt is output strictly passive if it is dissipative with supply rate\n\\[s = u^\\top y - \\delta \\lVert y \\rVert^2, \\; \\delta &gt; 0.\\]"
  },
  {
    "objectID": "main.html#stability-of-passive-systems",
    "href": "main.html#stability-of-passive-systems",
    "title": "main",
    "section": "Stability of Passive Systems",
    "text": "Stability of Passive Systems\n\n\\[\n\\Sigma: \\quad\n\\begin{cases}\n  \\dot{x} &= f(x,u), && f(0,0) = 0, \\\\\n  y &= h(x,u), && h(0,0) = 0,\n\\end{cases}\n\\]\n\\(u^{\\top} y \\geq \\dot{\\mathcal{H}} = \\frac{\\partial\\mathcal{H}}{\\partial x} f(x,u),\\quad \\mathcal{H} \\geq 0,\\quad y \\equiv 0 \\implies x \\equiv 0\\)\n\n\n\n \n\n\n\n\n\n\n\nLemma (Khalil, 2002)\n\n\nThe origin of \\(\\Sigma\\) is:\n\nstable if \\(\\Sigma\\) is passive,\nasymptotically stable if \\(\\Sigma\\) is output strictly passive,\nglobally asymptotically stable if \\(\\Sigma\\) is output strictly passive and the storage function \\(\\mathcal{H}(x) \\to \\infty\\) as \\(\\lVert x \\rVert \\to \\infty\\) (radially unbounded)\n\n\n\n\n\n\n\n\n\nNotice that we only require that the function \\(\\mathcal{H}\\) be positive semidefinite and not necessarily positive definite as per usual Lyapunov conditions.\nObservability (detectability) ensures LaSalle’s theorem works."
  },
  {
    "objectID": "main.html#passivity-based-control-pbc",
    "href": "main.html#passivity-based-control-pbc",
    "title": "main",
    "section": "Passivity-Based Control (PBC)",
    "text": "Passivity-Based Control (PBC)\n\n\n\n\n \n\n\n\n\n\\[\n\\Sigma_o: \\quad\n\\begin{cases}\n  \\dot{x} &= f(x) + g(x)u, \\\\\n  y &= h(x)\n\\end{cases}\n\\] % Main idea — Select \\(u(x) = u_{es} + u_{di}\\) that renders the closed-loop system passive. % \\[\n\\Sigma_d: \\quad\n\\begin{cases}\n  \\dot{x} &= f_d(x) + g(x) u_{di}, \\quad f_d := f(x) + g(x) u_{es}(x) \\\\\n  y_d &= h_d(x)\n\\end{cases}\n\\] % Control problem is cast as a search for \\(H_d\\) and \\(h_d\\) s.t. \\(\\dot{H}_d \\leq y_d^\\top u_{di}\\)"
  },
  {
    "objectID": "main.html#pbc-toy-example-simple-pendulum",
    "href": "main.html#pbc-toy-example-simple-pendulum",
    "title": "main",
    "section": "PBC Toy Example: Simple Pendulum",
    "text": "PBC Toy Example: Simple Pendulum\n\n\n\n\nSystem Dynamics\n\n\n\\(H(q,p) = \\frac{1}{2} J^{-1} p^2 + mgl (1 - \\cos q)\\)\n\\[\n\\begin{bmatrix} \\dot{q} \\\\ \\dot{p} \\end{bmatrix} =\n\\begin{bmatrix} \\phantom{-}0 & 1 \\\\ -1 & 0 \\end{bmatrix}\n\\begin{bmatrix} \\nabla_q H_{\\phantom{d}} \\\\ \\nabla_p H_{\\phantom{d}} \\end{bmatrix} +\n\\begin{bmatrix} 0 \\\\ G \\end{bmatrix} u_\\phantom{di},\n\\qquad y = \\dot{q}\n\\]\n\nChoose \\(u = u_{es} + u_{di}\\) that transforms system into a passive one with \\(x^\\star = (q^\\star, 0)\\) \n\n\n\\(Gu_{es} = \\nabla_q H  - \\nabla_q H_d , \\quad Gu_{di} = -GK_D G^\\top \\nabla_p H_d\\)\n\n\n\n\\[\n\\begin{bmatrix} \\dot{q} \\\\ \\dot{p} \\end{bmatrix} =\n\\begin{bmatrix} \\phantom{-}0 & 1 \\\\ -1 & 0 \\end{bmatrix}\n\\begin{bmatrix} \\nabla_q H_d \\\\ \\nabla_p H_d \\end{bmatrix} +\n\\begin{bmatrix} 0 \\\\ G \\end{bmatrix} u_{di},\n\\qquad y = \\dot{q}\n\\]\n\n\n\\[\n\\begin{bmatrix} \\dot{q} \\\\ \\dot{p} \\end{bmatrix} =\n\\begin{bmatrix} \\phantom{-}0 & 1 \\\\ -1 & -G K_D G^\\top \\end{bmatrix}\n\\begin{bmatrix} \\nabla_q H_d \\\\ \\nabla_p H_d \\end{bmatrix},\n\\qquad y = \\dot{q}\n\\]"
  },
  {
    "objectID": "main.html#pbc-toy-example-simple-pendulum-1",
    "href": "main.html#pbc-toy-example-simple-pendulum-1",
    "title": "main",
    "section": "PBC Toy Example: Simple Pendulum",
    "text": "PBC Toy Example: Simple Pendulum\n\n\n\n\nControl Synthesis via PBC\n\n\nChoose \\(u = u_{es} + u_{di}\\) that transforms system into a passive one with \\(x^\\star =  (q^\\star, 0)\\)\n\\(Gu_{es} = \\nabla_q H  - \\nabla_q H_d , \\quad Gu_{di} = -GK_D G^\\top \\nabla_p H_d\\)\n\\[\n\\begin{bmatrix} \\dot{q} \\\\ \\dot{p} \\end{bmatrix} =\n\\begin{bmatrix} \\phantom{-}0 & 1 \\\\ -1 & -G K_D G^\\top \\end{bmatrix}\n\\begin{bmatrix} \\nabla_q H_d \\\\ \\nabla_p H_d \\end{bmatrix},\n\\qquad y = \\dot{q}\n\\]\n\n\\(H_d(q,p) = \\frac{1}{2} J^{-1} p^2 + V_d(q), \\quad V_d(q) = \\frac{1}{2} K_{P} \\left( q - q^\\star \\right)^2\\)\n\n\n\n\\(\\dot{H}_d = -K_D \\left( J^{-1} p \\right)^2 = y^\\top u_{di} \\leq 0\\)\n\n\n\\(\\boxed{u = -mgl\\sin(x) - K_P(q - q^\\star) - K_D \\dot{q}}\\)"
  },
  {
    "objectID": "main.html#neuralpbc-problem-statement",
    "href": "main.html#neuralpbc-problem-statement",
    "title": "main",
    "section": "NeuralPbc Problem Statement",
    "text": "NeuralPbc Problem Statement\n\nConsider the mechanical system\n\\[\n\\begin{bmatrix} \\dot{q} \\\\ \\dot{p} \\end{bmatrix} =\n\\begin{bmatrix} \\phantom{-}0 & 1 \\\\ -1 & 0 \\end{bmatrix}\n\\begin{bmatrix} \\nabla_q H_{\\phantom{d}} \\\\ \\nabla_p H_{\\phantom{d}} \\end{bmatrix} +\n\\begin{bmatrix} 0 \\\\ G \\end{bmatrix} u_\\phantom{di}\n\\]\nControl task: stabilize desired equilibrium \\(x^\\star = (q^\\star, 0)\\)\n\n\n\\[u = u_{es} + u_{di} = G^{\\dagger} \\left( \\nabla_q H  - \\nabla_q H_d \\right)  - K_D G^\\top \\nabla_p H_d \\]\n\n\n\\[u = u_{es} + u_{di} = - G^{\\dagger} \\nabla_q H_d^{\\theta}  - K_D G^\\top \\nabla_p H_d^{\\theta} \\]\n\n\nChoosing a suitable \\(H_d\\) is not trivial\n\nParameterize \\(H_d\\) by a neural network \\(H_d^\\theta\\), and relax control task to bringing \\(x\\) to a small neighborhood of \\(x^\\star\\)\n\n\n\nInstead of asking for asymptotic stabilization, we only require that trajectories pass thru a nbhd of \\(x^\\star\\)\nThis is reasonable because we know how to stabilize a fixed point, e.g. stabilize the linearization of the system using LQR\nThis allows us to find approximations for \\(H_d^\\theta\\) using learning techniques"
  },
  {
    "objectID": "main.html#neuralpbc-techniques",
    "href": "main.html#neuralpbc-techniques",
    "title": "main",
    "section": "NeuralPbc Techniques",
    "text": "NeuralPbc Techniques\n\n\n\n\n\n\n\n\n\\[\n\\begin{aligned}\n\\underset{\\theta}{\\text{minimize}} && J(\\theta, x_0) &= \\int_{0}^{T} \\ell \\left(\\phi,u^\\theta,\\theta\\right)\\, \\text{d} t \\\\\n\\text{subject to} &&\n\\begin{bmatrix}\n  \\dot{q} \\\\ \\dot{p}\n\\end{bmatrix} &=\n\\begin{bmatrix}\n  0 & I \\\\ -I & 0\n\\end{bmatrix}\n\\begin{bmatrix} \\nabla_q H \\\\ \\nabla_p H \\end{bmatrix} +\n\\begin{bmatrix}\n  0 \\\\ G\n\\end{bmatrix} u^{\\theta}\n\\\\\n&& u^\\theta &= - G^{\\dagger}\\nabla_q H_d^{\\theta}  - K_D G^\\top \\nabla_p H_d^{\\theta}\n\\end{aligned}\n\\]\n\n\n\n\n\nInjecting control task into loss function design\n\n\n\nMay require an initial motion/path planning step\n\n\nFor simple tasks, can just be quadratic loss to goal\n\n\n\nBackprop through closed-loop trajectories\n\n\n\nForward or adjoint differentiation\n\n\nTypically adjoint differentiation is more efficient\n\n\n\nSampling the state space efficiently\n\n\n\nDAgger sampling\n\n\nInitial conditions chosen from previously visited states\n\n\n\n\n\n\n\n\n\n\nPenalize states away from a desired ball.\n\n\n\n\n\nPenalize nonzero transverse coordinates.\n\n\n\n\nWe need \\(\\partial J / \\partial \\theta\\), which depends ODE solutions\n\nAdjoint sensitivity method: solve the adjoint problem backward in time \\[\\frac{\\text{d}\\lambda}{\\text{d}t} = -\\lambda \\frac{\\partial f}{\\partial x}, \\quad \\frac{\\partial J}{\\partial \\theta} = \\lambda(t_0) \\frac{\\partial f}{\\partial x}\\]"
  },
  {
    "objectID": "main.html#robustness-via-bayesian-learning-1",
    "href": "main.html#robustness-via-bayesian-learning-1",
    "title": "main",
    "section": "Robustness via Bayesian Learning",
    "text": "Robustness via Bayesian Learning\n\n\n\n\n\nNeuralPbc assumes a nominal model \\(\\dot{x} = f_p(x, u)\\)\nThe trained controller must not overfit on the observations generated from the nominal model\n\n\n\n\n\n\n\n\nOur method: \\(H_d\\) is a Bayesian neural network\n\nachieves the performance objective for samples \\(\\theta \\sim P(\\theta | \\mathbb{D})\\)\nsearches for ensemble of parameters that meet the desired performance \\[\n  P(\\theta \\mid \\mathbb{D}) = \\frac{\\overbrace{P(\\mathbb{D} \\mid\n  \\theta)}^{\\text{likelihood}}\\overbrace{P(\\theta)}^{\\text{prior}}}\n  {\\underbrace{\\int_\\theta P(\\mathbb{D} \\mid \\theta^\\prime)P(\\theta^\\prime)\n  d\\theta^\\prime}_{\\text{evidence}}}.\n\\]"
  },
  {
    "objectID": "main.html#bayesian-learning-produces-more-robust-controllers",
    "href": "main.html#bayesian-learning-produces-more-robust-controllers",
    "title": "main",
    "section": "Bayesian Learning Produces More Robust Controllers",
    "text": "Bayesian Learning Produces More Robust Controllers\n\n\n\nConsider the control system:\n\n\nParameter uncertainty: \\(p \\sim \\mathcal{N}(\\hat{p}, \\sigma_p^2)\\).\nMeasurement noise: \\(x \\sim \\mathcal{N}(x, \\sigma^2)\\).\n\n\n\\[\n\\Sigma: \\quad\n\\begin{cases}\n  dx(t) &= (p+\\theta)x(t) dt + \\theta \\sigma dW_t, \\\\\n  x(0) &= 1.\n\\end{cases}\n\\] \\[\nx(t) = e^{(p+\\theta)t} + \\theta \\sigma \\int_0^t e^{(p+\\theta)(t-s)}dW_s.\n\\]\n\n\n\n\n\\[\n\\mathcal{J} = \\int_0^T \\left( \\frac{1}{2}qx(t)^2 + \\frac{1}{2}ru(t)^2  \\right)dt.\n\\]\n\n\n\n\n\n\nLemma\n\n\nThe conditional expectation \\(\\mathbb{E}[\\mathcal{J} \\mid p]\\) of the performance index given the system parameter \\(p\\) is\n\\[\n\\mathbb{E}[\\mathcal{J} \\mid p] =\n-\\frac{1}{4}\\frac{q+r\\theta^2}{p+\\theta}\\left[ \\theta^2 \\sigma^2 T +\n\\left(1-e^{2 T (p+\\theta)}\\right) \\left(1+\\frac{1}{2}\\frac{\\theta^2\n\\sigma^2}{p+\\theta}\\right) \\right]\n\\]"
  },
  {
    "objectID": "main.html#conditional-expectation",
    "href": "main.html#conditional-expectation",
    "title": "main",
    "section": "Conditional Expectation",
    "text": "Conditional Expectation\n\n\n\\[\n\\mathbb{E}[\\mathcal{J} \\mid p] =\n-\\frac{1}{4}\\frac{q+r\\theta^2}{p+\\theta}\\left[ \\theta^2 \\sigma^2 T +\n\\left(1-e^{2 T (p+\\theta)}\\right) \\left(1+\\frac{1}{2}\\frac{\\theta^2\n\\sigma^2}{p+\\theta}\\right) \\right]\n\\]\n\n\n\n\n\nProof\n\n\nSubstituting the solution of the SDE into the performance measure yields\n\\[\n\\begin{aligned} \\mathcal{J} =\n        & -\\frac{1}{4}\\frac{q+r\\theta^2}{p+\\theta}\\left(1 +\n        e^{2T(p+\\theta)}\\right) +\n        (q+r\\theta^2)\\theta\\sigma \\int_0^T\n        e^{(p+\\theta)t} \\int_0^t e^{(p+\\theta)(t-s)}dW_s\n        dt + \\frac{1}{2}(q+r\\theta^2)\\theta^2\n        \\sigma^2 \\int_0^T \\left( \\int_0^t\n        e^{(p+\\theta)(t-s)} dW_s  \\right)^2 dt\n\\end{aligned}\n\\]\nThe conditional expectation of this quantity given the system parameter \\(p\\) under the distribution induced by the Wiener process may be computed in closed-form using Ito calculus.\n\\[\n\\begin{aligned}\n\\mathbb{E}_W\\left[\\mathcal{J} \\mid p \\right] &= -\\frac{1}{4}\\frac{q+r\\theta^2}{p+\\theta}\\left(1 - e^{2T(p+\\theta)}\\right) +\n        (q+r\\theta^2)\\theta\\sigma\\int_0^Te^{(p+\\theta)t}\\mathbb{E}_W\\left[\\int_0^t\n        e^{(p+\\theta)(t-s)} dW_s~\\Big\\rvert p\\right] dt + \\\\\n        &\\frac{1}{2}(q+r\\theta)^2\\theta^2\\sigma^2\\int_0^T\\mathbb{E}_W\\left[\\left(\\int_0^t\n        e^{(p+\\theta)(t-s)} dW_s \\right)^2~\\bigg\\rvert p\\right] dt \\\\\n        &=-\\frac{1}{4}\\frac{q+r\\theta^2}{p+\\theta}\\left(1 -\n        e^{2T(p+\\theta)}\\right) +\n        \\frac{1}{2}(q+r\\theta^2)\\theta^2\\sigma^2\\int_0^T\\left(\\int_0^t\n        e^{2(p+\\theta)(t-s)} ds \\right) dt \\\\\n        &=-\\frac{1}{4}\\frac{q+r\\theta^2}{p+\\theta}\\left(1 - e^{2T(p+\\theta)}\\right) +\n        \\frac{1}{2}(q+r\\theta^2)\\theta^2\\sigma^2\\int_0^T\n        -\\frac{1}{2(p+\\theta)}\\left(1 - e^{2T(p+\\theta)}\\right) dt \\\\\n        &=-\\frac{1}{4}\\frac{q+r\\theta^2}{p+\\theta} \\left[ \\theta^2 \\sigma^2 T +\n        \\left(1 - e^{2T(p+\\theta)}\\right) \\left(1 +\n        \\frac{1}{2}\\frac{\\theta^2\\sigma^2}{p+\\theta}\\right)\\right].\n\\end{aligned}\n\\]\n\n🟧"
  },
  {
    "objectID": "main.html#optimal-controller",
    "href": "main.html#optimal-controller",
    "title": "main",
    "section": "Optimal Controller",
    "text": "Optimal Controller\n\n\n\n\n\n\n\n\nOptimal controller \\(|\\theta^\\star|\\) minimizing \\(\\mathbb{E}\\mathcal{J}\\)\n\n\nMinimal expected cost \\(\\mathbb{E}\\mathcal{J}\\)"
  },
  {
    "objectID": "main.html#optimal-controller-1",
    "href": "main.html#optimal-controller-1",
    "title": "main",
    "section": "Optimal Controller",
    "text": "Optimal Controller\n\n\n\n\n\nOptimal controller \\(|\\theta^\\star|\\) minimizing \\(\\mathbb{E}\\mathcal{J}\\)\n\n\n\n\n\nMinimal expected cost \\(\\mathbb{E}\\mathcal{J}\\)\n\n\n\n\n\nOptimal control parameter a nontrivial function of \\(\\sigma\\) and \\(\\sigma_p\\).\nBayesian learning strikes the right trade-off."
  },
  {
    "objectID": "main.html#bayesian-neuralpbc",
    "href": "main.html#bayesian-neuralpbc",
    "title": "main",
    "section": "Bayesian NeuralPbc",
    "text": "Bayesian NeuralPbc\n\n\n\n\n\n\n\nNeuralPbc Optimization Problem\n\n\n\\[\n\\begin{aligned}\n\\underset{\\theta}{\\text{minimize}} && J(\\phi, u^\\theta) &= \\mathbb{E}_{x_0 \\in \\mathcal{D}_N}[ \\ell( \\phi(x_0, u, T), u) ], \\\\\n\\text{subject to} &&\n\\begin{bmatrix}\n  \\dot{q} \\\\ \\dot{p}\n\\end{bmatrix} &=\n\\begin{bmatrix}\n  0 & I \\\\ -I & 0\n\\end{bmatrix}\n\\begin{bmatrix} \\nabla_q H \\\\ \\nabla_p H \\end{bmatrix} +\n\\begin{bmatrix}\n  0 \\\\ \\Omega\n\\end{bmatrix} u^{\\theta},\n\\\\\n&& u^\\theta &= \\Omega^{\\dagger}(\\nabla_q H  - \\nabla_q H_d^\\theta).\n\\end{aligned}\n\\]\n\n\n\n\n\n\n\n\n\n\nBayesian NeuralPbc Optimization Problem\n\n\n\\[\n\\begin{aligned}\n    \\underset{z}{\\text{minimize}} && J(\\phi, u^\\theta) &= \\mathbb{E}_{x_0 \\in \\mathcal{D}_N}[ \\ell( \\phi(x_0, u, T), u) ], \\\\\n    \\text{subject to} &&\n    \\begin{bmatrix}\n    \\dot{q} \\\\ \\dot{p}\n    \\end{bmatrix} &=\n    \\begin{bmatrix}\n    0 & I \\\\ -I & 0\n    \\end{bmatrix}\n    \\begin{bmatrix} \\nabla_q H \\\\ \\nabla_p H \\end{bmatrix} +\n    \\begin{bmatrix}\n    0 \\\\ \\Omega\n    \\end{bmatrix} u^{\\theta},\n    \\\\\n    && u^\\theta &= \\Omega^{\\dagger}(\\nabla_q H  - \\nabla_q H_d^\\theta),\\\\\n    && \\theta &\\sim Q(\\theta; z).\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "main.html#bayesian-neuralpbc-1",
    "href": "main.html#bayesian-neuralpbc-1",
    "title": "main",
    "section": "Bayesian NeuralPbc",
    "text": "Bayesian NeuralPbc\n\n\n\n\n\nNeuralPbc Optimization Problem\n\n\n\\[\n\\begin{aligned}\n\\underset{\\theta}{\\text{minimize}} && J(\\phi, u^\\theta) &= \\mathbb{E}_{x_0 \\in \\mathcal{D}_N}[ \\ell( \\phi(x_0, u, T), u) ], \\\\\n\\text{subject to} &&\n\\begin{bmatrix}\n  \\dot{q} \\\\ \\dot{p}\n\\end{bmatrix} &=\n\\begin{bmatrix}\n  0 & I \\\\ -I & 0\n\\end{bmatrix}\n\\begin{bmatrix} \\nabla_q H \\\\ \\nabla_p H \\end{bmatrix} +\n\\begin{bmatrix}\n  0 \\\\ \\Omega\n\\end{bmatrix} u^{\\theta},\n\\\\\n&& u^\\theta &= \\Omega^{\\dagger}(\\nabla_q H  - \\nabla_q H_d^\\theta).\n\\end{aligned}\n\\]\n\n\n\n\n\n\n\n\nBayesian NeuralPbc Optimization Problem\n\n\n\\[\n\\begin{aligned}\n    \\underset{z}{\\text{minimize}} && J(\\phi, u^\\theta) &= \\mathbb{E}_{x_0 \\in \\mathcal{D}_N}[ \\ell( \\phi(x_0, u, T), u) ], \\\\\n    \\text{subject to} &&\n    \\begin{bmatrix}\n    \\dot{q} \\\\ \\dot{p}\n    \\end{bmatrix} &=\n    \\begin{bmatrix}\n    0 & I \\\\ -I & 0\n    \\end{bmatrix}\n    \\begin{bmatrix} \\nabla_q H \\\\ \\nabla_p H \\end{bmatrix} +\n    \\begin{bmatrix}\n    0 \\\\ \\Omega\n    \\end{bmatrix} u^{\\theta},\n    \\\\\n    && u^\\theta &= \\Omega^{\\dagger}(\\nabla_q H  - \\nabla_q H_d^\\theta),\\\\\n    && \\theta &\\sim Q(\\theta; z).\n\\end{aligned}\n\\]\n\n\n\n\n\n\n\nThe parameter \\(z\\) of the posterior \\(Q(\\theta;z)\\) is inferred from running cost \\(J(\\phi, u^\\theta)\\)\n\\(H_d^\\theta\\) is a Bayesian neural network (BNN)"
  },
  {
    "objectID": "main.html#uncertainty-modeling",
    "href": "main.html#uncertainty-modeling",
    "title": "main",
    "section": "Uncertainty Modeling",
    "text": "Uncertainty Modeling\n\nWe provide more structure to the variance of the Bayesian controllers\n\n\n\n\nBayesian NeuralPbc Optimization Problem\n\n\n\\[\n\\begin{aligned}\n    \\underset{z}{\\text{minimize}} && J(\\phi, u^\\theta) &= \\mathbb{E}_{x_0 \\in \\mathcal{D}_N}[ \\ell( \\phi(x_0, u, T), u) ], \\\\\n    \\text{subject to} &&\n    \\mathop{}\\!\\mathrm{d}x &= \\left(\n        \\begin{bmatrix}\\phantom{-}\\nabla_p H \\\\-\\nabla_q H \\end{bmatrix} + \\begin{bmatrix} 0 \\\\ \\Omega \\end{bmatrix} u^{\\theta}(x) \\right) \\mathop{}\\!\\mathrm{d}t + \\nabla_x u(x) \\mathop{}\\!\\mathrm{d}W_t, \\\\\n    && u^\\theta &= \\Omega^{\\dagger}(\\nabla_q H  - \\nabla_q H_d^\\theta),\\\\\n    && \\theta &\\sim Q(\\theta; z), \\\\\n    && p_s &\\sim \\mathcal{N}(\\hat{p}_s, \\sigma_p).\n\\end{aligned}\n\\]\n\n\n\n\nObjective: maximize Elbo\n\n\\[\\begin{gather*}\n  \\mathcal{L}(J,z) = \\mathbb{E}_{\\theta \\sim Q} \\left[\\ln(P(J \\mid \\theta)P(\\theta)) - \\ln(Q(\\theta;z)) \\right] \\\\\n  P(J | \\theta) = \\mathcal{N}(J \\; | \\; 0, s).\n\\end{gather*}\\]"
  },
  {
    "objectID": "main.html#neuralpbc-hybrid-system",
    "href": "main.html#neuralpbc-hybrid-system",
    "title": "main",
    "section": "NeuralPbc: Hybrid System",
    "text": "NeuralPbc: Hybrid System\n\n\n\n\n\n\n\nPassive Smooth System\n\n\n\\[\nH\\left(  x(t_1) \\right) \\leq  H\\left(  x(t_0) \\right) + \\int_{t_0}^{t_1} s(u(t), y(t)) \\, \\text{d}t\n\\]\n\n\n\n\n\n \n\n\n\n\n\nPassive Hybrid System\n\n\n\\[\\begin{gather*}\nH\\left(  x(t_1) \\right) \\leq  H\\left(  x(t_0) \\right) + \\int_{t_0}^{t_1} s(u(t), y(t)) \\, \\text{d}t \\\\\nH(x^+) \\leq H(x^-)\n\\end{gather*}\\]\n\n\n\n\n\n\n\n\n\n\nNeuralPbc for contact-rich system\n\n\n\\[\\begin{aligned}\n    \\underset{\\theta}{\\textrm{minimize}}\n    & & J(\\phi, u^\\theta) &= \\mathbb{E}_{x_0 \\in \\mathcal{D}_N}[ \\ell( \\phi(x_0, u, T), u) ], \\\\%\n    \\textrm{subject to}\n    & & M(q) &\\mathop{}\\!\\mathrm{d}\\dot{q} + h(q, \\dot{q}, \\theta)\\mathop{}\\!\\mathrm{d}t - \\mathop{}\\!\\mathrm{d}R  = 0,\\\\%\n    & & u^{\\theta} &= \\Omega^{\\dagger}(\\nabla_q H  - \\nabla_q H_d).%\n\\end{aligned}\\]"
  },
  {
    "objectID": "main.html#bayesian-neuralpbc-hybrid-system",
    "href": "main.html#bayesian-neuralpbc-hybrid-system",
    "title": "main",
    "section": "Bayesian NeuralPbc: Hybrid System",
    "text": "Bayesian NeuralPbc: Hybrid System\n\n\n\nNeuralPbc for contact-rich system\n\n\n\\[\\begin{aligned}\n    \\underset{z}{\\textrm{minimize}}\n    & & & J(\\phi, u) = \\mathbb{E}_{x_0 \\in \\mathcal{D}_N}[\\ell(\\phi(x_0, u^\\theta, T), u^\\theta)], \\\\\n    \\textrm{subject to}\n    & & M(q) &\\mathop{}\\!\\mathrm{d}\\dot{q} + h(q, \\dot{q}, \\theta)\\mathop{}\\!\\mathrm{d}t - \\mathop{}\\!\\mathrm{d}R  = 0,\\\\\n    & & u^{\\theta} &= \\Omega^{\\dagger}(\\nabla_q H  - \\nabla_q H_d^\\theta), \\\\\n    & & p_s &\\sim \\mathbb{U}(p_{min}, p_{max}), \\\\\n    & & \\theta &\\sim Q(\\theta; z).\n\\end{aligned}\\]"
  },
  {
    "objectID": "main.html#deterministic-vs.-bayesian",
    "href": "main.html#deterministic-vs.-bayesian",
    "title": "main",
    "section": "Deterministic vs. Bayesian",
    "text": "Deterministic vs. Bayesian\n\n\n\n\n\n\n\n\n\n\n\nSubtracting rings from the wheel\n\ndecreases wheel mass\ndecreases wheel and pendulum inertia\nmoves the center of mass"
  },
  {
    "objectID": "main.html#rimless-wheel-with-torso",
    "href": "main.html#rimless-wheel-with-torso",
    "title": "main",
    "section": "Rimless Wheel with Torso",
    "text": "Rimless Wheel with Torso\n\n\n\n\n\n\n\n\nPerformance objective: achieve hip speed \\(\\dot{x}_c^* = 1\\)m/s \\[\\begin{align*}\n  J_T = \\sum_{t=0}^{T} \\| \\dot{x}_c^* - \\dot{x}_c(t; \\theta) \\|\n\\end{align*}\\]\nUncertainty in elevation under each spoke \\[\np_s \\sim \\mathbb{U}(0 \\textrm{cm}, 2\\textrm{cm})\n\\]"
  },
  {
    "objectID": "main.html#joint-work-with-university-of-kentucky",
    "href": "main.html#joint-work-with-university-of-kentucky",
    "title": "main",
    "section": "Joint Work with University of Kentucky",
    "text": "Joint Work with University of Kentucky\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) State partition according to NN\n\n\n\n\n\n\n\n\n\n\n\n(b) Experimental set up\n\n\n\n\n\n\n\nFigure 1: NSF Award #2330794"
  },
  {
    "objectID": "main.html#results-from-the-joint-work",
    "href": "main.html#results-from-the-joint-work",
    "title": "main",
    "section": "Results from the Joint Work",
    "text": "Results from the Joint Work"
  },
  {
    "objectID": "main.html#where-the-roboticscontrol-field-is-going",
    "href": "main.html#where-the-roboticscontrol-field-is-going",
    "title": "main",
    "section": "Where the Robotics/Control Field is Going?",
    "text": "Where the Robotics/Control Field is Going?"
  },
  {
    "objectID": "main.html#future-research-robustness-of-gnns-for-robot-control",
    "href": "main.html#future-research-robustness-of-gnns-for-robot-control",
    "title": "main",
    "section": "Future Research: Robustness of GNNs for Robot Control",
    "text": "Future Research: Robustness of GNNs for Robot Control"
  },
  {
    "objectID": "main.html#future-research-convex-optimization-layers-on-gnns",
    "href": "main.html#future-research-convex-optimization-layers-on-gnns",
    "title": "main",
    "section": "Future Research: Convex Optimization Layers on GNNs",
    "text": "Future Research: Convex Optimization Layers on GNNs\n\n\n\n\n\n\nEnd-to-end formation control with GNNs1\n\n\n\n\n\n\n\n\n\n\nPropagate features to neighbors using convex-opt layers rather than MLPs.\nAlternately, implement the message Aggregate phase using convex-opt layers.\n\n\n\n\n  \n\n\n\n\n\n\nGNN for Legged Robot Contact Perception2\n\n\n\n\n\n\n\n\n\n\n\n\nJiang, Chao et. al. (2023) End-to-end decentralized formation control using a GNN-based learning method.Butterfield, Daniel et. al. (2024) MI-HGNN: Morphology-Informed Heterogeneous Graph Neural Network for Legged Robot Contact Perception."
  },
  {
    "objectID": "main.html#future-research-representation-learning-through-llms",
    "href": "main.html#future-research-representation-learning-through-llms",
    "title": "main",
    "section": "Future Research: Representation-learning through LLMs",
    "text": "Future Research: Representation-learning through LLMs\n\n\n\n\n\n\n\n⬆️\n\n\n\n\n\n\n\n\n\n\n\nUtilize a causal transformer to learn trajectory representations.\n\n\nCan learn them for each joint.\n\n\nUse these representations as feature vectors of a subsequent GNN.\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\nCourtesy of MIT CSAIL"
  },
  {
    "objectID": "main.html#funding-mechanism-nsf-foundational-research-in-robotics",
    "href": "main.html#funding-mechanism-nsf-foundational-research-in-robotics",
    "title": "main",
    "section": "Funding Mechanism: NSF Foundational Research in Robotics",
    "text": "Funding Mechanism: NSF Foundational Research in Robotics"
  },
  {
    "objectID": "main.html#funding-mechanisms-sbir-and-sttrs",
    "href": "main.html#funding-mechanisms-sbir-and-sttrs",
    "title": "main",
    "section": "Funding Mechanisms: SBIR and STTRs",
    "text": "Funding Mechanisms: SBIR and STTRs"
  },
  {
    "objectID": "main.html#funding-mechanism-nih-through-collaborations",
    "href": "main.html#funding-mechanism-nih-through-collaborations",
    "title": "main",
    "section": "Funding Mechanism: NIH through Collaborations",
    "text": "Funding Mechanism: NIH through Collaborations\n\n\n\n\n\n \n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRobust Sensing and Data-Driven Control • Aykut C. Satici"
  }
]