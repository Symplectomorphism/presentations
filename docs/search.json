[
  {
    "objectID": "main.html#robust-sensing-and-learning-control-of-contact-rich-robots",
    "href": "main.html#robust-sensing-and-learning-control-of-contact-rich-robots",
    "title": "main",
    "section": "Robust Sensing and Learning Control of Contact-Rich Robots",
    "text": "Robust Sensing and Learning Control of Contact-Rich Robots\n\n\n\n UT Dallas Seminar\n\n\n\n\n\n\n\n\n\n\n\n\nPresenter:  Aykut Satici, Ph.D.  Associate Professor  Director, Robot Control Lab  Mechanical and Biomed. Eng.  Boise, Idaho, USA\n\n\n\n\n\n\n\n\n\nGraduate Students:  üáπüá≠ Wankun Sirichotiyakul üéì  üá™üáπ Nardos Ayele Ashenafi üéì  üá∫üá∏ Alex Peterson üéì  üá∫üá∏ Chandika Silva üéì  üá∫üá∏ Chris Dagher üéì \n\n\n\n\n\nProduced several ECE and MBE MS and PhDs.\nThey landed high tech jobs at robotics, ML."
  },
  {
    "objectID": "main.html#graduate-studies-sabanci-university-and-ut-dallas",
    "href": "main.html#graduate-studies-sabanci-university-and-ut-dallas",
    "title": "main",
    "section": "Graduate Studies: Sabanci University and UT Dallas",
    "text": "Graduate Studies: Sabanci University and UT Dallas\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n¬†\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAt Sabanci: BS and MS degrees in Mechatronics w/ a lot of robotics/controls focus.\nCame to UTD in 2010 for my PhD\n\nOptimal Control of drones\nGeometric control of mutlirobot collaboration\n\nI also got an MS in math."
  },
  {
    "objectID": "main.html#postdoctoral-training-university-of-naples-and-mit",
    "href": "main.html#postdoctoral-training-university-of-naples-and-mit",
    "title": "main",
    "section": "Postdoctoral Training: University of Naples and MIT",
    "text": "Postdoctoral Training: University of Naples and MIT\n\n\n\n\n\n\n\n\n\n\n\n¬†\n\n\n\n\n\n\n\n\n\n\n\n\n\nAfter PhD, did a brief stunt at Mathworks before getting hired at\n\nProf.¬†Siciliano‚Äôs group at University of Naples, Federico II as a postdoctoral researcher.\nhired to help with control system design for the RoDyMan project ‚Äì (EU) nonprehensile robotic manipulation.\nWorked on PBC for underactuated/nonprehensile robots and geometric motion planning for tossing and catching\n\nSpent a second year of postdoc at MIT in Russ Tedrake‚Äôs group.\n\nWorked on modeling and control of soft robotic systems.\nVideo shows modeling a soft end-effector w/ a cable contraint\nDevised a model-based controller and tested in experiment."
  },
  {
    "objectID": "main.html#boise-state-university-robust-data-driven-control-of-robotic-contact",
    "href": "main.html#boise-state-university-robust-data-driven-control-of-robotic-contact",
    "title": "main",
    "section": " Boise State University: Robust Data-Driven Control of Robotic Contact",
    "text": "Boise State University: Robust Data-Driven Control of Robotic Contact\n\n\n\nVideo\n\n\nVideo\n\n\n\n\n\nJoined BSU as an TT assistant professor at MBE dept.\nFostered a collaboration w/ local drone compnay over the last 3 years.\n\nPerforming manipulation on power lines."
  },
  {
    "objectID": "main.html#robust-robotic-system-design",
    "href": "main.html#robust-robotic-system-design",
    "title": "main",
    "section": "Robust Robotic System Design",
    "text": "Robust Robotic System Design\n\nThe Surge in Reliance Upon Robotic Systems\n\n\n\n\n\n\nWarehouse automation\n\n\n\n\nAutonomous vehicles\n\n\n\n\nDrones for first responders\n\n\n\n\nUtility drones\n\n\n\n\n\n\n\nVideo\n\n\n\nVideo\n\n\n\nVideo\n\n\n\n\nVideo\n\n\n\n\n\n\n\n\n\n\nRobotics becoming ever more ubiquitous, and increasing the requirement of robust sensing and control.\n\n\n\n\n\n\nRobot Institute of America: reprogrammable, multifunctional manipulator designed to move things.\nThe definition changed and robots became more ubiquitous, requiring ever more robustness."
  },
  {
    "objectID": "main.html#robustness-against-contact-under-uncertainty",
    "href": "main.html#robustness-against-contact-under-uncertainty",
    "title": "main",
    "section": "Robustness against Contact under Uncertainty",
    "text": "Robustness against Contact under Uncertainty\n\n\n\n\n¬†\n\n\n\n\n\n\n\n\n\n¬†\n\n\n\n\n¬†\n\n\n\n\n\n\n¬†\n\n\n\n\nVideo\n\n\n\n\n\n\nNeed to make and break contact to be useful\nContact inherently very complex\n\nInstantaneous jumps\nDynamics changes\n\nA quasi-static or quasi-dynamic motion plan may fail due to these\nObserve Astria bird-diverter installation\n\nUnexpected mode of contact kicks and destabilizes the flight controller."
  },
  {
    "objectID": "main.html#sources-of-uncertainty",
    "href": "main.html#sources-of-uncertainty",
    "title": "main",
    "section": "Sources of Uncertainty",
    "text": "Sources of Uncertainty\n\n\n\n¬†\n\n\n\n\n\n\n\n\n\n\\(H_d^\\theta\\) is a desired storage function.\n\\(H_d^\\theta\\) is a neural network parametrized by \\(\\theta\\).\n\n\n\nClassical control system depiction\nDesired task encoded in the trajectory cost block\nEvolution of the states described by MDEs (necessary for friction/contact modeling)\nEstimated state corrupted with noise\nController is trained with imperfections\n\ndynamics model\nperfect state information or model of the noise\n\n\nConclusion: Performance of the CL system in real life will deviate from predictions. Need to devise a controller that is insensitive to unexpected yet inevitable discrepancies."
  },
  {
    "objectID": "main.html#repercussions-of-untreated-uncertainty",
    "href": "main.html#repercussions-of-untreated-uncertainty",
    "title": "main",
    "section": "Repercussions of Untreated Uncertainty",
    "text": "Repercussions of Untreated Uncertainty\nThe Case of the Rimless Wheel\n\n\n\n\n\n\nTraining without taking uncertainty into account\n\n\n\n\n\n\n\n\nFailing real-life implementation\n\n\n\n\n\n\n\nNeed to design both robust state estimation and controllers.\nDomain randomization and Bayesian learning help for controller design.\nGTSAM and optimization over factor graphs help for state estimation.\n\n\n\n\nFairly complex robot trained in simulation, implemented in real life.\nShows the sources of uncertainty:\n\nmanufacturing tolerances\nuneven terrain\nsensor characteristics\n\nPerformance suffers.\n\nTake away:\n\nState estimators and controllers need to be designed to be insensitive\n\nto various kinds of uncertainties.\n\nWill advocate several concepts in this vein\n\nPBC\nBayesian learning\ndomain randomization\noptimization over factor graphs."
  },
  {
    "objectID": "main.html#robustness-via-bayesian-learning",
    "href": "main.html#robustness-via-bayesian-learning",
    "title": "main",
    "section": "Robustness via Bayesian Learning",
    "text": "Robustness via Bayesian Learning\n\n\n\n\n\n\nSystem Parameter Uncertainty and Measurement Noise\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLess robust: learns point estimates of the weights.\n\n\n\n\n\n\n\n\nMore robust: learns prob. distribution over the weights.\n\n\n\n\n\n\n\n\nAny function approximator (weights and biases)\n\nnot just point estimates\nhave assoc. prob. distributions\n\nInference time\n\ndistributions are marginalized out\n\nMAP estimates\nsimple sampling\nintegration"
  },
  {
    "objectID": "main.html#robust-localization-over-power-lines",
    "href": "main.html#robust-localization-over-power-lines",
    "title": "main",
    "section": "Robust Localization over Power Lines",
    "text": "Robust Localization over Power Lines\n\n\n\n\nThe ground has a uniform texture.\nToo few utility poles or immediate fences.\nThere are no trees or other geometries.\nGPS provides absolute position.\nDrone requires pose relative to power lines!\n\n\n\n\n\n\n\n\n\n\n\n\nInsufficient landmarks\n\n\nAny vision-based estimation mechanism will not perform reliably and robustly for drone localization.\n\n\n\n\n\n\n\n\n\nElectromagnetic field around the power lines\n\n\nIf we can get reliable measurements, then we can devise a distance and bearing factor exploiting this field.\n\n\n\n\n\nExamples:\n\nmounting bird diverters\ndynamic line rating sensors to facilitate efficient power flow through trans. lines.\n\nLocalization problem difficult b/c\n\nscene has no salient features\nGPS absolute not relative\n\nLiterature not good at exploiting the EM field\n\nGreat for robust relative pose estimation"
  },
  {
    "objectID": "main.html#navigating-the-uav-to-one-of-the-power-lines",
    "href": "main.html#navigating-the-uav-to-one-of-the-power-lines",
    "title": "main",
    "section": "Navigating the UAV to One of the Power Lines",
    "text": "Navigating the UAV to One of the Power Lines\n\n\n\n\n\n\nDefine the potential function \\(V(\\mathbf{q}) = \\frac{1}{\\bar{E}^2(\\mathbf{q})}\\). Its gradient is \\[\n\\nabla_{\\mathbf{q}}V(\\mathbf{q}) = -\\frac{2}{\\bar{E}^3}\\nabla_{\\mathbf{q}}\\bar{E}(\\mathbf{q})\n\\] Further, \\(\\lVert \\nabla_{\\mathbf{q}}V(\\mathbf{q}) \\rVert = O\\left(1/\\bar{E}\\right)\\) as \\(\\bar{E} \\rightarrow \\infty\\) (or \\(r_\\alpha \\rightarrow 0\\)).\n\n\n\n\n\n\nLemma: Direction of the gradient\n\n\nThe gradient \\(\\nabla_{\\mathbf{q}} \\bar{E}(\\mathbf{q})\\) points into the convex hull (triangle) formed by the transmission wires for every \\(\\mathbf{q}\\).\n\n\n\n\n\n\nLemma: Critical points of \\(V(\\mathbf{q})\\)\n\n\n\nGenerically \\(V\\) has \\(5\\) isolated critical points, \\(3\\) of which are global minima and have \\(r_\\alpha = 0\\).\nApplying Poincar√©-Hopf theorem on the convex hull of the power lines yields the remaining 2 are saddle points!\n\n\n\n\n\nFirst way to exploit: navigate the UAV to one of the power lines.\n\nCreate potential so that\n\nits gradient vanishes at one of the power lines.\n\nFurther lemma: these are its only minima\nOther critical points of V are saddle points\n\nCan be shown by combining Morse theory and Poincare-Hopf theorem\n\nIndex of a vector field around a critical point\nlined to the Euler characteristic of the underlying manifold\n\n\nAnalysis shows:\n\nFollowing the grad of the rms E-field gets to one of the power lines\nRMS quantities: low-pass filter ‚Äì&gt; robustness\n\n\n\n\n\n\n\nFollowing \\(\\nabla_{\\mathbf{q}}V(\\mathbf{q})\\) navigates the drone to one of the power lines."
  },
  {
    "objectID": "main.html#robust-localization-with-gtsam-sensor-fusion",
    "href": "main.html#robust-localization-with-gtsam-sensor-fusion",
    "title": "main",
    "section": "Robust Localization with GTSAM: Sensor Fusion",
    "text": "Robust Localization with GTSAM: Sensor Fusion\nFuse \\(\\nabla_{\\mathbf{q}}\\bar{E}(\\mathbf{q})\\), IMU, GPS, Camera Measurements\n\n\n\nFactors depict constaints on the poses as:\n\nprior state: \\(f_0(x_1)\\)\nodometry relation: \\(f_i(x_i, x_{i+1}; o_i)\\)\nobservations: \\(f_i(x_i;z_i)\\).\n\n\n\n\n\n\n\\[\n\\begin{aligned}\np(\\mathbf{x} | \\mathbf{o}) \\propto p(x_1) \\prod_{i=2}^{3} p(x_i | x_{i-1}, o_i)\\\\\n% f(\\mathbf{x}) = \\arg\\max_{\\mathbf{x}}  f_0(x_1) \\prod_{i=1}^{2} f_i(x_i, x_{i+1}; o_i)\n\\end{aligned}\n\\]\n\n\n\n\\[\n\\begin{aligned}\np(\\mathbf{x} | \\mathbf{o}, \\mathbf{z}) \\propto p(x_1) \\prod_{i=2}^{3} p(x_i | x_{i-1}, o_i) p(z_i | x_i) \\\\\n% f(\\mathbf{x}) = \\arg\\max_{\\mathbf{x}}  f_0(x_1) \\prod_{i=1}^{2} f_i(x_i, x_{i+1}; o_i)  g_i(x_i; z_i)\n\\end{aligned}\n\\]\n\n\n\n\\[\n\\begin{aligned}\np(\\mathbf{x} | \\mathbf{o}, \\mathbf{l}) \\propto p(x_1) \\prod_{i=2}^{3} p(x_i | x_{i-1}, o_i) p(l_i | x_i) \\\\\n% f(\\mathbf{x}) = \\arg\\max_{\\mathbf{x}}  f_0(x_1) \\prod_{i=1}^{2} f_i(x_i, x_{i+1}; o_i)  h_i(x_i; l_i)\n\\end{aligned}\n\\]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSecond way to exploit the gradient: use it as a measurement factor.\n\nFactor-graph based state estimators\n\neach measurement is a factor of a graph\nthe graph‚Äôs nodes are estimated states\nthe graph‚Äôs edges connect state estimates to observations with a factor.\n\nProb. distribution constructed\n\ncorresponds to the current belief of states\neach measurement/observation contributes\nan optimization problem is solved to find the MAP of this prob. dist."
  },
  {
    "objectID": "main.html#gtsam-meets-gradient-of-the-electric-field",
    "href": "main.html#gtsam-meets-gradient-of-the-electric-field",
    "title": "main",
    "section": "GTSAM meets Gradient of the Electric Field",
    "text": "GTSAM meets Gradient of the Electric Field\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRecall: the grad of the rms E-field points into the convex hull\n\neach measurement of the E- or B-field is a bearing to a landmark (convex hull)\nthink of ships observing the light from a lighthouse!\nLandmark observation handed to GTSAM for optimization of factor-graph\n\nExperiments conducted on custom powered transmission line\n\nAGV carries the appratus for measurements\nPlots show that the estimated bearing and distance is close to the truth.\nDistance gets more and more accurate as the sensors get close to the line."
  },
  {
    "objectID": "main.html#stable-contact-and-manipulation-over-power-lines",
    "href": "main.html#stable-contact-and-manipulation-over-power-lines",
    "title": "main",
    "section": "Stable Contact and Manipulation over Power Lines",
    "text": "Stable Contact and Manipulation over Power Lines\n\n\n\n\n\n\nWe are implementing passivity-based controllers (data-driven or otherwise) for manipulation over power lines.\n\n\n\n\n\n¬†\n¬†\n¬†\n¬†\n\n\n\n\n\n\nNSF STTR grant secured.\n\nImplement our state estimation and navigation alg on real UAV.\nAutonomously approach and make stable contact.\n\nNow designing PBC controllers for\n\nmaking and breaking stable contact\nusing high-fidelity simulations of the power line and the UAV interaction\n\nNext goal (control design):\n\nIncorporate wind gusts effects (NN approximators)\nCoM changes after installing or uninstalling devices (adaptive ctrl. ideas)"
  },
  {
    "objectID": "main.html#dissipativity-and-passivity",
    "href": "main.html#dissipativity-and-passivity",
    "title": "main",
    "section": "Dissipativity and Passivity",
    "text": "Dissipativity and Passivity\n\n\n\n\n\nDissipativity\n\n\n% \\[\n\\Sigma: \\quad\n\\begin{cases}\n  \\dot{x} &= f(x,u) \\\\\n  y &= h(x,u)\n\\end{cases}\n\\quad x \\in \\mathcal{X} \\subset \\mathbb{R}^{2n}, \\, u \\in \\mathcal{U} \\subset \\mathbb{R}^{m}\n\\] is dissipative with respect to some supply rate \\(s\\) if there exists a storage function \\(\\mathcal{H}: \\mathcal{X} \\to \\mathbb{R}^{+}\\) such that % \\[\n\\mathcal{H}\\left(  x(t_1) \\right) \\leq  \\mathcal{H}\\left(  x(t_0) \\right) + \\int_{t_0}^{t_1} s(u(t), y(t)) \\, \\text{d}t\n\\] % for all \\(x(t_0) = x_0\\), all input \\(u\\), and all \\(t_1 \\geq t_0\\).\n\n\n\n\n\n\n\nPassivity\n\n\nThe system \\(\\Sigma\\) is passive if it is dissipative with supply rate\n\\[s = u^\\top y.\\]\nIt is output strictly passive if it is dissipative with supply rate\n\\[s = u^\\top y - \\delta \\lVert y \\rVert^2, \\; \\delta &gt; 0.\\]\n\n\n\n\n\nDissipative if \\(\\exists\\) a storage function \\(H\\) and an supply rate \\(s\\) s.t. the storage increases at most as much as that supplies by \\(s\\).\nPassivity: special case, where \\(s = u^\\top y\\)."
  },
  {
    "objectID": "main.html#lyapunov-stability-of-passive-systems",
    "href": "main.html#lyapunov-stability-of-passive-systems",
    "title": "main",
    "section": "(Lyapunov) Stability of Passive Systems",
    "text": "(Lyapunov) Stability of Passive Systems\n\n\\[\n\\Sigma: \\quad\n\\begin{cases}\n  \\dot{x} &= f(x,u), && f(0,0) = 0, \\\\\n  y &= h(x,u), && h(0,0) = 0,\n\\end{cases}\n\\]\n\\(u^{\\top} y \\geq \\dot{\\mathcal{H}} = \\frac{\\partial\\mathcal{H}}{\\partial x} f(x,u),\\quad \\mathcal{H} \\geq 0,\\quad y \\equiv 0 \\implies x \\equiv 0\\)\n\n\n\n¬†\n\n\n\n\n\n\n\nLemma (Khalil, 2002)\n\n\nThe origin of \\(\\Sigma\\) is:\n\nstable if \\(\\Sigma\\) is passive,\nasymptotically stable if \\(\\Sigma\\) is output strictly passive,\nglobally asymptotically stable if \\(\\Sigma\\) is output strictly passive and the storage function \\(\\mathcal{H}(x) \\to \\infty\\) as \\(\\lVert x \\rVert \\to \\infty\\) (radially unbounded)\n\n\n\n\n\n\n\n\n\nNotice that we only require that the function \\(\\mathcal{H}\\) be positive semidefinite and not necessarily positive definite as per usual Lyapunov conditions.\nObservability (detectability) ensures LaSalle‚Äôs theorem works."
  },
  {
    "objectID": "main.html#passivity-based-control-pbc-toy-example-simple-pendulum",
    "href": "main.html#passivity-based-control-pbc-toy-example-simple-pendulum",
    "title": "main",
    "section": "Passivity-Based Control (PBC) Toy Example: Simple Pendulum",
    "text": "Passivity-Based Control (PBC) Toy Example: Simple Pendulum\n\n\n\n\nSystem Dynamics\n\n\n\\(H(q,p) = \\frac{1}{2} J^{-1} p^2 + mgl (1 - \\cos q)\\)\n\\[\n\\begin{bmatrix} \\dot{q} \\\\ \\dot{p} \\end{bmatrix} =\n\\begin{bmatrix} \\phantom{-}0 & 1 \\\\ -1 & 0 \\end{bmatrix}\n\\begin{bmatrix} \\nabla_q H_{\\phantom{d}} \\\\ \\nabla_p H_{\\phantom{d}} \\end{bmatrix} +\n\\begin{bmatrix} 0 \\\\ G \\end{bmatrix} u_\\phantom{di},\n\\qquad y = \\dot{q}\n\\]\n\nChoose \\(u = u_{es} + u_{di}\\) that transforms system into a passive one with \\(x^\\star = (q^\\star, 0)\\) \n\n\n\\(Gu_{es} = \\nabla_q H  - \\nabla_q H_d , \\quad Gu_{di} = -GK_D G^\\top \\nabla_p H_d\\)\n\n\n\n\\[\n\\begin{bmatrix} \\dot{q} \\\\ \\dot{p} \\end{bmatrix} =\n\\begin{bmatrix} \\phantom{-}0 & 1 \\\\ -1 & 0 \\end{bmatrix}\n\\begin{bmatrix} \\nabla_q H_d \\\\ \\nabla_p H_d \\end{bmatrix} +\n\\begin{bmatrix} 0 \\\\ G \\end{bmatrix} u_{di},\n\\qquad y = \\dot{q}\n\\]\n\n\n\\[\n\\begin{bmatrix} \\dot{q} \\\\ \\dot{p} \\end{bmatrix} =\n\\begin{bmatrix} \\phantom{-}0 & 1 \\\\ -1 & -G K_D G^\\top \\end{bmatrix}\n\\begin{bmatrix} \\nabla_q H_d \\\\ \\nabla_p H_d \\end{bmatrix},\n\\qquad y = \\dot{q}\n\\]\n\n\n\n\n\n\nMost basic PBC\n\nStart with Hamiltonian dynamics.\nUse control authority to impose a desired storage fcn., with a minimum at the desired state.\nNeed to solve PDEs in general.\nDamping injection for asymptotic stability."
  },
  {
    "objectID": "main.html#passivity-based-control-pbc-toy-example-simple-pendulum-1",
    "href": "main.html#passivity-based-control-pbc-toy-example-simple-pendulum-1",
    "title": "main",
    "section": "Passivity-Based Control (PBC) Toy Example: Simple Pendulum",
    "text": "Passivity-Based Control (PBC) Toy Example: Simple Pendulum\n\n\n\n\nControl Synthesis via PBC\n\n\nChoose \\(u = u_{es} + u_{di}\\) that transforms system into a passive one with \\(x^\\star =  (q^\\star, 0)\\)\n\\(Gu_{es} = \\nabla_q H  - \\nabla_q H_d , \\quad Gu_{di} = -GK_D G^\\top \\nabla_p H_d\\)\n\\[\n\\begin{bmatrix} \\dot{q} \\\\ \\dot{p} \\end{bmatrix} =\n\\begin{bmatrix} \\phantom{-}0 & 1 \\\\ -1 & -G K_D G^\\top \\end{bmatrix}\n\\begin{bmatrix} \\nabla_q H_d \\\\ \\nabla_p H_d \\end{bmatrix},\n\\qquad y = \\dot{q}\n\\]\n\n\\(H_d(q,p) = \\frac{1}{2} J^{-1} p^2 + V_d(q), \\quad V_d(q) = \\frac{1}{2} K_{P} \\left( q - q^\\star \\right)^2 \\implies H_d \\geq 0\\)\n\n\n\n\\(\\dot{H}_d = -K_D \\left( J^{-1} p \\right)^2 = y^\\top u_{di} \\leq 0\\)\nIn general, hard to show that such an \\(H_d\\) exists!\n\n\n\\(\\boxed{u = -mgl\\sin(q) - K_P(q - q^\\star) - K_D \\dot{q}}\\)\n\n\n\n\n\n\nDifficulty is in finding an \\(H_d\\) that satisfies the PDEs with the desired minimum.\nIn this fully actuated case, it is simple, with the resulting controller given."
  },
  {
    "objectID": "main.html#passivity-based-control-pbc",
    "href": "main.html#passivity-based-control-pbc",
    "title": "main",
    "section": "Passivity-Based Control (PBC)",
    "text": "Passivity-Based Control (PBC)\n\n\n\n\n¬†\n\n\n\n\n\\[\n\\Sigma_o: \\quad\n\\begin{cases}\n  \\dot{x} &= f(x) + g(x)u, \\\\\n  y &= h(x)\n\\end{cases}\n\\] % Main idea ‚Äî Select \\(u(x) = u_{es} + u_{di}\\) that renders the closed-loop system passive. % \\[\n\\Sigma_d: \\quad\n\\begin{cases}\n  \\dot{x} &= f_d(x) + g(x) u_{di}, \\quad f_d := f(x) + g(x) u_{es}(x) \\\\\n  y_d &= h_d(x)\n\\end{cases}\n\\] % Control problem is cast as a search for \\(H_d\\) and \\(h_d\\) such that \\[\n\\dot{H}_d \\leq y_d^\\top u_{di}\n\\]\n\n\n\n\n\nGeneral PBC follows a similar trajectory.\nStart with a Hamiltonian system\nUse control authority to seek a suitable desired Hamiltonian with a minimum at the desired state.\nStabilize using damping injection."
  },
  {
    "objectID": "main.html#neuralpbc-problem-statement",
    "href": "main.html#neuralpbc-problem-statement",
    "title": "main",
    "section": "NeuralPbc Problem Statement",
    "text": "NeuralPbc Problem Statement\n\nConsider the mechanical system\n\\[\n\\begin{bmatrix} \\dot{q} \\\\ \\dot{p} \\end{bmatrix} =\n\\begin{bmatrix} \\phantom{-}0 & 1 \\\\ -1 & 0 \\end{bmatrix}\n\\begin{bmatrix} \\nabla_q H_{\\phantom{d}} \\\\ \\nabla_p H_{\\phantom{d}} \\end{bmatrix} +\n\\begin{bmatrix} 0 \\\\ G \\end{bmatrix} u_\\phantom{di}\n\\]\nControl task: stabilize desired equilibrium \\(x^\\star = (q^\\star, 0)\\)\n\n\n\\[u = u_{es} + u_{di} = G^{\\dagger} \\left( \\nabla_q H  - \\nabla_q H_d \\right)  - K_D G^\\top \\nabla_p H_d \\]\n\n\n\\[u = u_{es} + u_{di} = - G^{\\dagger} \\nabla_q H_d^{\\theta}  - K_D G^\\top \\nabla_p H_d^{\\theta} \\]\n\n\nChoosing a suitable \\(H_d\\) is not trivial\n\nParameterize \\(H_d\\) by a neural network \\(H_d^\\theta\\), and relax control task to bringing \\(x\\) to a small neighborhood of \\(x^\\star\\)\n\n\n\nInstead of asking for asymptotic stabilization, we only require that trajectories pass thru a nbhd of \\(x^\\star\\)\nThis is reasonable because we know how to stabilize a fixed point, e.g.¬†stabilize the linearization of the system using LQR\nThis allows us to find approximations for \\(H_d^\\theta\\) using learning techniques"
  },
  {
    "objectID": "main.html#neuralpbc-techniques",
    "href": "main.html#neuralpbc-techniques",
    "title": "main",
    "section": "NeuralPbc Techniques",
    "text": "NeuralPbc Techniques\n\n\n\n\n\n\n\n\n\\[\n\\begin{aligned}\n\\underset{\\theta}{\\text{minimize}} && J(\\theta, x_0) &= \\int_{0}^{T} \\ell \\left(\\phi,u^\\theta,\\theta\\right)\\, \\text{d} t \\\\\n\\text{subject to} &&\n\\begin{bmatrix}\n  \\dot{q} \\\\ \\dot{p}\n\\end{bmatrix} &=\n\\begin{bmatrix}\n  0 & I \\\\ -I & 0\n\\end{bmatrix}\n\\begin{bmatrix} \\nabla_q H \\\\ \\nabla_p H \\end{bmatrix} +\n\\begin{bmatrix}\n  0 \\\\ G\n\\end{bmatrix} u^{\\theta}\n\\\\\n&& u^\\theta &= - G^{\\dagger}\\nabla_q H_d^{\\theta}  - K_D G^\\top \\nabla_p H_d^{\\theta}\n\\end{aligned}\n\\]\n\n\n\n\n\nInjecting control task into loss function design\n\n\n\nMay require an initial motion/path planning step\n\n\nFor simple tasks, can just be quadratic loss to goal\n\n\n\nBackprop through closed-loop trajectories\n\n\n\nForward or adjoint differentiation\n\n\nTypically adjoint differentiation is more efficient\n\n\n\nSampling the state space efficiently\n\n\n\nDAgger sampling\n\n\nInitial conditions chosen from previously visited states\n\n\n\n\n\n\n\n\n\n\nPenalize states away from a desired ball.\n\n\n\n\n\nPenalize nonzero transverse coordinates.\n\n\n\n\nWe need \\(\\partial J / \\partial \\theta\\), which depends ODE solutions\n\nAdjoint sensitivity method: solve the adjoint problem backward in time \\[\\frac{\\text{d}\\lambda}{\\text{d}t} = -\\lambda \\frac{\\partial f}{\\partial x}, \\quad \\frac{\\partial J}{\\partial \\theta} = \\lambda(t_0) \\frac{\\partial f}{\\partial x}\\]"
  },
  {
    "objectID": "main.html#robustness-via-bayesian-learning-1",
    "href": "main.html#robustness-via-bayesian-learning-1",
    "title": "main",
    "section": "Robustness via Bayesian Learning",
    "text": "Robustness via Bayesian Learning\n\n\n\n\nNeuralPbc assumes a nominal model \\[\n\\dot{x} = f_p(x, u)\n\\]\nThe trained controller must not overfit on the observations generated from the nominal model\n\n\n\n\n\n\n\n\nOur method: \\(H_d\\) is a Bayesian neural network\n\nachieves the performance objective for samples \\(\\theta \\sim P(\\theta | \\mathbb{D})\\)\nsearches for ensemble of parameters that meet the desired performance \\[\n  P(\\theta \\mid \\mathbb{D}) = \\frac{\\overbrace{P(\\mathbb{D} \\mid\n  \\theta)}^{\\text{likelihood}}\\overbrace{P(\\theta)}^{\\text{prior}}}\n  {\\underbrace{\\int_\\theta P(\\mathbb{D} \\mid \\theta^\\prime)P(\\theta^\\prime)\n  d\\theta^\\prime}_{\\text{evidence}}}.\n\\]\n\n\n\n\n\nThe vanilla NeuralPBC generates data from a nominal model\n\nDeduces a neural network whose weights are point estimates.\n\nContrast, we want to make \\(H_d\\) a BNN.\n\nLearn prob. distributions over the weights conditioned on the observed data.\nDo this by invoking Bayes‚Äôs rule, where we postulate a simple likelihood and a prior function\nNo need to compute the evidence, as it turns out."
  },
  {
    "objectID": "main.html#bayesian-learning-produces-more-robust-controllers",
    "href": "main.html#bayesian-learning-produces-more-robust-controllers",
    "title": "main",
    "section": "Bayesian Learning Produces More Robust Controllers",
    "text": "Bayesian Learning Produces More Robust Controllers\n\n\n\nConsider the control system:\n\n\nParameter uncertainty: \\(p \\sim \\mathcal{N}(\\hat{p}, \\sigma_p^2)\\).\nMeasurement noise: \\(x \\sim \\mathcal{N}(x, \\sigma^2)\\).\n\n\n\\[\n\\Sigma: \\quad\n\\begin{cases}\n  dx(t) &= (p+\\theta)x(t) dt + \\theta \\sigma dW_t, \\\\\n  x(0) &= 1.\n\\end{cases}\n\\] \\[\nx(t) = e^{(p+\\theta)t} + \\theta \\sigma \\int_0^t e^{(p+\\theta)(t-s)}dW_s.\n\\]\n\n\n\n\n\\[\n\\mathcal{J} = \\int_0^T \\left( \\frac{1}{2}qx(t)^2 + \\frac{1}{2}ru(t)^2  \\right)dt.\n\\]\n\n\n\n\n\n\nLemma\n\n\nThe conditional expectation \\(\\mathbb{E}[\\mathcal{J} \\mid p]\\) of the performance index given the system parameter \\(p\\) is\n\\[\n\\mathbb{E}[\\mathcal{J} \\mid p] =\n-\\frac{1}{4}\\frac{q+r\\theta^2}{p+\\theta}\\left[ \\theta^2 \\sigma^2 T +\n\\left(1-e^{2 T (p+\\theta)}\\right) \\left(1+\\frac{1}{2}\\frac{\\theta^2\n\\sigma^2}{p+\\theta}\\right) \\right]\n\\]\n\n\n\n\n\n\nSimplest dynamical system with a continuous flow depending on\n\nuncertain system parameter \\(p\\) modelled as a normal distribution\ncontroller parameter \\(\\theta\\)\n\nThe stochastic part models the measurement uncertainty\n\nstate \\(x\\) is sensed through a gaussian noise process\n\nSolution can be found for this simple case.\nConsider the cost function being the state and the control not being zero.\n\nInserting the solution \\(x(t)\\) into the cost fcn. allows us to compute its conditional expectation over the measurement distribution"
  },
  {
    "objectID": "main.html#conditional-expectation",
    "href": "main.html#conditional-expectation",
    "title": "main",
    "section": "Conditional Expectation",
    "text": "Conditional Expectation\n\n\n\\[\n\\mathbb{E}[\\mathcal{J} \\mid p] =\n-\\frac{1}{4}\\frac{q+r\\theta^2}{p+\\theta}\\left[ \\theta^2 \\sigma^2 T +\n\\left(1-e^{2 T (p+\\theta)}\\right) \\left(1+\\frac{1}{2}\\frac{\\theta^2\n\\sigma^2}{p+\\theta}\\right) \\right]\n\\]\n\n\n\n\n\nProof\n\n\nSubstituting the solution of the SDE into the performance measure yields\n\\[\n\\begin{aligned} \\mathcal{J} =\n        & -\\frac{1}{4}\\frac{q+r\\theta^2}{p+\\theta}\\left(1 +\n        e^{2T(p+\\theta)}\\right) +\n        (q+r\\theta^2)\\theta\\sigma \\int_0^T\n        e^{(p+\\theta)t} \\int_0^t e^{(p+\\theta)(t-s)}dW_s\n        dt + \\frac{1}{2}(q+r\\theta^2)\\theta^2\n        \\sigma^2 \\int_0^T \\left( \\int_0^t\n        e^{(p+\\theta)(t-s)} dW_s  \\right)^2 dt\n\\end{aligned}\n\\]\nThe conditional expectation of this quantity given the system parameter \\(p\\) under the distribution induced by the Wiener process may be computed in closed-form using Ito calculus.\n\\[\n\\begin{aligned}\n\\mathbb{E}_W\\left[\\mathcal{J} \\mid p \\right] &= -\\frac{1}{4}\\frac{q+r\\theta^2}{p+\\theta}\\left(1 - e^{2T(p+\\theta)}\\right) +\n        (q+r\\theta^2)\\theta\\sigma\\int_0^Te^{(p+\\theta)t}\\mathbb{E}_W\\left[\\int_0^t\n        e^{(p+\\theta)(t-s)} dW_s~\\Big\\rvert p\\right] dt + \\\\\n        &\\frac{1}{2}(q+r\\theta)^2\\theta^2\\sigma^2\\int_0^T\\mathbb{E}_W\\left[\\left(\\int_0^t\n        e^{(p+\\theta)(t-s)} dW_s \\right)^2~\\bigg\\rvert p\\right] dt \\\\\n        &=-\\frac{1}{4}\\frac{q+r\\theta^2}{p+\\theta}\\left(1 -\n        e^{2T(p+\\theta)}\\right) +\n        \\frac{1}{2}(q+r\\theta^2)\\theta^2\\sigma^2\\int_0^T\\left(\\int_0^t\n        e^{2(p+\\theta)(t-s)} ds \\right) dt \\\\\n        &=-\\frac{1}{4}\\frac{q+r\\theta^2}{p+\\theta}\\left(1 - e^{2T(p+\\theta)}\\right) +\n        \\frac{1}{2}(q+r\\theta^2)\\theta^2\\sigma^2\\int_0^T\n        -\\frac{1}{2(p+\\theta)}\\left(1 - e^{2T(p+\\theta)}\\right) dt \\\\\n        &=-\\frac{1}{4}\\frac{q+r\\theta^2}{p+\\theta} \\left[ \\theta^2 \\sigma^2 T +\n        \\left(1 - e^{2T(p+\\theta)}\\right) \\left(1 +\n        \\frac{1}{2}\\frac{\\theta^2\\sigma^2}{p+\\theta}\\right)\\right].\n\\end{aligned}\n\\]\n\nüüß\n\n\n\n\n\n\n\nThe derivation of this conditional expectation follows the rules of Ito calculus and the Wiener process to perform some simplifications.\nThis computation is important because it allows us to take a further expectation to compute the total expectation \\(\\mathbb{E}\\mathcal{J}\\) of the cost fcn.\nThe total expectation can only be computed numerically and this computation can then be autodiff‚Äôd to find its gradient w.r.t. the parameter \\(\\theta\\)"
  },
  {
    "objectID": "main.html#optimal-controller",
    "href": "main.html#optimal-controller",
    "title": "main",
    "section": "Optimal Controller",
    "text": "Optimal Controller\n\n\n\n\n\n\n\n\nOptimal controller \\(|\\theta^\\star|\\) minimizing \\(\\mathbb{E}\\mathcal{J}\\)\n\n\nMinimal expected cost \\(\\mathbb{E}\\mathcal{J}\\)"
  },
  {
    "objectID": "main.html#optimal-controller-1",
    "href": "main.html#optimal-controller-1",
    "title": "main",
    "section": "Optimal Controller",
    "text": "Optimal Controller\n\n\n\n\n\nOptimal controller \\(|\\theta^\\star|\\) minimizing \\(\\mathbb{E}\\mathcal{J}\\)\n\n\n\n\n\nMinimal expected cost \\(\\mathbb{E}\\mathcal{J}\\)\n\n\n\n\n\nOptimal control parameter a nontrivial function of \\(\\sigma\\) and \\(\\sigma_p\\).\nBayesian learning strikes the right trade-off.\n\n\n\n\nThe gradient information may be used to deduce the optimal control parameter \\(\\theta\\) under the various sources of uncertaintly.\nThere is a nontrivial trade-off \\(\\ldots\\)"
  },
  {
    "objectID": "main.html#bayesian-neuralpbc",
    "href": "main.html#bayesian-neuralpbc",
    "title": "main",
    "section": "Bayesian NeuralPbc",
    "text": "Bayesian NeuralPbc\n\n\n\n\n\n\n\nNeuralPbc Optimization Problem\n\n\n\\[\n\\begin{aligned}\n\\underset{\\theta}{\\text{minimize}} && J(\\phi, u^\\theta) &= \\mathbb{E}_{x_0 \\in \\mathcal{D}_N}[ \\ell( \\phi(x_0, u, T), u) ], \\\\\n\\text{subject to} &&\n\\begin{bmatrix}\n  \\dot{q} \\\\ \\dot{p}\n\\end{bmatrix} &=\n\\begin{bmatrix}\n  0 & I \\\\ -I & 0\n\\end{bmatrix}\n\\begin{bmatrix} \\nabla_q H \\\\ \\nabla_p H \\end{bmatrix} +\n\\begin{bmatrix}\n  0 \\\\ \\Omega\n\\end{bmatrix} u^{\\theta},\n\\\\\n&& u^\\theta &= \\Omega^{\\dagger}(\\nabla_q H  - \\nabla_q H_d^\\theta).\n\\end{aligned}\n\\]\n\n\n\n\n\n\n\n\n\n\nBayesian NeuralPbc Optimization Problem\n\n\n\\[\n\\begin{aligned}\n    \\underset{z}{\\text{minimize}} && J(\\phi, u^\\theta) &= \\mathbb{E}_{x_0 \\in \\mathcal{D}_N}[ \\ell( \\phi(x_0, u, T), u) ], \\\\\n    \\text{subject to} &&\n    \\begin{bmatrix}\n    \\dot{q} \\\\ \\dot{p}\n    \\end{bmatrix} &=\n    \\begin{bmatrix}\n    0 & I \\\\ -I & 0\n    \\end{bmatrix}\n    \\begin{bmatrix} \\nabla_q H \\\\ \\nabla_p H \\end{bmatrix} +\n    \\begin{bmatrix}\n    0 \\\\ \\Omega\n    \\end{bmatrix} u^{\\theta},\n    \\\\\n    && u^\\theta &= \\Omega^{\\dagger}(\\nabla_q H  - \\nabla_q H_d^\\theta),\\\\\n    && \\theta &\\sim Q(\\theta; z).\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "main.html#bayesian-neuralpbc-1",
    "href": "main.html#bayesian-neuralpbc-1",
    "title": "main",
    "section": "Bayesian NeuralPbc",
    "text": "Bayesian NeuralPbc\n\n\n\n\n\nNeuralPbc Optimization Problem\n\n\n\\[\n\\begin{aligned}\n\\underset{\\theta}{\\text{minimize}} && J(\\phi, u^\\theta) &= \\mathbb{E}_{x_0 \\in \\mathcal{D}_N}[ \\ell( \\phi(x_0, u, T), u) ], \\\\\n\\text{subject to} &&\n\\begin{bmatrix}\n  \\dot{q} \\\\ \\dot{p}\n\\end{bmatrix} &=\n\\begin{bmatrix}\n  0 & I \\\\ -I & 0\n\\end{bmatrix}\n\\begin{bmatrix} \\nabla_q H \\\\ \\nabla_p H \\end{bmatrix} +\n\\begin{bmatrix}\n  0 \\\\ \\Omega\n\\end{bmatrix} u^{\\theta},\n\\\\\n&& u^\\theta &= \\Omega^{\\dagger}(\\nabla_q H  - \\nabla_q H_d^\\theta).\n\\end{aligned}\n\\]\n\n\n\n\n\n\n\n\nBayesian NeuralPbc Optimization Problem\n\n\n\\[\n\\begin{aligned}\n    \\underset{z}{\\text{minimize}} && J(\\phi, u^\\theta) &= \\mathbb{E}_{x_0 \\in \\mathcal{D}_N}[ \\ell( \\phi(x_0, u, T), u) ], \\\\\n    \\text{subject to} &&\n    \\begin{bmatrix}\n    \\dot{q} \\\\ \\dot{p}\n    \\end{bmatrix} &=\n    \\begin{bmatrix}\n    0 & I \\\\ -I & 0\n    \\end{bmatrix}\n    \\begin{bmatrix} \\nabla_q H \\\\ \\nabla_p H \\end{bmatrix} +\n    \\begin{bmatrix}\n    0 \\\\ \\Omega\n    \\end{bmatrix} u^{\\theta},\n    \\\\\n    && u^\\theta &= \\Omega^{\\dagger}(\\nabla_q H  - \\nabla_q H_d^\\theta),\\\\\n    && \\theta &\\sim Q(\\theta; z).\n\\end{aligned}\n\\]\n\n\n\n\n\n\n\nThe parameter \\(z\\) of the posterior \\(Q(\\theta;z)\\) is inferred from running cost \\(J(\\phi, u^\\theta)\\)\n\\(H_d^\\theta\\) is a Bayesian neural network (BNN)"
  },
  {
    "objectID": "main.html#uncertainty-modeling",
    "href": "main.html#uncertainty-modeling",
    "title": "main",
    "section": "Uncertainty Modeling",
    "text": "Uncertainty Modeling\n\nWe provide more structure to the variance of the Bayesian controllers\n\n\n\n\nBayesian NeuralPbc Optimization Problem\n\n\n\\[\n\\begin{aligned}\n    \\underset{z}{\\text{minimize}} && J(\\phi, u^\\theta) &= \\mathbb{E}_{x_0 \\in \\mathcal{D}_N}[ \\ell( \\phi(x_0, u, T), u) ], \\\\\n    \\text{subject to} &&\n    \\mathop{}\\!\\mathrm{d}x &= \\left(\n        \\begin{bmatrix}\\phantom{-}\\nabla_p H \\\\-\\nabla_q H \\end{bmatrix} + \\begin{bmatrix} 0 \\\\ \\Omega \\end{bmatrix} u^{\\theta}(x) \\right) \\mathop{}\\!\\mathrm{d}t + \\nabla_x u(x) \\mathop{}\\!\\mathrm{d}W_t, \\\\\n    && u^\\theta &= \\Omega^{\\dagger}(\\nabla_q H  - \\nabla_q H_d^\\theta),\\\\\n    && \\theta &\\sim Q(\\theta; z), \\\\\n    && p_s &\\sim \\mathcal{N}(\\hat{p}_s, \\sigma_p).\n\\end{aligned}\n\\]\n\n\n\n\nObjective: maximize Elbo\n\n\\[\\begin{gather*}\n  \\mathcal{L}(J,z) = \\mathbb{E}_{\\theta \\sim Q} \\left[\\ln(P(J \\mid \\theta)P(\\theta)) - \\ln(Q(\\theta;z)) \\right] \\\\\n  P(J | \\theta) = \\mathcal{N}(J \\; | \\; 0, s).\n\\end{gather*}\\]"
  },
  {
    "objectID": "main.html#neuralpbc-hybrid-system",
    "href": "main.html#neuralpbc-hybrid-system",
    "title": "main",
    "section": "NeuralPbc: Hybrid System",
    "text": "NeuralPbc: Hybrid System\n\n\n\n\n\n\n\nPassive Smooth System\n\n\n\\[\nH\\left(  x(t_1) \\right) \\leq  H\\left(  x(t_0) \\right) + \\int_{t_0}^{t_1} s(u(t), y(t)) \\, \\text{d}t\n\\]\n\n\n\n\n\n¬†\n\n\n\n\n\nPassive Hybrid System\n\n\n\\[\\begin{gather*}\nH\\left(  x(t_1) \\right) \\leq  H\\left(  x(t_0) \\right) + \\int_{t_0}^{t_1} s(u(t), y(t)) \\, \\text{d}t \\\\\nH(x^+) \\leq H(x^-)\n\\end{gather*}\\]\n\n\n\n\n\n\n\n\n\n\nNeuralPbc for contact-rich system\n\n\n\\[\\begin{aligned}\n    \\underset{\\theta}{\\textrm{minimize}}\n    & & J(\\phi, u^\\theta) &= \\mathbb{E}_{x_0 \\in \\mathcal{D}_N}[ \\ell( \\phi(x_0, u, T), u) ], \\\\%\n    \\textrm{subject to}\n    & & M(q) &\\mathop{}\\!\\mathrm{d}\\dot{q} + h(q, \\dot{q}, \\theta)\\mathop{}\\!\\mathrm{d}t - \\mathop{}\\!\\mathrm{d}R  = 0,\\\\%\n    & & u^{\\theta} &= \\Omega^{\\dagger}(\\nabla_q H  - \\nabla_q H_d).%\n\\end{aligned}\\]"
  },
  {
    "objectID": "main.html#bayesian-neuralpbc-hybrid-system",
    "href": "main.html#bayesian-neuralpbc-hybrid-system",
    "title": "main",
    "section": "Bayesian NeuralPbc: Hybrid System",
    "text": "Bayesian NeuralPbc: Hybrid System\n\n\n\nNeuralPbc for contact-rich system\n\n\n\\[\\begin{aligned}\n    \\underset{z}{\\textrm{minimize}}\n    & & & J(\\phi, u) = \\mathbb{E}_{x_0 \\in \\mathcal{D}_N}[\\ell(\\phi(x_0, u^\\theta, T), u^\\theta)], \\\\\n    \\textrm{subject to}\n    & & M(q) &\\mathop{}\\!\\mathrm{d}\\dot{q} + h(q, \\dot{q}, \\theta)\\mathop{}\\!\\mathrm{d}t - \\mathop{}\\!\\mathrm{d}R  = 0,\\\\\n    & & u^{\\theta} &= \\Omega^{\\dagger}(\\nabla_q H  - \\nabla_q H_d^\\theta), \\\\\n    & & p_s &\\sim \\mathbb{U}(p_{min}, p_{max}), \\\\\n    & & \\theta &\\sim Q(\\theta; z).\n\\end{aligned}\\]\n\n\n\n\n\n\n\n\n\n\n\\(p_s \\sim \\mathbb{U}(0 \\textrm{cm}, 2\\textrm{cm})\\)"
  },
  {
    "objectID": "main.html#cart-pole-and-cart-pole-with-walls",
    "href": "main.html#cart-pole-and-cart-pole-with-walls",
    "title": "main",
    "section": "Cart-Pole and Cart-Pole with Walls",
    "text": "Cart-Pole and Cart-Pole with Walls"
  },
  {
    "objectID": "main.html#deterministic-vs.-bayesian",
    "href": "main.html#deterministic-vs.-bayesian",
    "title": "main",
    "section": "Deterministic vs.¬†Bayesian",
    "text": "Deterministic vs.¬†Bayesian\n\n\n\n\n\n\n\n\n\n\n\nSubtracting rings from the wheel\n\ndecreases wheel mass\ndecreases wheel and pendulum inertia\nmoves the center of mass"
  },
  {
    "objectID": "main.html#joint-work-with-university-of-kentucky",
    "href": "main.html#joint-work-with-university-of-kentucky",
    "title": "main",
    "section": "Joint Work with University of Kentucky",
    "text": "Joint Work with University of Kentucky\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) State partition according to NN\n\n\n\n\n\n\n\n\n\n\n\n(b) Experimental set up\n\n\n\n\n\n\n\nFigure¬†1: NSF Award #2330794"
  },
  {
    "objectID": "main.html#results-from-the-joint-work",
    "href": "main.html#results-from-the-joint-work",
    "title": "main",
    "section": "Results from the Joint Work",
    "text": "Results from the Joint Work"
  },
  {
    "objectID": "main.html#where-the-roboticscontrol-field-is-going",
    "href": "main.html#where-the-roboticscontrol-field-is-going",
    "title": "main",
    "section": "Where the Robotics/Control Field is Going?",
    "text": "Where the Robotics/Control Field is Going?"
  },
  {
    "objectID": "main.html#future-research-robustness-of-gnns-for-robot-control",
    "href": "main.html#future-research-robustness-of-gnns-for-robot-control",
    "title": "main",
    "section": "Future Research: Robustness of GNNs for Robot Control",
    "text": "Future Research: Robustness of GNNs for Robot Control\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCollaboration: Robustness of Networked Systems\n\n\n\nDr.¬†Waseem Abbas\nDr.¬†Justin Ruths"
  },
  {
    "objectID": "main.html#future-research-convex-optimization-layers-on-gnns",
    "href": "main.html#future-research-convex-optimization-layers-on-gnns",
    "title": "main",
    "section": "Future Research: Convex Optimization Layers on GNNs",
    "text": "Future Research: Convex Optimization Layers on GNNs\n\n\n\n\n\n\nEnd-to-end formation control with GNNs1\n\n\n\n\n\n\n\n\n\n\nPropagate features to neighbors using convex-opt layers rather than MLPs.\nAlternately, implement the message Aggregate phase using convex-opt layers.\n\n\n\n\n\n\nCollaboration: Networked Systems and Convex Opt.\n\n\n\nDr.¬†Justin Ruths\nDr.¬†Waseem Abbas\nDr.¬†Mark Spong\n\n\n\n\n\n\n\n\n\n\nGNN for Legged Robot Contact Perception2\n\n\n\n\n\n\n\n\n\n\n\n\nJiang, Chao et. al.¬†(2023) End-to-end decentralized formation control using a GNN-based learning method.Butterfield, Daniel et. al.¬†(2024) MI-HGNN: Morphology-Informed Heterogeneous Graph Neural Network for Legged Robot Contact Perception."
  },
  {
    "objectID": "main.html#future-research-representation-learning-through-llms",
    "href": "main.html#future-research-representation-learning-through-llms",
    "title": "main",
    "section": "Future Research: Representation-learning through LLMs",
    "text": "Future Research: Representation-learning through LLMs\n\n\n\n\n\n\n\n‚¨ÜÔ∏è\n\n\n\n\n\n\n\n\n\n\n\nUtilize a causal transformer to learn trajectory representations.\n\n\nCan learn them for each joint.\n\n\nUse these representations as feature vectors of a subsequent GNN.\n\n\n\n\n\n\n\nCollaboration: Representation Learning\n\n\n\nDr.¬†Waseem Abbas\nDr.¬†Yu Xiang from Computer Science\n\n\n\n\n\n\n\n\n\n\n\n\n\nCourtesy of MIT CSAIL"
  },
  {
    "objectID": "main.html#funding-mechanism-nsf-foundational-research-in-robotics",
    "href": "main.html#funding-mechanism-nsf-foundational-research-in-robotics",
    "title": "main",
    "section": "Funding Mechanism: NSF Foundational Research in Robotics",
    "text": "Funding Mechanism: NSF Foundational Research in Robotics"
  },
  {
    "objectID": "main.html#funding-mechanisms-sbir-and-sttrs",
    "href": "main.html#funding-mechanisms-sbir-and-sttrs",
    "title": "main",
    "section": "Funding Mechanisms: SBIR and STTRs",
    "text": "Funding Mechanisms: SBIR and STTRs"
  },
  {
    "objectID": "main.html#funding-mechanism-nih-through-collaborations",
    "href": "main.html#funding-mechanism-nih-through-collaborations",
    "title": "main",
    "section": "Funding Mechanism: NIH through Collaborations",
    "text": "Funding Mechanism: NIH through Collaborations\n\n\n\n\n\n \n\n\n\n\n¬†\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n¬†\n\n\n\n\n\n\n\n\n\n¬†\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCollaboration: Cellular Structures and Imaging\n\n\n\nDr.¬†Chen Cao (Bioeng.)\nDr.¬†Reza Moheimani"
  },
  {
    "objectID": "main.html#loosening-up-chess-and-basketball-1",
    "href": "main.html#loosening-up-chess-and-basketball-1",
    "title": "main",
    "section": "Loosening up: Chess and Basketball",
    "text": "Loosening up: Chess and Basketball\n\n\n\n\nVideo \n\n\n\n\n\n\nRobust Sensing and Data-Driven Control ‚Ä¢ Aykut C. Satici"
  }
]