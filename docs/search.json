[
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "main",
    "section": "",
    "text": "Title: Data-Driven Passivity Based Control of Robotic Locomotion and Manipulation\nAbstract: The recent boom and success of machine learning methods has encouraged efforts in synthesizing controllers that leverage neural networks as function approximators. However, when such controllers are synthesized it is important to take precautions against their potential vulnerabilities against disturbances arising from model uncertainties or measurement noise. In this work we address the automatic robust data-driven controller synthesis problem for robotic manipulation and locomotion. We demonstrate the efficacy of our theoretical results in simulation and real-world experiments on a rimless-wheel and a cart-pole system that contains walls. Our approach performs repeated interactions with a nominal dynamical model to infer a contact-aware passivity-based controller, whose storage function is given by a fully-connected neural network. Contacts, impacts and Coulomb friction are modeled through the linear complementarity problem (LCP), and solved via Lemkeâ€™s algorithm, which allows us to take pertinent gradients for the data-driven technique. Additionally, we improve the robustness properties of the controller under model uncertainties, such as the rimless wheel traversing on uneven terrain, via Bayesian learning.\nBio: Aykut Satici holds a BSc and MSc of Mechatronics Engineering from Sabanci University in Turkey, an MSc of Mathematics, and Ph.D.Â in Electrical Engineering from the University of Texas at Dallas under Prof.Â Mark W. Spong. He worked as a postdoctoral associate at University of Naples, Federico II and at Massachusetts Institute of Technology. Dr.Â Satici is currently an assistant professor of Mechanical and Biomedical Engineering at Boise State University. He has actively contributed to the control, estimation, and robotics research communities for more than 15 years. His research output includes the optimal design of robotic manipulators, optimal control of uncrewed aerial vehicles, multi-agent robot control and estimation, differential geometric methods in nonlinear control, passivity-based control, and control synthesis with machine learning methods."
  },
  {
    "objectID": "main.html#data-driven-passivity-based-control",
    "href": "main.html#data-driven-passivity-based-control",
    "title": "main",
    "section": "Data-Driven Passivity-Based Control",
    "text": "Data-Driven Passivity-Based Control\n\n\nUniversity of Texas at Dallas Seminar\n\n\n\n\nPresenter: Aykut Satici, Ph.D.Â  Mechanical and Biomedical Engineering Department  Boise State University, Boise, Idaho, USA\n\n\nGraduate Students:  Wankun Sirichotiyakul ğŸ“  Nardos Ayele Ashenafi ğŸ“"
  },
  {
    "objectID": "main.html#peer-reviewed-contributions",
    "href": "main.html#peer-reviewed-contributions",
    "title": "main",
    "section": "Peer-Reviewed Contributions",
    "text": "Peer-Reviewed Contributions\n\n\n\nNeuralPbc\n\n\nISER 2020\n\n\nCCTA 2021\n\n\nACC 2022\n\n\nL-CSS 20221\n\n\n\nNeuralIdaPbc\n\n\nIJC 2021\n\n\nTACON 20221\n\n\n\n\n\n\nISER - International Symposium on Experimental Robotics\nCCTA - Conference on Control Technology and Applications\nACC - American Control Conference\nLCSS - Control Systems Letters\nIJC - International Journal of Control\nTACON - Transactions on Automatic Control\n\n\nUnder review"
  },
  {
    "objectID": "main.html#what-is-underactuation",
    "href": "main.html#what-is-underactuation",
    "title": "main",
    "section": "What is Underactuation?",
    "text": "What is Underactuation?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUnderactuation\n\n\n\nNo control input can generate acceleration in arbitrary direction\nControl problem becomes much more complicated"
  },
  {
    "objectID": "main.html#underactuated-robots",
    "href": "main.html#underactuated-robots",
    "title": "main",
    "section": "Underactuated Robots",
    "text": "Underactuated Robots\n\n\n\n\n\n\n\n\nWalking machines\n\n\n\n\nÂ \n\n\n\n\n\nFlying machines\n\n\n\n\n\n\n\n\n\n\n\nTorque-limited manipulators\n\n\n\n\nÂ \n\n\n\n\n\nNonprehensile manipulation"
  },
  {
    "objectID": "main.html#existing-methods",
    "href": "main.html#existing-methods",
    "title": "main",
    "section": "Existing Methods",
    "text": "Existing Methods\n\n\n\n\n\n\n\n\nÂ \n\n\n\nStrengths\n\nStability guarantees\nClosed-form policy\n\nWeaknesses\n\nModel uncertainties\nNeed to solve PDEs\n\n\n\n\n\n\n\n\n\n\nReinforcement learning \n\n\nÂ \n\n\n\nStrengths\n\nMore general\nUnknown dynamics OK\n\nWeaknesses\n\nSample complexity\nStability guarantees?"
  },
  {
    "objectID": "main.html#our-methods",
    "href": "main.html#our-methods",
    "title": "main",
    "section": "Our Methods",
    "text": "Our Methods\n\n\n\n\nÂ \n\n\n\n\n\nÂ \n\n\n\n\n\n\n\n\n\n\n\n\nNeuralPbc\nNeuralIdaPbc\n\n\n\n\nHdH_d neural net\nHdH_d quadratic in pp\n\n\nSample state space\nSample configuration space\n\n\nNo stability certificate\nStability certificate\n\n\nMore flexible\nAs applicable as IdaPbc"
  },
  {
    "objectID": "main.html#robustness-via-bayesian-learning",
    "href": "main.html#robustness-via-bayesian-learning",
    "title": "main",
    "section": "Robustness via Bayesian Learning",
    "text": "Robustness via Bayesian Learning\n\n\n\n\n\n\nSystem Parameter Uncertainty and Measurement Noise\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLess robust\n\n\n\n\n\n\n\n\n\nMore robust"
  },
  {
    "objectID": "main.html#dissipativity",
    "href": "main.html#dissipativity",
    "title": "main",
    "section": "Dissipativity",
    "text": "Dissipativity\n\nA dynamical system\nÎ£:{xÌ‡=f(x,u)y=h(x,u)xâˆˆğ’³âŠ‚â„2n,uâˆˆğ’°âŠ‚â„m\n\\Sigma: \\quad\n\\begin{cases}\n  \\dot{x} &= f(x,u) \\\\\n  y &= h(x,u)\n\\end{cases}\n\\quad x \\in \\mathcal{X} \\subset \\mathbb{R}^{2n}, \\, u \\in \\mathcal{U} \\subset \\mathbb{R}^{m} \n\nis dissipative with respect to some supply rate ss if there exists a storage function â„‹:ğ’³â†’â„+\\mathcal{H}: \\mathcal{X} \\to \\mathbb{R}^{+} such that\nâ„‹(x(t1))â‰¤â„‹(x(t0))+âˆ«t0t1s(u(t),y(t))dt\n\\mathcal{H}\\left(  x(t_1) \\right) \\leq  \\mathcal{H}\\left(  x(t_0) \\right) + \\int_{t_0}^{t_1} s(u(t), y(t)) \\, \\text{d}t\n\nfor all x(t0)=x0x(t_0) = x_0, all input uu, and all t1â‰¥t0t_1 \\geq t_0"
  },
  {
    "objectID": "main.html#dissipativity-1",
    "href": "main.html#dissipativity-1",
    "title": "main",
    "section": "Dissipativity",
    "text": "Dissipativity\nâ„‹(x(t1))â‰¤â„‹(x(t0))+âˆ«t0t1s(u(t),y(t))dt\n\\mathcal{H}\\left(  x(t_1) \\right) \\leq  \\mathcal{H}\\left(  x(t_0) \\right) + \\int_{t_0}^{t_1} s(u(t), y(t)) \\, \\text{d}t\n\n\n\n\nDissipation Inequality\n\n\n\n\nStored energy at t1t_1 is at most equal to stored energy at t0t_0, plus externally supplied energy s(u,y)s(u,y)\nNo generation of energy, only internal dissipation\nWith s(t)â‰¡0s(t) \\equiv 0, trajectories tend towards minimum of â„‹\\mathcal{H}"
  },
  {
    "objectID": "main.html#passivity",
    "href": "main.html#passivity",
    "title": "main",
    "section": "Passivity",
    "text": "Passivity\n\nThe system Î£\\Sigma is passive if it is dissipative with supply rate\ns=uâŠ¤y.s = u^\\top y.\nIt is output strictly passive if it is dissipative with supply rate\ns=uâŠ¤yâˆ’Î´âˆ¥yâˆ¥2,Î´>0.s = u^\\top y - \\delta \\lVert y \\rVert^2, \\; \\delta > 0.\nIt is input strictly passive if it is dissipative with supply rate\ns=uâŠ¤yâˆ’Î´âˆ¥uâˆ¥2,Î´>0.s = u^\\top y - \\delta \\lVert u \\rVert^2, \\; \\delta > 0."
  },
  {
    "objectID": "main.html#passive-system-example",
    "href": "main.html#passive-system-example",
    "title": "main",
    "section": "Passive System Example",
    "text": "Passive System Example\n\n\n\n\n\nKirchoffâ€™s law\nv=Ri+1Câˆ«0ti(Ï„)dÏ„+Ldidtviâˆ’Ri2=ddt(12C(âˆ«0ti(Ï„)dÏ„)2âŸğ’±+12Li2âŸğ’¯)\n\\begin{aligned}\nv &= Ri + \\frac{1}{C} \\int_{0}^{t} i(\\tau) \\, \\text{d}\\tau + L \\frac{\\text{d} i}{\\text{d} t} \\\\\nvi - Ri^2 &= \\frac{\\text{d}}{\\text{d} t} \\left( \n  \\underbrace{\\frac{1}{2C} \\left( \\int_{0}^{t} i(\\tau)\\, \\text{d} \\tau \\right)^2}_{\\mathcal{V}} + \n  \\underbrace{\\frac{1}{2} Li^2}_{\\mathcal{T}}  \n\\right)\n\\end{aligned}\n\n\n\nLet â„‹=ğ’±+ğ’¯\\mathcal{H} = \\mathcal{V} + \\mathcal{T}, integrate to obtain\nâ„‹(t)âŸavailableâˆ’â„‹(0)âŸinitial=âˆ«0tv(Ï„)i(Ï„)dÏ„âŸsuppliedâˆ’âˆ«0tRi2(Ï„)dÏ„âŸdissipated<âˆ«0tv(Ï„)i(Ï„)dÏ„\n\\underbrace{\\mathcal{H}(t)}_{\\textrm{available}} -\n\\underbrace{\\mathcal{H}(0)}_{\\textrm{initial}} \n= \n\\underbrace{\\int_{0}^{t} v(\\tau)i(\\tau)\\, \\text{d} \\tau}_{\\textrm{supplied}} - \n\\underbrace{\\int_{0}^{t} Ri^2(\\tau)\\, \\text{d} \\tau}_{\\textrm{dissipated}}\n<\n\\int_{0}^{t} v(\\tau) i(\\tau) \\, \\text{d} \\tau"
  },
  {
    "objectID": "main.html#stability-of-passive-systems",
    "href": "main.html#stability-of-passive-systems",
    "title": "main",
    "section": "Stability of Passive Systems",
    "text": "Stability of Passive Systems\n\nÎ£:{xÌ‡=f(x,u),f(0,0)=0,y=h(x,u),h(0,0)=0,\n\\Sigma: \\quad\n\\begin{cases}\n  \\dot{x} &= f(x,u), && f(0,0) = 0, \\\\\n  y &= h(x,u), && h(0,0) = 0,\n\\end{cases}\n\nuâŠ¤yâ‰¥â„‹Ì‡=âˆ‚â„‹âˆ‚xf(x,u),â„‹â‰¥0,yâ‰¡0âŸ¹xâ‰¡0u^{\\top} y \\geq \\dot{\\mathcal{H}} = \\frac{\\partial\\mathcal{H}}{\\partial x} f(x,u),\\quad \\mathcal{H} \\geq 0,\\quad y \\equiv 0 \\implies x \\equiv 0\n\n\n\nLemma (Khalil, 2002)\n\n\nThe origin of Î£\\Sigma is:\n\nstable if Î£\\Sigma is passive,\nasymptotically stable if Î£\\Sigma is output strictly passive,\nglobally asymptotically stable if Î£\\Sigma is output strictly passive and the storage function â„‹(x)â†’âˆ\\mathcal{H}(x) \\to \\infty as âˆ¥xâˆ¥â†’âˆ\\lVert x \\rVert \\to \\infty (radially unbounded)\n\n\n\n\n\n\nNotice that we only require that the function â„‹\\mathcal{H} be positive semidefinite and not necessarily positive definite as per usual Lyapunov conditions.\nObservability (detectability) ensures LaSalleâ€™s theorem works."
  },
  {
    "objectID": "main.html#passivity-based-control-pbc",
    "href": "main.html#passivity-based-control-pbc",
    "title": "main",
    "section": "Passivity-Based Control (PBC)",
    "text": "Passivity-Based Control (PBC)\n\nÎ£o:{xÌ‡=f(x)+g(x)u,y=h(x)\n\\Sigma_o: \\quad\n\\begin{cases}\n  \\dot{x} &= f(x) + g(x)u, \\\\\n  y &= h(x)\n\\end{cases}\n\nMain idea â€” Select u(x)=ues+udiu(x) = u_{es} + u_{di} that renders the closed-loop system passive.\nÎ£d:{xÌ‡=fd(x)+g(x)udi,fd:=f(x)+g(x)ues(x)yd=hd(x)\n\\Sigma_d: \\quad\n\\begin{cases}\n  \\dot{x} &= f_d(x) + g(x) u_{di}, \\quad f_d := f(x) + g(x) u_{es}(x) \\\\\n  y_d &= h_d(x)\n\\end{cases}\n\nControl problem is cast as a search for HdH_d and hdh_d s.t. HÌ‡dâ‰¤ydâŠ¤udi\\dot{H}_d \\leq y_d^\\top u_{di}"
  },
  {
    "objectID": "main.html#pbc-example---simple-pendulum",
    "href": "main.html#pbc-example---simple-pendulum",
    "title": "main",
    "section": "PBC Example - Simple Pendulum",
    "text": "PBC Example - Simple Pendulum\n\n\n\n\nSystem Dynamics\n\n\nH(q,p)=12Jâˆ’1p2+mgl(1âˆ’cosq)H(q,p) = \\frac{1}{2} J^{-1} p^2 + mgl (1 - \\cos q)\n[qÌ‡pÌ‡]=[âˆ’01âˆ’10][âˆ‡qHdâˆ‡pHd]+[0G]udi,y=qÌ‡\n\\begin{bmatrix} \\dot{q} \\\\ \\dot{p} \\end{bmatrix} = \n\\begin{bmatrix} \\phantom{-}0 & 1 \\\\ -1 & 0 \\end{bmatrix} \n\\begin{bmatrix} \\nabla_q H_{\\phantom{d}} \\\\ \\nabla_p H_{\\phantom{d}} \\end{bmatrix} +\n\\begin{bmatrix} 0 \\\\ G \\end{bmatrix} u_\\phantom{di},\n\\qquad y = \\dot{q}\n\n\nChoose u=ues+udiu = u_{es} + u_{di} that transforms system into a passive one with xâ‹†=(qâ‹†,0)x^\\star = (q^\\star, 0) \n\n\nGues=âˆ‡qHâˆ’âˆ‡qHd,Gudi=âˆ’GKDGâŠ¤âˆ‡pHdGu_{es} = \\nabla_q H - \\nabla_q H_d , \\quad Gu_{di} = -GK_D G^\\top \\nabla_p H_d\n\n\n\n[qÌ‡pÌ‡]=[âˆ’01âˆ’10][âˆ‡qHdâˆ‡pHd]+[0G]udi,y=qÌ‡\n\\begin{bmatrix} \\dot{q} \\\\ \\dot{p} \\end{bmatrix} = \n\\begin{bmatrix} \\phantom{-}0 & 1 \\\\ -1 & 0 \\end{bmatrix} \n\\begin{bmatrix} \\nabla_q H_d \\\\ \\nabla_p H_d \\end{bmatrix} +\n\\begin{bmatrix} 0 \\\\ G \\end{bmatrix} u_{di},\n\\qquad y = \\dot{q}\n\n\n\n[qÌ‡pÌ‡]=[âˆ’01âˆ’1âˆ’GKDGâŠ¤][âˆ‡qHdâˆ‡pHd],y=qÌ‡\n\\begin{bmatrix} \\dot{q} \\\\ \\dot{p} \\end{bmatrix} = \n\\begin{bmatrix} \\phantom{-}0 & 1 \\\\ -1 & -G K_D G^\\top \\end{bmatrix} \n\\begin{bmatrix} \\nabla_q H_d \\\\ \\nabla_p H_d \\end{bmatrix},\n\\qquad y = \\dot{q}"
  },
  {
    "objectID": "main.html#pbc-example---simple-pendulum-1",
    "href": "main.html#pbc-example---simple-pendulum-1",
    "title": "main",
    "section": "PBC Example - Simple Pendulum",
    "text": "PBC Example - Simple Pendulum\n\n\n\n\nControl Synthesis via PBC\n\n\nChoose u=ues+udiu = u_{es} + u_{di} that transforms system into a passive one with xâ‹†=(qâ‹†,0)x^\\star = (q^\\star, 0)\nGues=âˆ‡qHâˆ’âˆ‡qHd,Gudi=âˆ’GKDGâŠ¤âˆ‡pHdGu_{es} = \\nabla_q H - \\nabla_q H_d , \\quad Gu_{di} = -GK_D G^\\top \\nabla_p H_d\n[qÌ‡pÌ‡]=[âˆ’01âˆ’1âˆ’GKDGâŠ¤][âˆ‡qHdâˆ‡pHd],y=qÌ‡\n\\begin{bmatrix} \\dot{q} \\\\ \\dot{p} \\end{bmatrix} = \n\\begin{bmatrix} \\phantom{-}0 & 1 \\\\ -1 & -G K_D G^\\top \\end{bmatrix} \n\\begin{bmatrix} \\nabla_q H_d \\\\ \\nabla_p H_d \\end{bmatrix},\n\\qquad y = \\dot{q}\n\n\nHd(q,p)=12Jâˆ’1p2+Vd(q),Vd(q)=12KP(qâˆ’qâ‹†)2H_d(q,p) = \\frac{1}{2} J^{-1} p^2 + V_d(q), \\quad V_d(q) = \\frac{1}{2} K_{P} \\left( q - q^\\star \\right)^2\n\n\n\nHÌ‡d=âˆ’KD(Jâˆ’1p)2=yâŠ¤udiâ‰¤0\\dot{H}_d = -K_D \\left( J^{-1} p \\right)^2 = y^\\top u_{di} \\leq 0\n\n\nu=âˆ’mglsin(x)âˆ’KP(qâˆ’qâ‹†)âˆ’KDqÌ‡\\boxed{u = -mgl\\sin(x) - K_P(q - q^\\star) - K_D \\dot{q}}"
  },
  {
    "objectID": "main.html#our-methods-1",
    "href": "main.html#our-methods-1",
    "title": "main",
    "section": "Our Methods",
    "text": "Our Methods\n\n\n\n\nÂ \n\n\n\n\n\nÂ \n\n\n\n\n\n\n\n\n\n\n\n\nNeuralPbc\nNeuralIdaPbc\n\n\n\n\nHdH_d neural net\nHdH_d quadratic in pp\n\n\nSample state space\nSample configuration space\n\n\nNo stability certificate\nStability certificate\n\n\nMore flexible\nAs applicable as IdaPbc"
  },
  {
    "objectID": "main.html#bayesian-learning",
    "href": "main.html#bayesian-learning",
    "title": "main",
    "section": "Bayesian Learning",
    "text": "Bayesian Learning\n\np(Î¸âˆ£ğ’Ÿ)=p(ğ’Ÿâˆ£Î¸)âlikelihoodp(Î¸)âpriorâˆ«Î¸p(ğ’Ÿâˆ£Î¸â€²)p(Î¸â€²)dÎ¸â€²âŸevidenceâ‰ˆq(Î¸;z)âŸVI.\np(\\theta \\mid \\mathcal{D}) = \\frac{\\overbrace{p(\\mathcal{D} \\mid\n\\theta)}^{\\text{likelihood}}\\overbrace{p(\\theta)}^{\\text{prior}}}\n{\\underbrace{\\int_\\theta p(\\mathcal{D} \\mid \\theta^\\prime)p(\\theta^\\prime)\nd\\theta^\\prime}_{\\text{evidence}}} \\underbrace{\\approx q(\\theta;\nz)}_{\\text{VI}}.\n\n\n\n\n\n\n\n\nShow ELBO convergence.\n\n\n\n\n\n\nKL-divergence and ELBO\n\n\nDKL=ğ”¼Î¸âˆ¼q[logq(Î¸;z)p(Î¸âˆ£ğ’Ÿ)]=logp(ğ’Ÿ)âˆ’ğ”¼Î¸âˆ¼q[logp(ğ’Ÿâˆ£Î¸)p(Î¸)q(Î¸;z)]â„’(ğ’Ÿ;z)=ğ”¼Î¸âˆ¼q[logp(ğ’Ÿâˆ£Î¸)p(Î¸)âˆ’logq(Î¸;z)]\n\\begin{aligned}\nD_{\\text{KL}} &= \\mathbb{E}_{\\theta \\sim q}\\left[ \\log \\frac{q(\\theta;\nz)}{p(\\theta \\mid \\mathcal{D})}\\right] \\\\\n&= \\log p(\\mathcal{D}) - \\mathbb{E}_{\\theta \\sim q}\\left[ \\log\n\\frac{p(\\mathcal{D} \\mid \\theta) p(\\theta)}{q(\\theta; z)} \\right] \\\\\n\\mathcal{L}(\\mathcal{D}; z) &= \\mathbb{E}_{\\theta \\sim q}\\left[ \\log\np(\\mathcal{D} \\mid \\theta) p(\\theta) - \\log q(\\theta; z) \\right]\n\\end{aligned}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow prob. distribution\n\n\n\n\n\n\nPrediction through marginalization\n\n\nmÌ‚=1Nâˆ‘Î¸âˆ¼qm(x,Î¸).\n\\begin{aligned}\n\\hat{m} &= \\frac{1}{N}\\sum_{\\theta \\sim q} m(x, \\theta).\n\\end{aligned}"
  },
  {
    "objectID": "main.html#system-parameter-uncertainty",
    "href": "main.html#system-parameter-uncertainty",
    "title": "main",
    "section": "System Parameter Uncertainty",
    "text": "System Parameter Uncertainty\n\n\n\nScalar control system\nUncertain drift vector field: pâˆ¼ğ’©(pÌ‚,Ïƒp2)p \\sim \\mathcal{N}(\\hat{p}, \\sigma_p^2).\nNo measurement uncertainty\n\n\n\n\n\n\nÎ£:{xÌ‡=px+u,u(x)=Î¸x,x(0)=1.\n\\Sigma: \\quad\n\\begin{cases}\n  \\dot{x} &= px + u, \\\\\n  u(x) &= \\theta x, \\\\\n  x(0) &= 1.\n\\end{cases}\n x(t)=e(p+Î¸)t.\n  x(t) = e^{(p+\\theta)t}."
  },
  {
    "objectID": "main.html#performance-index",
    "href": "main.html#performance-index",
    "title": "main",
    "section": "Performance Index",
    "text": "Performance Index\n\n\n\n\n\nÎ£:{xÌ‡=px+u,u(x)=Î¸x,x(0)=1.\n\\Sigma: \\quad\n\\begin{cases}\n  \\dot{x} &= px + u, \\\\\n  u(x) &= \\theta x, \\\\\n  x(0) &= 1.\n\\end{cases}\n x(t)=e(p+Î¸)t.\n  x(t) = e^{(p+\\theta)t}.\n\n\n\nÂ \n\n\n\n\n\nQuadratic performance index\n\nqâ‰¥0q \\geq 0, r>0r > 0\n\nTT: control horizon\n\n\n\nğ’¥=âˆ«0T(12qx(t)2+12ru(t)2)dt.\n\\mathcal{J} = \\int_0^T \\left( \\frac{1}{2}qx(t)^2 + \\frac{1}{2}ru(t)^2  \\right)dt."
  },
  {
    "objectID": "main.html#infinite-horizon-best-performance",
    "href": "main.html#infinite-horizon-best-performance",
    "title": "main",
    "section": "Infinite-Horizon Best Performance",
    "text": "Infinite-Horizon Best Performance\n\n\n\n\nğ’¥=âˆ«0T(12qx(t)2+12ru(t)2)dt.\n\\mathcal{J} = \\int_0^T \\left( \\frac{1}{2}qx(t)^2 + \\frac{1}{2}ru(t)^2  \\right)dt.\n ğ’¥Tâ†’âˆ=âˆ’14q+rÎ¸2p+Î¸.\n\\mathcal{J}_{T \\to \\infty} = -\\frac{1}{4}\\frac{q+r \\theta^2}{p+\\theta}.\n\n\n\nÂ \n\n\n\n\nSolve for Î¸\\theta that minimizes ğ’¥âˆ\\mathcal{J}_\\infty: Î¸â‹†=g(p):=âˆ’pâˆ’p2+qr\\theta^\\star = g(p) := -p -\\sqrt{p^2+\\frac{q}{r}}.\n\n\n\n\n\n\nDeterministic\n\n\nÎ¸â‹†=g(pÌ‚):=âˆ’pÌ‚âˆ’pÌ‚2+qr\\theta^\\star = g(\\hat{p}) := -\\hat{p} -\\sqrt{\\hat{p}^2+\\frac{q}{r}}\n\n\n\n\nÂ \n\n\n\n\nProbabilistic\n\n\nfÎ¸â‹†(Î¸â‹†)=1Ïƒp2Ï€(12(1+qrÎ¸â‹†2))exp{âˆ’12Ïƒp2(q2rÎ¸â‹†âˆ’Î¸â‹†2âˆ’pÌ‚)2}\n\\begin{aligned}\nf_{\\theta^\\star}(\\theta^\\star) &= \\frac{1}{\\sigma_p \\sqrt{2\\pi}}\\left( \\\n\\frac{1}{2}\\left(1+\\frac{q}{r{\\theta^\\star}^2}\\right) \\right) \\\\\n&\\exp{\\left\\{ -\\frac{1}{2\\sigma_p^2}\\left( \\frac{q}{2r\\theta^\\star} -\n\\frac{\\theta^\\star}{2} - \\hat{p}  \\right)^2  \\right\\} }\n\\end{aligned}"
  },
  {
    "objectID": "main.html#infinite-horizon-best-performance-1",
    "href": "main.html#infinite-horizon-best-performance-1",
    "title": "main",
    "section": "Infinite-Horizon Best Performance",
    "text": "Infinite-Horizon Best Performance\n\n\n\n\n\n\nDeterministic\n\n\nÎ¸â‹†=g(pÌ‚):=âˆ’pÌ‚âˆ’pÌ‚2+qr\\theta^\\star = g(\\hat{p}) := -\\hat{p} -\\sqrt{\\hat{p}^2+\\frac{q}{r}}\n\n\n\n\nÂ \n\n\n\n\nProbabilistic\n\n\nfÎ¸â‹†(Î¸â‹†)=1Ïƒp2Ï€(12(1+qrÎ¸â‹†2))exp{âˆ’12Ïƒp2(q2rÎ¸â‹†âˆ’Î¸â‹†2âˆ’pÌ‚)2}\n\\begin{aligned}\nf_{\\theta^\\star}(\\theta^\\star) &= \\frac{1}{\\sigma_p \\sqrt{2\\pi}}\\left( \\\n\\frac{1}{2}\\left(1+\\frac{q}{r{\\theta^\\star}^2}\\right) \\right) \\\\\n&\\exp{\\left\\{ -\\frac{1}{2\\sigma_p^2}\\left( \\frac{q}{2r\\theta^\\star} -\n\\frac{\\theta^\\star}{2} - \\hat{p}  \\right)^2  \\right\\} }\n\\end{aligned}"
  },
  {
    "objectID": "main.html#conditional-expectation",
    "href": "main.html#conditional-expectation",
    "title": "main",
    "section": "Conditional Expectation",
    "text": "Conditional Expectation\n\n\nğ”¼[ğ’¥âˆ£p]=âˆ’14q+rÎ¸2p+Î¸[Î¸2Ïƒ2T+(1âˆ’e2T(p+Î¸))(1+12Î¸2Ïƒ2p+Î¸)]\n\\mathbb{E}[\\mathcal{J} \\mid p] =\n-\\frac{1}{4}\\frac{q+r\\theta^2}{p+\\theta}\\left[ \\theta^2 \\sigma^2 T +\n\\left(1-e^{2 T (p+\\theta)}\\right) \\left(1+\\frac{1}{2}\\frac{\\theta^2\n\\sigma^2}{p+\\theta}\\right) \\right]\n\n\n\n\n\n\nProof\n\n\nSubstituting the solution of the SDE into the performance measure yields\nğ’¥=âˆ’14q+rÎ¸2p+Î¸(1+e2T(p+Î¸))+(q+rÎ¸2)Î¸Ïƒâˆ«0Te(p+Î¸)tâˆ«0te(p+Î¸)(tâˆ’s)dWsdt+12(q+rÎ¸2)Î¸2Ïƒ2âˆ«0T(âˆ«0te(p+Î¸)(tâˆ’s)dWs)2dt\n\\begin{aligned} \\mathcal{J} =\n        & -\\frac{1}{4}\\frac{q+r\\theta^2}{p+\\theta}\\left(1 +\n        e^{2T(p+\\theta)}\\right) + \n        (q+r\\theta^2)\\theta\\sigma \\int_0^T\n        e^{(p+\\theta)t} \\int_0^t e^{(p+\\theta)(t-s)}dW_s\n        dt \\; + \\\\ &\\frac{1}{2}(q+r\\theta^2)\\theta^2\n        \\sigma^2 \\int_0^T \\left( \\int_0^t\n        e^{(p+\\theta)(t-s)} dW_s  \\right)^2 dt \n\\end{aligned}\n\nThe conditional expectation of this quantity given the system parameter pp under the distribution induced by the Wiener process may be computed in closed-form using Ito calculus.\nğ”¼W[ğ’¥âˆ£p]=âˆ’14q+rÎ¸2p+Î¸(1âˆ’e2T(p+Î¸))+(q+rÎ¸2)Î¸Ïƒâˆ«0Te(p+Î¸)tğ”¼W[âˆ«0te(p+Î¸)(tâˆ’s)dWs|p]dt+12(q+rÎ¸)2Î¸2Ïƒ2âˆ«0Tğ”¼W[(âˆ«0te(p+Î¸)(tâˆ’s)dWs)2|p]dt=âˆ’14q+rÎ¸2p+Î¸(1âˆ’e2T(p+Î¸))+12(q+rÎ¸2)Î¸2Ïƒ2âˆ«0T(âˆ«0te2(p+Î¸)(tâˆ’s)ds)dt=âˆ’14q+rÎ¸2p+Î¸(1âˆ’e2T(p+Î¸))+12(q+rÎ¸2)Î¸2Ïƒ2âˆ«0Tâˆ’12(p+Î¸)(1âˆ’e2T(p+Î¸))dt=âˆ’14q+rÎ¸2p+Î¸[Î¸2Ïƒ2T+(1âˆ’e2T(p+Î¸))(1+12Î¸2Ïƒ2p+Î¸)].\n\\begin{aligned} \n\\mathbb{E}_W\\left[\\mathcal{J} \\mid p \\right] &= -\\frac{1}{4}\\frac{q+r\\theta^2}{p+\\theta}\\left(1 - e^{2T(p+\\theta)}\\right) +\n        (q+r\\theta^2)\\theta\\sigma\\int_0^Te^{(p+\\theta)t}\\mathbb{E}_W\\left[\\int_0^t\n        e^{(p+\\theta)(t-s)} dW_s~\\Big\\rvert p\\right] dt + \\\\\n        &\\frac{1}{2}(q+r\\theta)^2\\theta^2\\sigma^2\\int_0^T\\mathbb{E}_W\\left[\\left(\\int_0^t\n        e^{(p+\\theta)(t-s)} dW_s \\right)^2~\\bigg\\rvert p\\right] dt \\\\\n        &=-\\frac{1}{4}\\frac{q+r\\theta^2}{p+\\theta}\\left(1 -\n        e^{2T(p+\\theta)}\\right) + \n        \\frac{1}{2}(q+r\\theta^2)\\theta^2\\sigma^2\\int_0^T\\left(\\int_0^t\n        e^{2(p+\\theta)(t-s)} ds \\right) dt \\\\ \n        &=-\\frac{1}{4}\\frac{q+r\\theta^2}{p+\\theta}\\left(1 - e^{2T(p+\\theta)}\\right) + \n        \\frac{1}{2}(q+r\\theta^2)\\theta^2\\sigma^2\\int_0^T\n        -\\frac{1}{2(p+\\theta)}\\left(1 - e^{2T(p+\\theta)}\\right) dt \\\\ \n        &=-\\frac{1}{4}\\frac{q+r\\theta^2}{p+\\theta} \\left[ \\theta^2 \\sigma^2 T +\n        \\left(1 - e^{2T(p+\\theta)}\\right) \\left(1 +\n        \\frac{1}{2}\\frac{\\theta^2\\sigma^2}{p+\\theta}\\right)\\right]. \n\\end{aligned}\n\n\nğŸŸ§"
  },
  {
    "objectID": "main.html#optimal-controller",
    "href": "main.html#optimal-controller",
    "title": "main",
    "section": "Optimal Controller",
    "text": "Optimal Controller\n\n\n\n\nOptimal controller |Î¸â‹†||\\theta^\\star| minimizing ğ”¼ğ’¥\\mathbb{E}\\mathcal{J}\n\n\n\nMinimal expected cost ğ”¼ğ’¥\\mathbb{E}\\mathcal{J}"
  },
  {
    "objectID": "main.html#optimal-controller-1",
    "href": "main.html#optimal-controller-1",
    "title": "main",
    "section": "Optimal Controller",
    "text": "Optimal Controller\n\n\n\n\n\nOptimal controller |Î¸â‹†||\\theta^\\star| minimizing ğ”¼ğ’¥\\mathbb{E}\\mathcal{J}\n\n\n\n\n\nMinimal expected cost ğ”¼ğ’¥\\mathbb{E}\\mathcal{J}\n\n\n\n\n\nOptimal control parameter a nontrivial function of Ïƒ\\sigma and Ïƒp\\sigma_p.\nBayesian learning strikes the right trade-off."
  },
  {
    "objectID": "main.html#motivation-1",
    "href": "main.html#motivation-1",
    "title": "main",
    "section": "Motivation",
    "text": "Motivation\n\nNeuralPbc is flexible, but guaranteeing stability is hard\nAdditional structure of IdaPbc facilitates stability analysis\n\n\n[qÌ‡pÌ‡]=[0Iâˆ’I0][âˆ‡qHâˆ‡pH]+[0G]u \\begin{bmatrix} \\dot{q} \\\\ \\dot{p} \\end{bmatrix} = \\begin{bmatrix}0 & I \\\\ -I & 0\\end{bmatrix} \\begin{bmatrix} \\nabla_q H \\\\ \\nabla_p H  \\end{bmatrix} + \\begin{bmatrix} 0 \\\\ G \\end{bmatrix} u  \nClosed-loop port-Hamiltonian dynamics:\n\n[qÌ‡pÌ‡]=[0Mâˆ’1Mdâˆ’MdMâˆ’1J2(q,p)âˆ’GKvGâŠ¤][âˆ‡qHdâˆ‡pHd]\n\\begin{bmatrix} \\dot{q} \\\\ \\dot{p} \\end{bmatrix}\n=\n\\begin{bmatrix}0 & M^{-1}M_d \\\\ -M_dM^{-1} & J_2(q,p) - GK_vG^\\top\\end{bmatrix}\n\\begin{bmatrix} \\nabla_q H_d \\\\ \\nabla_p H_d \\end{bmatrix}\n  \nHd=12pâŠ¤Md(q)âˆ’1p+Vd(q),Mdâ‰»0H_d = \\frac{1}{2} p^{\\top} M_d(q)^{-1} p + V_d(q),\\, M_d \\succ 0\n\n\nFurther structure not only facilitates stability analysis but also restricts the search to a pd matrix MdM_d and VdV_d.\nThis search may be performed solely on the configuration space."
  },
  {
    "objectID": "main.html#neuralpbc-problem-statement",
    "href": "main.html#neuralpbc-problem-statement",
    "title": "main",
    "section": "NeuralPbc Problem Statement",
    "text": "NeuralPbc Problem Statement\n\nConsider the mechanical system\n[qÌ‡pÌ‡]=[âˆ’01âˆ’10][âˆ‡qHdâˆ‡pHd]+[0G]udi\n\\begin{bmatrix} \\dot{q} \\\\ \\dot{p} \\end{bmatrix} = \n\\begin{bmatrix} \\phantom{-}0 & 1 \\\\ -1 & 0 \\end{bmatrix} \n\\begin{bmatrix} \\nabla_q H_{\\phantom{d}} \\\\ \\nabla_p H_{\\phantom{d}} \\end{bmatrix} +\n\\begin{bmatrix} 0 \\\\ G \\end{bmatrix} u_\\phantom{di}\n\nControl task: stabilize desired equilibrium xâ‹†=(qâ‹†,0)x^\\star = (q^\\star, 0)\n\n\nu=ues+udi=Gâ€ (âˆ‡qHâˆ’âˆ‡qHd)âˆ’KDGâŠ¤âˆ‡pHdu = u_{es} + u_{di} = G^{\\dagger} \\left( \\nabla_q H  - \\nabla_q H_d \\right)  - K_D G^\\top \\nabla_p H_d \n\n\nu=ues+udi=âˆ’Gâ€ âˆ‡qHdÎ¸âˆ’KDGâŠ¤âˆ‡pHdÎ¸u = u_{es} + u_{di} = - G^{\\dagger} \\nabla_q H_d^{\\theta}  - K_D G^\\top \\nabla_p H_d^{\\theta} \n\n\nChoosing a suitable HdH_d is not trivial\n\nParameterize HdH_d by a neural network HdÎ¸H_d^\\theta, and relax control task to bringing xx to a small neighborhood of xâ‹†x^\\star\n\n\n\nInstead of asking for asymptotic stabilization, we only require that trajectories pass thru a nbhd of xâ‹†x^\\star\nThis is reasonable because we know how to stabilize a fixed point, e.g.Â stabilize the linearization of the system using LQR\nThis allows us to find approximations for HdÎ¸H_d^\\theta using learning techniques"
  },
  {
    "objectID": "main.html#neuralpbc-problem-statement-1",
    "href": "main.html#neuralpbc-problem-statement-1",
    "title": "main",
    "section": "NeuralPbc Problem Statement",
    "text": "NeuralPbc Problem Statement\n\n\n\n\nminimizeÎ¸J(Î¸,x0)=âˆ«0Tâ„“(Ï•,uÎ¸,Î¸)dtsubject to[qÌ‡pÌ‡]=[0Iâˆ’I0][âˆ‡qHâˆ‡pH]+[0G]uÎ¸uÎ¸=âˆ’Gâ€ âˆ‡qHdÎ¸âˆ’KDGâŠ¤âˆ‡pHdÎ¸\n\\begin{aligned}\n\\underset{\\theta}{\\text{minimize}} && J(\\theta, x_0) &= \\int_{0}^{T} \\ell \\left(\\phi,u^\\theta,\\theta\\right)\\, \\text{d} t \\\\\n\\text{subject to} &&\n\\begin{bmatrix}\n  \\dot{q} \\\\ \\dot{p}\n\\end{bmatrix} &=\n\\begin{bmatrix}\n  0 & I \\\\ -I & 0\n\\end{bmatrix}\n\\begin{bmatrix} \\nabla_q H \\\\ \\nabla_p H \\end{bmatrix} + \n\\begin{bmatrix}\n  0 \\\\ G\n\\end{bmatrix} u^{\\theta}\n\\\\\n&& u^\\theta &= - G^{\\dagger}\\nabla_q H_d^{\\theta}  - K_D G^\\top \\nabla_p H_d^{\\theta}\n\\end{aligned}\n\n\n\n\n\nInjecting control task into loss function design\nBackprop through closed-loop trajectories\nSampling the state space efficiently"
  },
  {
    "objectID": "main.html#neuralpbc-loss-function",
    "href": "main.html#neuralpbc-loss-function",
    "title": "main",
    "section": "NeuralPbc Loss Function",
    "text": "NeuralPbc Loss Function\n\nJ(Î¸,x0)=âˆ«0Tâ„“(Ï•,uÎ¸,Î¸)dt\nJ(\\theta, x_0) = \\int_{0}^{T} \\ell \\left(\\phi,u^\\theta,\\theta\\right)\\, \\text{d} t\n\nâ„“â‰œâ„“set(Î³)+â„“âŠ¥(Î³,u)\\ell \\triangleq \\ell_{\\text{set}}(\\gamma) + \\ell_{\\bot}(\\gamma,u) where\n\nÏ•\\phi is the flow of the equation of motion\nÎ³\\gamma is the closed-loop trajectory starting from x0x_0\nTT is the time horizon (hyperparameter)"
  },
  {
    "objectID": "main.html#neuralpbc-loss-function-1",
    "href": "main.html#neuralpbc-loss-function-1",
    "title": "main",
    "section": "NeuralPbc Loss Function",
    "text": "NeuralPbc Loss Function\n\nâ„“â‰œâ„“set(Î³)+â„“âŠ¥(Î³,u)\\ell \\triangleq \\ell_{\\text{set}}(\\gamma) + \\ell_{\\bot}(\\gamma,u)\n\n\n\nSet Distance Loss â„“set\\ell_{\\text{set}}\n\n\nPenalizes when closed-loop trajectory Î³\\gamma under the current control law is far away from a neighborhood ğ’®\\mathcal{S} of xâ‹†x^\\star\n\n\n\n\n\n\nâ„“set(x)=inft{âˆ¥aâˆ’bâˆ¥:aâˆˆÎ³(t),bâˆˆğ’®}\\ell_{\\text{set}}(x) = \\underset{t}{\\inf} \\left\\{ \\lVert a-b \\rVert : a \\in \\gamma(t), b \\in \\mathcal{S}\\right\\} * The set ğ’®\\mathcal{S} may be chosen as * A ball around xâ‹†x^\\star * Estimated region of attraction * No additional loss if any point in Î³\\gamma is in ğ’®\\mathcal{S}"
  },
  {
    "objectID": "main.html#neuralpbc-loss-function-2",
    "href": "main.html#neuralpbc-loss-function-2",
    "title": "main",
    "section": "NeuralPbc Loss Function",
    "text": "NeuralPbc Loss Function\n\nâ„“â‰œâ„“set(Î³)+â„“âŠ¥(Î³,u)\\ell \\triangleq \\ell_{\\text{set}}(\\gamma) + \\ell_{\\bot}(\\gamma,u)\n\n\n\nTransversal Distance Loss â„“âŠ¥\\ell_{\\bot}\n\n\nMeasures how close Î³\\gamma is to Î³â‹†\\gamma^\\star (expert trajectory) using transverse coordinates xâŠ¥x_\\bot\n\n\n\n\n\n\n\nCoordinate transformation\n\nÏ„âˆˆâ„\\tau \\in \\mathbb{R} a surrogate for time\nxâŠ¥âˆˆâ„2nâˆ’1x_{\\bot} \\in \\mathbb{R}^{2n-1} quantify how far away the current state is from Î³â‹†\\gamma^\\star\n\nBy construction xâŠ¥â†’0â‡”Î³=Î³â‹†x_{\\bot} \\to 0 \\iff \\gamma = \\gamma^\\star\n\nâ„“âŠ¥=xâŠ¥âŠ¤QxâŠ¥+uâŠ¤Ru,Qâ‰½0,Râ‰»0\\ell_{\\bot} = x_\\bot^\\top Q x_\\bot + u^\\top R u, \\, Q \\succeq 0, \\, R \\succ 0\n\nNo preferred orbit? Q=0Q = 0\n\n\n\n\n\n\n\n\n\nWe can find a coordinate transformation such that 1 coordinate Ï„\\tau is along the desired orbit and acts as surrogate for time\nThe remaining coordinates xâŠ¥x_{\\bot} quantify how far away the current state is from the desired trajectory"
  },
  {
    "objectID": "main.html#backprop-through-ode-solutions",
    "href": "main.html#backprop-through-ode-solutions",
    "title": "main",
    "section": "Backprop through ODE Solutions",
    "text": "Backprop through ODE Solutions\n\nWe need âˆ‚J/âˆ‚Î¸\\partial J / \\partial \\theta, which depends ODE solutions\n\nğŸ˜¿ Combining autodiff with numerical ODE solvers\n\n\nğŸ˜¿ Adjoint sensitivity method: solve the adjoint problem backward in time dÎ»dt=âˆ’Î»âˆ‚fâˆ‚x,âˆ‚Jâˆ‚Î¸=Î»(t0)âˆ‚fâˆ‚x\\frac{\\text{d}\\lambda}{\\text{d}t} = -\\lambda \\frac{\\partial f}{\\partial x}, \\quad \\frac{\\partial J}{\\partial \\theta} = \\lambda(t_0) \\frac{\\partial f}{\\partial x}\n\n\nğŸ˜º Adjoint methods + autodiff implemented in DiffEqFlux.jl\n\n\n\nPlain autodiff causes errors due to numerical ODE integration, high memory consumption\nAdjoint methods requires storing many passes of the adjoint problem, again high memory consumption\nDiffEqFlux combines the two, avoiding multiple passes through clever implementation, fast an efficient"
  },
  {
    "objectID": "main.html#neuralpbc-sampling-state-space",
    "href": "main.html#neuralpbc-sampling-state-space",
    "title": "main",
    "section": "NeuralPbc Sampling State Space",
    "text": "NeuralPbc Sampling State Space\n\nLearned policy uÎ¸u^\\theta need to perform well for a wide range of x0x_0\n\n\nJ(Î¸,x0)=âˆ«0Tâ„“(Ï•,uÎ¸,Î¸)dtJ(\\theta, x_0) = \\int_{0}^{T} \\ell \\left(\\phi,u^\\theta,\\theta\\right)\\, \\text{d} t\n\n\n\nJ(Î¸)=ğ”¼x0âˆ¼p(ğ±0)[âˆ«0Tâ„“(Ï•(t,x0),uÎ¸,Î¸)dt]J(\\theta) = \\mathbb{E}_{x_0 \\sim p(\\mathbf{x}_0)} \\left[ \\int_{0}^{T} \\ell \\left(\\phi(t,x_0),u^\\theta,\\theta\\right)\\, \\text{d} t \\right]\n\n\nSample state space with technique based on DAgger1\n\n\nSimulating system under application of uÎ¸u^\\theta\nCollect samples from the regions of state-space visited by uÎ¸u^\\theta\n\n\n\n\nUse dynamics to guide the collection of samples\n\n\nRoss, S., Gordon, G. J., & Bagnell, J. A. (2011). No-regret reductions for imitation learning and structured prediction. In AISTATS."
  },
  {
    "objectID": "main.html#neuralpbc-algorithm",
    "href": "main.html#neuralpbc-algorithm",
    "title": "main",
    "section": "NeuralPbc Algorithm ğŸ“‰",
    "text": "NeuralPbc Algorithm ğŸ“‰"
  },
  {
    "objectID": "main.html#bayesian-solution",
    "href": "main.html#bayesian-solution",
    "title": "main",
    "section": "Bayesian Solution",
    "text": "Bayesian Solution\n\nÂ \n\nComputing ELBO â„’(ğ’Ÿ;z)=ğ”¼Î¸âˆ¼q[logp(ğ’Ÿâˆ£Î¸)p(Î¸)âˆ’logq(Î¸;z)] \\mathcal{L}(\\mathcal{D};z) = \\mathbb{E}_{\\theta \\sim q}\\left[ \\log p(\\mathcal{D} \\mid \\theta)p(\\theta) - \\log q(\\theta; z)  \\right]  requires: Â \n\nLikelihood: p(âˆ¥â„“set(Î³)+â„“âŠ¥(Î³,u)âˆ¥2âˆ£Î¸)=ğ’©(0,s). p\\left( \\lVert \\ell_{\\text{set}}(\\gamma) + \\ell_\\bot(\\gamma, u) \\rVert^2 \\mid \\theta \\right) = \\mathcal{N}(0, s). \n\n\nPrior:\n\n\nUninformed\n\n\nDeterministic"
  },
  {
    "objectID": "main.html#comparison-of-methods",
    "href": "main.html#comparison-of-methods",
    "title": "main",
    "section": "Comparison of Methods",
    "text": "Comparison of Methods\n\nÂ \n\n\n\nAdvantages âœ”ï¸ and Disadvantages âŒ\n\n\n\n\n\n\n\n\n\n\nCase\nDeterministic\nBayesian\n\n\n\n\nRobustness\nâŒ\nâœ”ï¸\n\n\nComputation cost\nâœ”ï¸\nâŒ\n\n\nModel selection\nâŒ\nâœ”ï¸\n\n\nPrior knowledge\nâœ”ï¸\nâœ”ï¸âœ”ï¸\n\n\nOverfitting\nâŒ\nâœ”ï¸"
  },
  {
    "objectID": "main.html#energy-shaping-pendulum-swing-up",
    "href": "main.html#energy-shaping-pendulum-swing-up",
    "title": "main",
    "section": "Energy-Shaping Pendulum Swing-Up",
    "text": "Energy-Shaping Pendulum Swing-Up"
  },
  {
    "objectID": "main.html#energy-shaping-pendulum-swing-up-1",
    "href": "main.html#energy-shaping-pendulum-swing-up-1",
    "title": "main",
    "section": "Energy-Shaping Pendulum Swing-Up",
    "text": "Energy-Shaping Pendulum Swing-Up\n\n\n\n\n\n\n\nDeterministic training vs.Â Bayesian training under parameter uncertainty and measurement noise.\nMeasurement noise: Ïµq=5Ã—104\\epsilon_q = 5 \\times 10^4 rad., ÏµqÌ‡=5Ã—102\\epsilon_{\\dot{q}} = 5 \\times 10^2 rad/s."
  },
  {
    "objectID": "main.html#neuralpbc-experiments",
    "href": "main.html#neuralpbc-experiments",
    "title": "main",
    "section": "NeuralPbc Experiments",
    "text": "NeuralPbc Experiments\n\nBenchmark underactuated control problems:\n\n\n\n\nCart-pole\n\n\nInertia-Wheel Pendulum (IWP)\n\n\nAcrobot"
  },
  {
    "objectID": "main.html#learned-storage-function",
    "href": "main.html#learned-storage-function",
    "title": "main",
    "section": "Learned storage function",
    "text": "Learned storage function\n\n\n\nObservations\n\nHdÎ¸H_d^\\theta has a local minimum at xâ‹†x^\\star, control law uÎ¸u^\\theta commands the force in the expected direction"
  },
  {
    "objectID": "main.html#comparison-with-energy-shapingastrom",
    "href": "main.html#comparison-with-energy-shapingastrom",
    "title": "main",
    "section": "Comparison with Energy Shaping1",
    "text": "Comparison with Energy Shaping1\n\n\nK. J. Ã…strÃ¶m and K. Furuta, â€œSwinging up a pendulum by energy control,â€ Automatica, vol.Â 36, no. 2, pp.Â 287â€“295, 2000."
  },
  {
    "objectID": "main.html#motivation-2",
    "href": "main.html#motivation-2",
    "title": "main",
    "section": "Motivation",
    "text": "Motivation\n\nNeuralPbc is flexible, but guaranteeing stability is hard\nAdditional structure of IdaPbc facilitates stability analysis\n\n\n[qÌ‡pÌ‡]=[0Iâˆ’I0][âˆ‡qHâˆ‡pH]+[0G]u \\begin{bmatrix} \\dot{q} \\\\ \\dot{p} \\end{bmatrix} = \\begin{bmatrix}0 & I \\\\ -I & 0\\end{bmatrix} \\begin{bmatrix} \\nabla_q H \\\\ \\nabla_p H  \\end{bmatrix} + \\begin{bmatrix} 0 \\\\ G \\end{bmatrix} u  \nClosed-loop port-Hamiltonian dynamics:\n\n[qÌ‡pÌ‡]=[0Mâˆ’1Mdâˆ’MdMâˆ’1J2(q,p)âˆ’GKvGâŠ¤][âˆ‡qHdâˆ‡pHd]\n\\begin{bmatrix} \\dot{q} \\\\ \\dot{p} \\end{bmatrix}\n=\n\\begin{bmatrix}0 & M^{-1}M_d \\\\ -M_dM^{-1} & J_2(q,p) - GK_vG^\\top\\end{bmatrix}\n\\begin{bmatrix} \\nabla_q H_d \\\\ \\nabla_p H_d \\end{bmatrix}\n  \nHd=12pâŠ¤Md(q)âˆ’1p+Vd(q),Mdâ‰»0H_d = \\frac{1}{2} p^{\\top} M_d(q)^{-1} p + V_d(q),\\, M_d \\succ 0\n\n\nFurther structure not only facilitates stability analysis but also restricts the search to a pd matrix MdM_d and VdV_d.\nThis search may be performed solely on the configuration space."
  },
  {
    "objectID": "main.html#idapbc-background",
    "href": "main.html#idapbc-background",
    "title": "main",
    "section": "IdaPbc Background",
    "text": "IdaPbc Background\n\n[qÌ‡pÌ‡]=[0Mâˆ’1Mdâˆ’MdMâˆ’1J2(q,p)âˆ’GKvGâŠ¤][âˆ‡qHdâˆ‡pHd] \\begin{bmatrix} \\dot{q} \\\\ \\dot{p} \\end{bmatrix} = \\begin{bmatrix}0 & M^{-1}M_d \\\\ -M_dM^{-1} & J_2(q,p) - GK_vG^\\top\\end{bmatrix} \\begin{bmatrix} \\nabla_q H_d \\\\ \\nabla_p H_d \\end{bmatrix} \nHd=12pâŠ¤Md(q)âˆ’1p+Vd(q),Mdâ‰»0H_d = \\frac{1}{2} p^{\\top} M_d(q)^{-1} p + V_d(q),\\, M_d \\succ 0\n\n\n\n\n\nStability results\n\n\nHÌ‡d=(âˆ‡pHd)âŠ¤(âˆ’GKvGâŠ¤)âˆ‡pHdâ‰¤âˆ’Î»min{Kv}âˆ¥(âˆ‡pHd)âŠ¤Gâˆ¥2â‰¤0\\begin{aligned}\\dot{H}_d &= \\left( \\nabla_p H_d \\right)^{\\top} \\left(-G K_v G^{\\top}\\right) \\nabla_p H_d \\\\ &\\leq -\\lambda_{\\textrm{min}} \\{ K_v \\} \\left\\| \\left( \\nabla_p H_d \\right)^{\\top} G \\right\\|^2 \\leq 0 \\end{aligned}\nWith qâ‹†=argminVd(q)q^\\star = \\arg \\min V_d(q), we have xâ†’xâ‹†=(qâ‹†,0)x \\to x^\\star = (q^\\star, 0)\n\n\n\n\n\n\n\nControl synthesis\n\n\nChoose u=ues+udiu = u_{es} + u_{di} where Gues=âˆ‡qHâˆ’MdMâˆ’1âˆ‡qHd+J2Mdâˆ’1pâˆ‡pâŠ¤udi=âˆ’KvGâŠ¤âˆ‡pHdâˆ¥(âˆ‡p)âŠ¤âˆ¥2\n\\begin{aligned} \nGu_{es} &= \\nabla_{q} H - M_{d}M^{-1} \\nabla_{q} H_{d} \\\\\n&\\quad\\; + J_{2} M_{d}^{-1} p \\phantom{\\nabla_{p}^{\\top}} \\\\\nu_{di} &= -K_v G^\\top \\nabla_p H_d \\phantom{\\left\\|\\left(\\nabla_p\\right)^{\\top} \\right\\|^2} \n\\end{aligned}"
  },
  {
    "objectID": "main.html#idapbc-via-optimization",
    "href": "main.html#idapbc-via-optimization",
    "title": "main",
    "section": "IdaPbc via Optimization",
    "text": "IdaPbc via Optimization\n\n\n\n\nÂ \n\n\n\n\nminimizeMd,J2,Vd0subject to0=GâŠ¥{âˆ‡qHâˆ’MdMâˆ’1âˆ‡qHd+J2Mdâˆ’1p}Hd=12pâŠ¤Md(q)âˆ’1p+Vd(q)Md=MdâŠ¤â‰»0J2=âˆ’J2âŠ¤qâ‹†=argminqVd(q)\n\\begin{aligned}\n\\underset{M_d,\\,J_2,\\,V_d}{\\text{minimize}} && 0 &  \\\\\n\\text{subject to} &&\n0 &= G^{\\bot}\\left\\{ \\nabla_{q} H - M_{d}M^{-1} \\nabla_{q} H_{d} + J_{2} M_{d}^{-1} p  \\right\\}\n\\\\\n&& H_d &= \\frac{1}{2} p^{\\top} M_d(q)^{-1} p + V_d(q)\n\\\\\n&& M_d &= M_d^\\top \\succ 0\n\\\\\n&& J_2 &= -J_2^\\top\n\\\\\n&& q^\\star &= \\underset{q}{\\arg \\min} \\, V_d(q)\n\\end{aligned}\n\n\n\n\n\nÂ \n\n\n\n\nInfinite-dimensionalâ€”closed-form solution is difficult"
  },
  {
    "objectID": "main.html#neuralidapbc-2",
    "href": "main.html#neuralidapbc-2",
    "title": "main",
    "section": "NeuralIdaPbc",
    "text": "NeuralIdaPbc"
  },
  {
    "objectID": "main.html#neuralidapbc-problem-statement",
    "href": "main.html#neuralidapbc-problem-statement",
    "title": "main",
    "section": "NeuralIdaPbc Problem Statement",
    "text": "NeuralIdaPbc Problem Statement\n\n\n\n\nÂ \n\n\n\n\nminimizeÎ¸J(Î¸)=âˆ¥GâŠ¥{âˆ‡qHâˆ’MdÎ¸Mâˆ’1âˆ‡qHdÎ¸+J2Î¸(MdÎ¸)âˆ’1p}âˆ¥2subject toHdÎ¸=12pâŠ¤(MdÎ¸)âˆ’1p+VdÎ¸(q)MdÎ¸(q)=(MdÎ¸(q))âŠ¤â‰»0J2Î¸(q,p)=âˆ’(J2Î¸(q,p))âŠ¤qâ‹†=argminqVdÎ¸(q)\n\\begin{aligned}\n\\underset{\\theta}{\\text{minimize}} && J(\\theta) &= \\left\\lVert G^{\\bot} \\left\\{ \\nabla_{q} H - M_{d}^{\\theta}M^{-1} \\nabla_{q} H_{d}^{\\theta} + J_{2}^{\\theta} \\left(M_{d}^{\\theta}\\right)^{-1} p \\right\\} \\right\\rVert^2  \\\\\n\\text{subject to} \n&& H_d^{\\theta} &= \\frac{1}{2} p^{\\top} \\left( M_{d}^{\\theta} \\right)^{-1} p + V_{d}^{\\theta}(q)\n\\\\\n&& M_d^{\\theta}(q) &= \\left(M_d^{\\theta}(q)\\right)^\\top \\succ 0\n\\\\\n&& J_{2}^{\\theta}(q,p) &= -\\left(J_{2}^{\\theta}(q,p)\\right)^\\top\n\\\\\n&& q^\\star &= \\underset{q}{\\arg \\min} \\, V_{d}^{\\theta} (q)\n\\end{aligned}\n\n\n\n\n\nÂ \n\n\n\n\n\n\n\nFinite-dimensional search\nSample configuration space\n\n\n\nÂ \n\n\n\nController uu is a continuous function of JJ"
  },
  {
    "objectID": "main.html#neuralidapbc-constraints",
    "href": "main.html#neuralidapbc-constraints",
    "title": "main",
    "section": "NeuralIdaPbc Constraints",
    "text": "NeuralIdaPbc Constraints\n\n\nMdÎ¸=(MdÎ¸)âŠ¤â‰»0M_d^{\\theta} = \\left(M_d^{\\theta}\\right)^{\\top} \\succ 0\n\n\nJ2Î¸=âˆ’(J2Î¸)âŠ¤J_{2}^{\\theta} = -\\left(J_{2}^{\\theta}\\right)^{\\top}\nqâ‹†=argminqVdÎ¸(q)q^\\star = \\underset{q}{\\arg \\min} \\, V_{d}^{\\theta} (q)\n\n\n\n\n\nPositive-definiteness of the desired mass matrix\n\n\n\nCholesky decomposition MdÎ¸(q)=LÎ¸(q)LÎ¸âŠ¤(q)M_d^\\theta(q) = L_{\\theta}(q) L_{\\theta}^{\\top}(q)\nComponents of the lower-triangular matrix LÎ¸(q)L_\\theta(q) are outputs of a neural network"
  },
  {
    "objectID": "main.html#neuralidapbc-constraints-1",
    "href": "main.html#neuralidapbc-constraints-1",
    "title": "main",
    "section": "NeuralIdaPbc Constraints",
    "text": "NeuralIdaPbc Constraints\n\n\nMdÎ¸=(MdÎ¸)âŠ¤â‰»0M_d^{\\theta} = \\left(M_d^{\\theta}\\right)^{\\top} \\succ 0\n\n\nJ2Î¸=âˆ’(J2Î¸)âŠ¤J_{2}^{\\theta} = -\\left(J_{2}^{\\theta}\\right)^{\\top}\n\n\nqâ‹†=argminqVdÎ¸(q)q^\\star = \\underset{q}{\\arg \\min} \\, V_{d}^{\\theta} (q)\n\n\n\n\n\nSkew symmetry of J2Î¸(q,p)J_2^\\theta(q,p)\n\n\n\nDecompose a square matrix into symmetric and skew-symmetric parts J2Î¸(q,p)=AÎ¸(q,p)âˆ’AÎ¸âŠ¤(q,p)J_2^\\theta(q,p) = A_{\\theta}(q,p) -  A_{\\theta}^{\\top}(q,p)\nComponents of the square matrix AÎ¸(q,p)A_\\theta(q,p) are output of a neural network"
  },
  {
    "objectID": "main.html#neuralidapbc-constraints-2",
    "href": "main.html#neuralidapbc-constraints-2",
    "title": "main",
    "section": "NeuralIdaPbc Constraints",
    "text": "NeuralIdaPbc Constraints\n\n\nMdÎ¸=(MdÎ¸)âŠ¤â‰»0M_d^{\\theta} = \\left(M_d^{\\theta}\\right)^{\\top} \\succ 0 J2Î¸=âˆ’(J2Î¸)âŠ¤J_{2}^{\\theta} = -\\left(J_{2}^{\\theta}\\right)^{\\top}\n\n\nqâ‹†=argminqVdÎ¸(q)q^\\star = \\underset{q}{\\arg \\min} \\, V_{d}^{\\theta} (q)\n\n\n\n\n\nBoundedness of VdÎ¸V_d^\\theta\n\n\n\nVdÎ¸(q)V_d^\\theta(q) bounded from below with isolated minimum at qâ‹†q^\\star \nParameterize VdÎ¸V_d^\\theta by a sums-of-square (SoS) polynomial\nVdÎ¸(q)>0,qâ‰ qâ‹†V_d^\\theta(q) > 0,\\, q \\neq q^\\star"
  },
  {
    "objectID": "main.html#sos-decomposition",
    "href": "main.html#sos-decomposition",
    "title": "main",
    "section": "SoS Decomposition",
    "text": "SoS Decomposition\n\n\n\n\nTheorem (Choi, 1995)\n\n\nA polynomial Pâˆˆâ„[x]P \\in \\mathbb{R}[x] of degree 2d2d has a SoS decomposition â‡”\\Leftrightarrow âˆƒQâ‰»0\\exists Q \\succ 0 such that, with Î¼(x)=[1x1â‹¯xnx1x2â‹¯xnd]\\mu(x) = \\begin{bmatrix} 1 & x_1 & \\cdots & x_n & x_1 x_2 & \\cdots & x_n^d\\end{bmatrix}, we have P(x)=Î¼(x)âŠ¤QÎ¼(x)P(x) = \\mu(x)^\\top Q \\mu(x)\n\n\n\n\n\n\n\nExample\n\n\nx12+2x12x2+5x12x22+4x1x22+x22=Î¼(x)âŠ¤(110152021)Î¼(x)=Î¼(x)âŠ¤(100120010)(100120010)âŠ¤Î¼(x)\\begin{aligned} x_1^2 + 2x_1^2x_2 + 5x_1^2x_2^2 + 4x_1x_2^2 + x_2^2  &= \\mu(x)^{\\top} \\begin{pmatrix} 1 & 1 & 0 \\\\ 1 & 5 & 2 \\\\ 0 & 2 & 1 \\end{pmatrix} \\mu(x) \\\\ &= \\mu(x)^{\\top} \\begin{pmatrix} 1 & 0 & 0 \\\\ 1 & 2 & 0 \\\\ 0 & 1 & 0 \\end{pmatrix} \\begin{pmatrix}   1 & 0 & 0 \\\\ 1 & 2 & 0 \\\\ 0 & 1 & 0 \\end{pmatrix}^{\\top} \\mu(x) \\end{aligned}"
  },
  {
    "objectID": "main.html#neuralidapbc-experiments",
    "href": "main.html#neuralidapbc-experiments",
    "title": "main",
    "section": "NeuralIdaPbc Experiments",
    "text": "NeuralIdaPbc Experiments\n\nFollowed the experiments performed in IdaPbc paper1\n\nInertia-wheel pendulum (IWP)\nBall-beam system\n\nR. Ortega, M. W. Spong, F. GÃ³mez-Estern, and G. Blankenstein, â€œStabilization of a class of underactuated mechanical systems via interconnection and damping assignment,â€ IEEE transactions on automatic control, vol.Â 47, no. 8, pp. 1218â€“1233, 2002."
  },
  {
    "objectID": "main.html#simulated-iwp-experiments",
    "href": "main.html#simulated-iwp-experiments",
    "title": "main",
    "section": "Simulated IWP experiments",
    "text": "Simulated IWP experiments\n\n\n\n\n\n\n\nComparison of control effort expenditure\n\n\n\n\n\n\n\n\n\nNeuralPbc\nNeuralIdaPbc\nIdaPbc"
  },
  {
    "objectID": "main.html#deterministic-vs.-bayesian-training",
    "href": "main.html#deterministic-vs.-bayesian-training",
    "title": "main",
    "section": "Deterministic vs.Â Bayesian Training",
    "text": "Deterministic vs.Â Bayesian Training\n\n\n\n\nPerformance metric: ğ’¥=âˆ«0T(12qx(t)2+12ru(t)2)dt\\mathcal{J} = \\int_0^T \\left( \\frac{1}{2}qx(t)^2 + \\frac{1}{2}ru(t)^2 \\right)dt.\n\nÂ \n\nSimulated dynamics\ndx=[qÌ‡1q2Ì‡1I1(mglsinq1âˆ’uÎ¸âˆ’b1qÌ‡1)1I2(uÎ¸âˆ’b2qÌ‡2)]dt+âˆ‡xuÎ¸(x)ÏƒdWt.\n\\begin{aligned}\ndx &= \\begin{bmatrix}\n\\dot{q}_1 \\\\ \\dot{q_2} \\\\ \\frac{1}{I_1}\\left(m g l \\sin{q_1} - u^\\theta -\nb_1\\dot{q}_1\\right) \\\\ \\frac{1}{I_2}\\left(u^\\theta -b_2 \\dot{q}_2 \\right)\n\\end{bmatrix} dt \\\\\n&+ \\nabla_xu^\\theta(x) \\sigma dW_t.\n\\end{aligned}"
  },
  {
    "objectID": "main.html#deterministic-vs.-bayesian-training-1",
    "href": "main.html#deterministic-vs.-bayesian-training-1",
    "title": "main",
    "section": "Deterministic vs.Â Bayesian Training",
    "text": "Deterministic vs.Â Bayesian Training\n\n\n\n\n\nSubtracting rings from the wheel\n\ndecreases wheel mass\ndecreases wheel and pendulum inertia\nmoves the center of mass\n\n\n\n\n\n\n\n\n\nParameter vector Î¶\\zeta\nI1I_1\nI2I_2\nmglm g l\nError\n\n\n\n\nNominal\n0.04550.0455\n0.004250.00425\n1.7951.795\n00\n\n\n3 rings\n0.04170.0417\n0.003300.00330\n1.5771.577\n0.1220.122\n\n\n2 rings\n0.03780.0378\n0.002350.00235\n1.3581.358\n0.2430.243\n\n\n1 rings\n0.03400.0340\n0.001410.00141\n1.1401.140\n0.3650.365"
  },
  {
    "objectID": "main.html#ball-beam-experiments",
    "href": "main.html#ball-beam-experiments",
    "title": "main",
    "section": "Ball-beam experiments",
    "text": "Ball-beam experiments"
  },
  {
    "objectID": "main.html#closing-thoughts-and-future-directions",
    "href": "main.html#closing-thoughts-and-future-directions",
    "title": "main",
    "section": "Closing Thoughts and Future Directions",
    "text": "Closing Thoughts and Future Directions\nPBC + machine learning techniques âœ¨\n\n\nWe uncovered the engineering foundations for combining them\nTransparent connection to stability analysis (NeuralIdaPbc)\nExtensive experimental results in simulation and on hardware\n\n\nFuture directionsâ€”applications in:\n\n\nDynamical models with uncertainity\nHybrid dynamical systems (walking machines)"
  },
  {
    "objectID": "main.html#data-driven-control-through-contact",
    "href": "main.html#data-driven-control-through-contact",
    "title": "main",
    "section": "Data-Driven Control Through Contact",
    "text": "Data-Driven Control Through Contact\n\n\n\nÂ \n\n\n\nminq(Î¸)J(Ï•(t;x0,u),u)subject toM(x)dxâˆ’h(x,xÌ‡,u)dtâˆ’dÎ›=0,u(x;Î¸)=ğ’Ÿ{F(x;Î¸)},Î¶âˆ¼ğ’©(Î¶0,Î£Î¶),Î¸âˆ¼q(Î¸),\n\\begin{aligned}\n\\underset{q(\\theta) }{\\text{min}} \n&&\\quad J(&\\phi(t; x_0, u), u) \\\\\n\\text{subject to} \n&&\\quad M(x) dx &- h(x, \\dot{x}, u) dt - d\\Lambda= 0, \\\\\n&&\\quad u(x; \\theta) &= \\mathcal{D}\\{F(x; \\theta)\\}, \\\\\n&&\\quad \\zeta &\\sim \\mathcal{N}(\\zeta_0, \\Sigma_{\\zeta}), \\\\\n&&\\quad \\theta &\\sim q(\\theta),\n\\end{aligned} \n\n\n\n\n\n\n\n\n\n\nImpacts and friction modelled through measure differential inclusions.\nUsually solved through linear complementarity problems (convex optimization).\nData-driven PBC designed to be robust against uncertainties (e.g.Â surface friction)."
  },
  {
    "objectID": "main.html#acknowledgements",
    "href": "main.html#acknowledgements",
    "title": "main",
    "section": "Acknowledgements",
    "text": "Acknowledgements"
  },
  {
    "objectID": "main.html#neuralpbc-publications",
    "href": "main.html#neuralpbc-publications",
    "title": "main",
    "section": "NeuralPbc Publications",
    "text": "NeuralPbc Publications\n\nThis work is published in ISER 20201, CCTA 20212\nW. Sirichotiyakul and A. C. Satici, â€œData-driven design of energy-shaping controllers for swing-up control of underactuated robots,â€ in International Symposium on Experimental Robotics. Springer, 2020, pp.Â 323-333.W. Sirichotiyakul and A. C. Satici, â€œCombining energy-shaping control of dynamical systems with data-driven approaches,â€ in 2021 IEEE Conference on Control Technology and Applications (CCTA). IEEE, 2021, pp.Â 1121-1127."
  },
  {
    "objectID": "main.html#neuralpbc-publications-1",
    "href": "main.html#neuralpbc-publications-1",
    "title": "main",
    "section": "NeuralPbc Publications",
    "text": "NeuralPbc Publications\n\nThis work also provides a foundation for an ongoing research that investigate the improvement of robustness properties of NeuralPbc1,2\nW. Sirichotiyakul, N. A. Ashenafi, and A. C. Satici, â€œRobust Data-Driven Passivity-Based Control of Underactuated Systems via Neural Approximators and Bayesian Inference,â€ in 2022 American Control Conference, ACC. IEEE, Accepted for publication January 2022.N. A. Ashenafi, W. Sirichotiyakul, and A. C. Satici, â€œRobust Passivity-Based Control of Underactuated Systems via Neural Approximators and Bayesian In ference,â€ in 2022 Conference on Decision and Control, CDC. IEEE. (Submitted for review March 2022)."
  },
  {
    "objectID": "main.html#neuralidapbc-publications",
    "href": "main.html#neuralidapbc-publications",
    "title": "main",
    "section": "NeuralIdaPbc Publications",
    "text": "NeuralIdaPbc Publications\n\nThis work is published in the International Journal of Control1\nÂ \nNeuralIdaPbc is the basis for an ongoing research that investigate the improvement of robustness properties2\nW. Sirichotiyakul and A. C. Satici, â€œData-Driven Passivity-Based Control of Underactuated Mechanical Systems via Interconnection and Damping Assignment,â€ in International Journal of Control. (Accepted for publication March 2022)W. Sirichotiyakul, N. A. Ashenafi, and A. C. Satici, â€œRobust Interconnection and Damping Assignment Passivity-Based Control via Neural Bayesian Inference,â€ in IEEE Transactions on Automatic Control. (Submitted for review April 2022)"
  },
  {
    "objectID": "main.html#diffeqflux.jl-demo",
    "href": "main.html#diffeqflux.jl-demo",
    "title": "main",
    "section": "DiffEqFlux.jl Demo",
    "text": "DiffEqFlux.jl Demo\n\nLearning xÌ‡=f(x)\\dot{x} = f(x) where ff is a neural network\nRegress on MSE between trajectory of ff and data"
  },
  {
    "objectID": "main.html#neuralidapbc-main-problem",
    "href": "main.html#neuralidapbc-main-problem",
    "title": "main",
    "section": "NeuralIdaPbc Main Problem",
    "text": "NeuralIdaPbc Main Problem\n\nminimizeÎ¸J(Î¸)=âˆ¥GâŠ¥{âˆ‡qHâˆ’MdÎ¸Mâˆ’1âˆ‡qHdÎ¸+J2Î¸(MdÎ¸)âˆ’1p}âˆ¥2subject toHdÎ¸=12pâŠ¤(MdÎ¸)âˆ’1p+VdÎ¸(q)MdÎ¸(q)=(MdÎ¸(q))âŠ¤â‰»0J2Î¸(q,p)=âˆ’(J2Î¸(q,p))âŠ¤qâ‹†=argminqVdÎ¸(q)\\begin{aligned} \\underset{\\theta}{\\text{minimize}} && J(\\theta) &= \\left\\lVert G^{\\bot} \\left\\{ \\nabla_{q} H - M_{d}^{\\theta}M^{-1} \\nabla_{q} H_{d}^{\\theta} + J_{2}^{\\theta} \\left(M_{d}^{\\theta}\\right)^{-1} p \\right\\} \\right\\rVert^2  \\\\ \\text{subject to}  && H_d^{\\theta} &= \\frac{1}{2} p^{\\top} \\left( M_{d}^{\\theta} \\right)^{-1} p + V_{d}^{\\theta}(q) \\\\ && M_d^{\\theta}(q) &= \\left(M_d^{\\theta}(q)\\right)^\\top \\succ 0 \\\\ && J_{2}^{\\theta}(q,p) &= -\\left(J_{2}^{\\theta}(q,p)\\right)^\\top \\\\ && q^\\star &= \\underset{q}{\\arg \\min} \\, V_{d}^{\\theta} (q) \\end{aligned}\n\n\n\n\n\n\nNeuralIdaPbc\n\n\n\nSolve nonlinear PDEs using neural networks and SoS polynomials\nSurrogates of MdM_d, J2J_2, VdV_d are constrained by construction\n\n\n\n\n\n\n\n\n\n\nPinn\n\n\n\nSolve nonlinear PDEs using neural networks\nSolution surrogates are constrained via penalty term in loss function"
  },
  {
    "objectID": "main.html#sos-polynomials",
    "href": "main.html#sos-polynomials",
    "title": "main",
    "section": "SoS Polynomials",
    "text": "SoS Polynomials\n\nIs p(x)p(x) nonnegative for all xx? p(x)=4x12+x1x2âˆ’4x22âˆ’2.1x14+4x24+13x16+1.0316p(x) = 4x_1^2 + x_1x_2 - 4x_2^2 - 2.1x_1^4 + 4x_2^4 + \\frac{1}{3}x_1^6 + 1.0316\\;\n\np(x)=(0.116x12+0.01x1x2âˆ’2x22+1.015)2+(âˆ’0.569x13+1.938x1+0.244x2)2+(0.224x12+0.666x1x2+0.029x22+0.026)2+(âˆ’0.188x12+0.063x1x2âˆ’0.006x22+0.009)2+(0.099x13+0.029x1+0.004x2)2+(0.009x12x2)2\\begin{aligned} p(x) = &\\left(0.116x_1^2 + 0.01x_1x_2 - 2x_2^2 + 1.015\\right)^2 \\\\ & + \\; \\left(-0.569x_1^3 + 1.938x_1 + 0.244x_2\\right)^2 \\\\ & + \\; \\left(0.224x_1^2 + 0.666x_1x_2 + 0.029x_2^2 + 0.026\\right)^2 \\\\ & + \\; \\left(-0.188x_1^2 + 0.063x_1x_2 - 0.006x_2^2 + 0.009\\right)^2 \\\\ & + \\; \\left(0.099x_1^3 + 0.029x_1 + 0.004x_2\\right)^2 + \\left(0.009x_1^2x_2\\right)^2 \\end{aligned}\n\n\n\nData-Driven Passivity-Based Control â€¢ Aykut C. Satici"
  },
  {
    "objectID": "main.html#neuralidapbc-1",
    "href": "main.html#neuralidapbc-1",
    "title": "main",
    "section": "NeuralIdaPbc",
    "text": "NeuralIdaPbc"
  },
  {
    "objectID": "main.html#acknowledgments",
    "href": "main.html#acknowledgments",
    "title": "main",
    "section": "Acknowledgments",
    "text": "Acknowledgments"
  },
  {
    "objectID": "main.html#data-driven-passivity-based-control-of-robotic-locomotion-and-manipulation",
    "href": "main.html#data-driven-passivity-based-control-of-robotic-locomotion-and-manipulation",
    "title": "main",
    "section": "Data-Driven Passivity-Based Control of Robotic Locomotion and Manipulation",
    "text": "Data-Driven Passivity-Based Control of Robotic Locomotion and Manipulation\n\n\nUniversity of Texas at Dallas Seminar\n\n\n\n\nPresenter: Aykut Satici, Ph.D.Â  Mechanical and Biomedical Engineering  Boise State University, Boise, Idaho, USA\n\n\nGraduate Students:  Chris Dagher ğŸ“  Wankun Sirichotiyakul ğŸ“  Nardos Ayele Ashenafi ğŸ“"
  },
  {
    "objectID": "main.html#motivation",
    "href": "main.html#motivation",
    "title": "main",
    "section": "Motivation",
    "text": "Motivation\n\nControl synthesis in PBC: Gues=âˆ‡qHâˆ’âˆ‡qHd\nGu_{es} = \\nabla_q H - \\nabla_q H_d\n\n\nIf underactuated, GG is not invertible\n\nChoice of uesu_{es} must satisfy nonlinear PDE\nQuadratic potential most likely not viable\n\nIncorporate performance objective into design of HdH_d?"
  },
  {
    "objectID": "main.html#hybrid-systems",
    "href": "main.html#hybrid-systems",
    "title": "main",
    "section": "Hybrid Systems",
    "text": "Hybrid Systems\n\n\nexhibit both continuous state flow and discrete state transitions\n\n\n\n\nE.g. Room temperature control, contact-rich robots\n\n\n\n\nWe tackle two main challenges in the control of contact-rich robots\n\n\n\n\n\n\n\n\nWalking machines\n\n\n\n\n\n\n\n\nManipulators"
  },
  {
    "objectID": "main.html#challenge-1-mode-changes",
    "href": "main.html#challenge-1-mode-changes",
    "title": "main",
    "section": "Challenge 1: Mode Changes",
    "text": "Challenge 1: Mode Changes\n\n\n\n\n\n\n\n\n\n\nContacts cause mode changes\nEach mode has distinct dynamics\nSwitching control does not scale well\nIt is difficult to parameterize the switching condition"
  },
  {
    "objectID": "main.html#challenge-1-proposed-method",
    "href": "main.html#challenge-1-proposed-method",
    "title": "main",
    "section": "Challenge 1: Proposed Method",
    "text": "Challenge 1: Proposed Method\n \n\nOur method uses data-driven technique to automatically learn a mixture of expert controller and the switching conditionals\n\n\n\nWe infer contact-aware controllers by training on trajectories generated from contact models\n\nContact-aware controllers minimize the adverse effects of contacts or leverage the potential contacts to their advantage"
  },
  {
    "objectID": "main.html#challenge-2-operating-under-uncertain-conditions",
    "href": "main.html#challenge-2-operating-under-uncertain-conditions",
    "title": "main",
    "section": "Challenge 2: Operating under Uncertain Conditions",
    "text": "Challenge 2: Operating under Uncertain Conditions"
  },
  {
    "objectID": "main.html#challenge-2-existing-methods",
    "href": "main.html#challenge-2-existing-methods",
    "title": "main",
    "section": "Challenge 2: Existing Methods",
    "text": "Challenge 2: Existing Methods\n\n\n\n\n\nReinforcement learning \n\n\nÂ \n\n\n\nStrengths\n\nMore general\nUnknown dynamics OK\n\nWeaknesses\n\nSample complexity\nStability guarantees?\n\n\n\n\n\n\n\n\n\n\nBayesian Neural Passivity-based Control \n\n\nÂ \n\n\n\nStrengths\n\nStability guarantees\nClosed-form policy\nReasons about model uncertainties"
  },
  {
    "objectID": "dissertation-main/Slides/quarto/presentations/main.html#robust-control-of-contact-rich-robots-via-neural-bayesian-inference",
    "href": "dissertation-main/Slides/quarto/presentations/main.html#robust-control-of-contact-rich-robots-via-neural-bayesian-inference",
    "title": "main",
    "section": "Robust Control of Contact-Rich Robots via Neural Bayesian Inference",
    "text": "Robust Control of Contact-Rich Robots via Neural Bayesian Inference\n\n\nDoctoral Dissertation Defense\n\n\n\n\nCandidate:  Nardos AshenafiğŸ“  Electrical and Computer Engineering Department  Boise State University, Boise, Idaho, USA\n\n\nSupervisory Committee:  Aykut Satici, Ph.D.Â  John Chiasson, Ph.D.Â  Kurtis Cantley, Ph.D.Â  Hao Chen, Ph.D.Â  Arash Komaee, Ph.D."
  },
  {
    "objectID": "dissertation-main/Slides/quarto/presentations/main.html#publications-and-contributions",
    "href": "dissertation-main/Slides/quarto/presentations/main.html#publications-and-contributions",
    "title": "main",
    "section": "Publications and Contributions",
    "text": "Publications and Contributions\n\n\n\n\nPublished\n\nCCTA 2021: Cooperative Manipulation\nACC 2022: Bayesian NeuralPbc\nL-CSS 2022: Bayesian NeuralPbc\n\nCDC 2022\n\nArxiv 2022: Control Design via Bayesian Inference: Theoretical Justification of Robustness \n\n\n\n\n\nUpcoming Submissions\n\nTACON 2023: Control of Hybrid Dynamical Systems via Deep-net Mixture of Experts\nIJRR 2023: Data Driven Passivity-Based Control of the Rimless Wheel on Uneven Terrain"
  },
  {
    "objectID": "dissertation-main/Slides/quarto/presentations/main.html#hybrid-systems",
    "href": "dissertation-main/Slides/quarto/presentations/main.html#hybrid-systems",
    "title": "main",
    "section": "Hybrid Systems",
    "text": "Hybrid Systems\n\n\nexhibit both continuous state flow and discrete state transitions\n\n\n\n\nE.g. Room temperature control, contact-rich robots\n\n\n\n\nWe tackle two main challenges in the control of contact-rich robots\n\n\n\n\n\n\n\n\nWalking machines\n\n\n\n\n\n\n\n\nManipulators"
  },
  {
    "objectID": "dissertation-main/Slides/quarto/presentations/main.html#challenge-1-mode-changes",
    "href": "dissertation-main/Slides/quarto/presentations/main.html#challenge-1-mode-changes",
    "title": "main",
    "section": "Challenge 1: Mode Changes",
    "text": "Challenge 1: Mode Changes\n\n\n\n\n\n\n\n\n\n\nContacts cause mode changes\nEach mode has distinct dynamics\nSwitching control does not scale well\nIt is difficult to parameterize the switching condition"
  },
  {
    "objectID": "dissertation-main/Slides/quarto/presentations/main.html#challenge-1-proposed-method",
    "href": "dissertation-main/Slides/quarto/presentations/main.html#challenge-1-proposed-method",
    "title": "main",
    "section": "Challenge 1: Proposed Method",
    "text": "Challenge 1: Proposed Method\n \n\nOur method uses data-driven technique to automatically learn a mixture of expert controller and the switching conditionals\n\n\n\nWe infer contact-aware controllers by training on trajectories generated from contact models\n\nContact-aware controllers minimize the adverse effects of contacts or leverage the potential contacts to their advantage"
  },
  {
    "objectID": "dissertation-main/Slides/quarto/presentations/main.html#challenge-2-operating-under-uncertain-conditions",
    "href": "dissertation-main/Slides/quarto/presentations/main.html#challenge-2-operating-under-uncertain-conditions",
    "title": "main",
    "section": "Challenge 2: Operating under Uncertain Conditions",
    "text": "Challenge 2: Operating under Uncertain Conditions"
  },
  {
    "objectID": "dissertation-main/Slides/quarto/presentations/main.html#challenge-2-existing-methods",
    "href": "dissertation-main/Slides/quarto/presentations/main.html#challenge-2-existing-methods",
    "title": "main",
    "section": "Challenge 2: Existing Methods",
    "text": "Challenge 2: Existing Methods\n\n\n\n\n\nReinforcement learning \n\n\nÂ \n\n\n\nStrengths\n\nMore general\nUnknown dynamics OK\n\nWeaknesses\n\nSample complexity\nStability guarantees?\n\n\n\n\n\n\n\n\n\n\nBayesian Neural Passivity-based Control \n\n\nÂ \n\n\n\nStrengths\n\nStability guarantees\nClosed-form policy\nReasons about model uncertainties"
  },
  {
    "objectID": "dissertation-main/Slides/quarto/presentations/main.html#mixture-of-experts-moe-old-faithful",
    "href": "dissertation-main/Slides/quarto/presentations/main.html#mixture-of-experts-moe-old-faithful",
    "title": "main",
    "section": "Mixture of Experts (MOE): Old Faithful",
    "text": "Mixture of Experts (MOE): Old Faithful\n\nObjective: learn two expert Gaussian models that represent dataset ğ”»={(x1,y1),â€¦,(xN,yN)}\\mathbb{D} = \\{(x_1, y_1), \\dots, (x_N, y_N) \\}\n\n\n\n\n\nThe experts are chosen as F(x;Î¸)={ğ’©1(Î¼1,Ïƒ1),ğ’©2(Î¼2,Ïƒ2)}Î¸={(Î¼1,Ïƒ1),(Î¼2,Ïƒ2)}\\begin{align*}\nF(x;\\theta) &= \\{\\mathcal{N}_1(\\mu_1, \\sigma_1), \\mathcal{N}_2(\\mu_2, \\sigma_2)\\} \\\\\n\\theta &= \\{(\\mu_1, \\sigma_1), (\\mu_2, \\sigma_2) \\}\n\\end{align*}\n\nPrediction is a weighted-average of experts\n\n\n\n\n\n\n\n\n\n\n\nThe gating network is a neural net ğ(x|Ïˆ)=[P1(x|Ïˆ),P2(x|Ïˆ)]\\mathbf{P}(x | \\psi) = [P_1(x | \\psi), P_2(x | \\psi) ]\n\nDivides the input space into partitions\n\n\n\n\n\nExpectation Maximization: maximizes log likelihood ln{P(ğ”»|Î¸,Ïˆ)}=âˆ‘j=1Nlnâˆ‘i=1NF12Ï€Ïƒi2exp(âˆ’12(yjâˆ’Î¼i)2Ïƒi2)Pi(xj,Ïˆ)\n\\ln \\{P(\\mathbb{D} | \\theta, \\psi) \\} = \\sum_{j=1}^{N} \\ln \\sum_{i=1}^{N_F} \\frac{1}{\\sqrt{2 \\pi \\sigma_i^2}} \\exp \\left( -\\frac{1}{2}\\frac{(y_j - \\mu_i)^2}{\\sigma_i^2} \\right) P_i(x_j, \\psi)"
  },
  {
    "objectID": "dissertation-main/Slides/quarto/presentations/main.html#mixture-of-experts-controller-1",
    "href": "dissertation-main/Slides/quarto/presentations/main.html#mixture-of-experts-controller-1",
    "title": "main",
    "section": "Mixture of Experts Controller",
    "text": "Mixture of Experts Controller\n\n\n\nObjective: learn contact-aware mixture of experts controller and a gating network\n\n\n\n\nAll the experts and the gating network are given by neural nets\nWe pose the search over the parameters Ïˆ,Î¸\\psi, \\theta as the following optimization problem\n\n\n\n\nOptimization Problem\n\n\nminimizeÏˆ,Î¸âˆ«0Tâ„“(x(t),u)â…†t,subject toM(q)â…†qÌ‡+h(x;Ïˆ,Î¸)â…†tâˆ’â…†R=0,u={Fi(x;Î¸i)|iâˆ¼Categorical(ğ(x|Ïˆ))}.\\begin{align*}\n    \\begin{aligned}\n        \\underset{\\psi, \\theta}{\\textrm{minimize}} \n        & & & \\int_0^T \\ell (x(t),u) \\dd t , \\\\%\n        \\textrm{subject to}\n        & & & M(q) \\dd \\dot{q} + h(x; \\psi, \\theta)\\dd t - \\dd R  = 0,\\\\%\n        & & & u = \\{F_i(x; \\theta_i) \\; | \\; i  \\sim \\text{Categorical} (\\mathbf{P}(x| \\psi)) \\}.\n    \\end{aligned}\n\\end{align*}"
  },
  {
    "objectID": "dissertation-main/Slides/quarto/presentations/main.html#training",
    "href": "dissertation-main/Slides/quarto/presentations/main.html#training",
    "title": "main",
    "section": "Training",
    "text": "Training\n\n\n\nTraining procedure:\n\nStart from initial parameters (Ïˆ,Î¸)(\\psi, \\theta)\nSample initial state x0x_0\nGenerate trajectories Ï•(x0,u,T)\\phi(x_0, u, T) using current parameters iâˆ¼Categorical(ğ(x|Ïˆ))u(x;Ïˆ,Î¸)=Fi(x;Î¸i)M(q)â…†qÌ‡+h(x;Ïˆ,Î¸)â…†tâˆ’â…†R=0 (Moreauâ€™s time stepping)\\begin{gather*}\ni  \\sim \\text{Categorical} (\\mathbf{P}(x| \\psi)) \\\\\nu(x; \\psi, \\theta) = F_i(x; \\theta_i) \\\\\nM(q) \\dd \\dot{q} + h(x; \\psi, \\theta) \\dd t - \\dd R  = 0 \\text{ (Moreau's time stepping)}\n\\end{gather*}\nAssign a running cost â„“\\ell to the trajectories based on performance\nUpdate parameters (Ïˆ,Î¸)(\\psi, \\theta) to minimize running cost"
  },
  {
    "objectID": "dissertation-main/Slides/quarto/presentations/main.html#performance-objective",
    "href": "dissertation-main/Slides/quarto/presentations/main.html#performance-objective",
    "title": "main",
    "section": "Performance Objective",
    "text": "Performance Objective\n\nminimizeÏˆ,Î¸âˆ«0Tâ„“(x(t),u)â…†t,subject toM(q)â…†qÌ‡+h(x;Ïˆ,Î¸)â…†tâˆ’â…†R=0,u={Fi(x;Î¸i)|iâˆ¼Categorical(ğ(x|Ïˆ))}.\\begin{align*}\n    \\begin{aligned}\n        \\underset{\\psi, \\theta}{\\textrm{minimize}} \n        & & & \\int_0^T \\ell (x(t),u) \\dd t , \\\\%\n        \\textrm{subject to}\n        & & & M(q) \\dd \\dot{q} + h(x; \\psi, \\theta)\\dd t - \\dd R  = 0,\\\\%\n        & & & u = \\{F_i(x; \\theta_i) \\; | \\; i  \\sim \\text{Categorical} (\\mathbf{P}(x| \\psi)) \\}.\n    \\end{aligned}\n\\end{align*}\n\n\nAccumulated loss: total quadratic loss from desired state x*x^* â„“(x,u)=12(xâˆ’x*)âŠ¤ğ’¬(xâˆ’x*)+12uâŠ¤â„›uğ’¬â‰»0,â„›â‰½0\\begin{gather*}\n\\ell(x, u) = \\frac{1}{2}(x - x^*)^\\top \\mathcal{Q} (x - x^*) + \\frac{1}{2} u^\\top \\mathcal{R} u \\\\\n\\mathcal{Q} \\succ 0, \\mathcal{R} \\succeq 0\n\\end{gather*}\n\n\n\nThe corresponding likelihood function is\n\n\n\nln{P(ğ”»|Î¸,Ïˆ)}=âˆ‘j=1Nlnâˆ‘i=1NF12Ï€Ïƒi2exp(âˆ’12(yjâˆ’Î¼i)2Ïƒi2)Pi(xj,Ïˆ)\n\\ln \\{P(\\mathbb{D} | \\theta, \\psi) \\} = \\sum_{j=1}^{N} \\ln \\sum_{i=1}^{N_F} \\frac{1}{\\sqrt{2 \\pi \\sigma_i^2}} \\exp \\left( -\\frac{1}{2}\\frac{(y_j - \\mu_i)^2}{\\sigma_i^2} \\right) P_i(x_j, \\psi)\n\n\n\nln{P(Ï•|Î¸,Ïˆ)}=âˆ‘t=0Tlnâˆ‘i=1NF12Ï€s2exp(âˆ’12â„“(x(t+Î”t),Fi)2s2)Pi(x(t),Ïˆ)\n\\ln \\{P(\\phi | \\theta, \\psi) \\} = \\sum_{t=0}^{T} \\ln \\sum_{i=1}^{N_F} \\frac{1}{\\sqrt{2 \\pi s^2}} \\exp \\left( -\\frac{1}{2}\\frac{\\ell (x(t+\\Delta t), F_i )^2}{s^2} \\right) P_i(x(t), \\psi)"
  },
  {
    "objectID": "dissertation-main/Slides/quarto/presentations/main.html#state-sampling",
    "href": "dissertation-main/Slides/quarto/presentations/main.html#state-sampling",
    "title": "main",
    "section": "State Sampling",
    "text": "State Sampling\nObjective: meet performance for various initial states"
  },
  {
    "objectID": "dissertation-main/Slides/quarto/presentations/main.html#cartpole-with-wall-barriers",
    "href": "dissertation-main/Slides/quarto/presentations/main.html#cartpole-with-wall-barriers",
    "title": "main",
    "section": "Cartpole with wall barriers",
    "text": "Cartpole with wall barriers\n\n\n\n\n\nNotice LQR fails due to the impact from the wall\nMOE controller training\n\nthere are three deep-net experts Fi(x;Î¸i)F_i(x;\\theta_i)\nthe gating network is also a neural net"
  },
  {
    "objectID": "dissertation-main/Slides/quarto/presentations/main.html#results",
    "href": "dissertation-main/Slides/quarto/presentations/main.html#results",
    "title": "main",
    "section": "Results",
    "text": "Results\n\nThe contact-aware MOE controller\n\nleverages the impacts from the wall\nswitches to a policy that rapidly brakes to assist in the catching process"
  },
  {
    "objectID": "dissertation-main/Slides/quarto/presentations/main.html#conclusions",
    "href": "dissertation-main/Slides/quarto/presentations/main.html#conclusions",
    "title": "main",
    "section": "Conclusions",
    "text": "Conclusions\n \n\n\nWe provide a data-driven control design that automatically learns several policies and the necessary switching scheme\nThe framework leverages the switching controllers to stabilize the multi-modal dynamical system\nThe gating network successsfully parameterizes the control-switching conditionals that achieves the desired performance"
  },
  {
    "objectID": "dissertation-main/Slides/quarto/presentations/main.html#dissipativity",
    "href": "dissertation-main/Slides/quarto/presentations/main.html#dissipativity",
    "title": "main",
    "section": "Dissipativity",
    "text": "Dissipativity\n\n\n\nA dynamical system Î£:{xÌ‡=f(x,u)y=g(x,u)xâˆˆğ’³âŠ‚â„2m,uâˆˆğ’°âŠ‚â„n\n\\Sigma: \\quad\n\\begin{cases}\n\\dot{x} &= f(x,u) \\\\\ny &= g(x,u)\n\\end{cases}\n\\quad x \\in \\mathcal{X} \\subset \\mathbb{R}^{2m}, \\, u \\in \\mathcal{U} \\subset \\mathbb{R}^{n} \n is dissipative with respect to some supply rate ss if there exists a storage function H:ğ’³â†’â„+H: \\mathcal{X} \\to \\mathbb{R}^{+} such that H(x(t1))â‰¤H(x(t0))+âˆ«t0t1s(u(t),y(t))dt\nH\\left(  x(t_1) \\right) \\leq  H\\left(  x(t_0) \\right) + \\int_{t_0}^{t_1} s(u(t), y(t)) \\, \\text{d}t\n for all x(t0)=x0x(t_0) = x_0, all input uu, and all t1â‰¥t0t_1 \\geq t_0\nIt is passive if s=uâŠ¤ys = u^{\\top} y"
  },
  {
    "objectID": "dissertation-main/Slides/quarto/presentations/main.html#stability-of-passive-systems",
    "href": "dissertation-main/Slides/quarto/presentations/main.html#stability-of-passive-systems",
    "title": "main",
    "section": "Stability of Passive Systems",
    "text": "Stability of Passive Systems\n\n\nÎ£:{xÌ‡=f(x,u)f(0,0)=0,y=g(x,u)g(0,0)=0.\n\\Sigma: \\quad\n\\begin{cases}\n  \\dot{x} &= f(x,u) && f(0,0) = 0, \\\\\n  y &= g(x,u) && g(0,0) = 0.\n\\end{cases}\n\nuâŠ¤yâ‰¥HÌ‡=âˆ‚Hâˆ‚xf(x,u),Hâ‰¥0,yâ‰¡0âŸ¹xâ‰¡0.\\begin{gather*}\nu^{\\top} y \\geq \\dot{H} = \\frac{\\partial H}{\\partial x} f(x,u), \\\\\n\\quad H \\geq 0,\\quad y \\equiv 0 \\implies x \\equiv 0.\n\\end{gather*}\n\n\n\n\nLemma (Khalil, 2002)\n\n\nThe origin of Î£\\Sigma is:\n\nstable if Î£\\Sigma is passive,\nasymptotically stable if Î£\\Sigma is output strictly passive (s=uâŠ¤yâˆ’Î´âˆ¥yâˆ¥2,Î´>0s = u^\\top y - \\delta \\lVert y \\rVert^2, \\; \\delta > 0)."
  },
  {
    "objectID": "dissertation-main/Slides/quarto/presentations/main.html#simple-pendulum",
    "href": "dissertation-main/Slides/quarto/presentations/main.html#simple-pendulum",
    "title": "main",
    "section": "Simple Pendulum",
    "text": "Simple Pendulum\n\n\n\n\n\nEnergy Shaping\n\n\nH(q,p)=12Jâˆ’1p2+mgl(1âˆ’cosq)H(q,p) = \\frac{1}{2} J^{-1} p^2 + mgl (1 - \\cos q)\n[qÌ‡pÌ‡]=[âˆ’01âˆ’10][âˆ‡qHdâˆ‡pHd]+[0Î©]udi,y=qÌ‡\n\\begin{bmatrix} \\dot{q} \\\\ \\dot{p} \\end{bmatrix} = \n\\begin{bmatrix} \\phantom{-}0 & 1 \\\\ -1 & 0 \\end{bmatrix} \n\\begin{bmatrix} \\nabla_q H_{\\phantom{d}} \\\\ \\nabla_p H_{\\phantom{d}} \\end{bmatrix} +\n\\begin{bmatrix} 0 \\\\ \\Omega \\end{bmatrix} u_\\phantom{di},\n\\qquad y = \\dot{q}\n\n\nChoose u=ues+udiu = u_{es} + u_{di} that transforms system into a passive one with xâ‹†=(qâ‹†,0)x^\\star = (q^\\star, 0) \n\n\nÎ©ues=âˆ‡qHâˆ’âˆ‡qHd,Î©udi=âˆ’Î©KDÎ©âŠ¤âˆ‡pHd\\Omega u_{es} = \\nabla_q H - \\nabla_q H_d , \\quad \\Omega u_{di} = -\\Omega K_D \\Omega^\\top \\nabla_p H_d\n\n\n\n[qÌ‡pÌ‡]=[âˆ’01âˆ’10][âˆ‡qHdâˆ‡pHd]+[0Î©]udi,y=qÌ‡\n\\begin{bmatrix} \\dot{q} \\\\ \\dot{p} \\end{bmatrix} = \n\\begin{bmatrix} \\phantom{-}0 & 1 \\\\ -1 & 0 \\end{bmatrix} \n\\begin{bmatrix} \\nabla_q H_d \\\\ \\nabla_p H_d \\end{bmatrix} +\n\\begin{bmatrix} 0 \\\\ \\Omega \\end{bmatrix} u_{di},\n\\qquad y = \\dot{q}\n\n\n\n[qÌ‡pÌ‡]=[âˆ’01âˆ’1âˆ’Î©KDÎ©âŠ¤][âˆ‡qHdâˆ‡pHd],y=qÌ‡\n\\begin{bmatrix} \\dot{q} \\\\ \\dot{p} \\end{bmatrix} = \n\\begin{bmatrix} \\phantom{-}0 & 1 \\\\ -1 & -\\Omega K_D \\Omega^\\top \\end{bmatrix} \n\\begin{bmatrix} \\nabla_q H_d \\\\ \\nabla_p H_d \\end{bmatrix},\n\\qquad y = \\dot{q}"
  },
  {
    "objectID": "dissertation-main/Slides/quarto/presentations/main.html#simple-pendulum-1",
    "href": "dissertation-main/Slides/quarto/presentations/main.html#simple-pendulum-1",
    "title": "main",
    "section": "Simple Pendulum",
    "text": "Simple Pendulum\n\n\n\n\nControl Synthesis via PBC\n\n\nChoose u=ues+udiu = u_{es} + u_{di} that transforms system into a passive one with xâ‹†=(qâ‹†,0)x^\\star = (q^\\star, 0)\nÎ©ues=âˆ‡qHâˆ’âˆ‡qHd,Î©udi=âˆ’Î©KDÎ©âŠ¤âˆ‡pHd\\Omega u_{es} = \\nabla_q H - \\nabla_q H_d , \\quad \\Omega u_{di} = -\\Omega K_D \\Omega^\\top \\nabla_p H_d\n[qÌ‡pÌ‡]=[âˆ’01âˆ’1âˆ’Î©KDÎ©âŠ¤][âˆ‡qHdâˆ‡pHd],y=qÌ‡\n\\begin{bmatrix} \\dot{q} \\\\ \\dot{p} \\end{bmatrix} = \n\\begin{bmatrix} \\phantom{-}0 & 1 \\\\ -1 & -\\Omega K_D \\Omega^\\top \\end{bmatrix} \n\\begin{bmatrix} \\nabla_q H_d \\\\ \\nabla_p H_d \\end{bmatrix},\n\\qquad y = \\dot{q}\n\n\nHd(q,p)=12Jâˆ’1p2+Vd(q),Vd(q)=12KP(qâˆ’qâ‹†)2H_d(q,p) = \\frac{1}{2} J^{-1} p^2 + V_d(q), \\quad V_d(q) = \\frac{1}{2} K_{P} \\left( q - q^\\star \\right)^2\n\n\n\nHÌ‡d=âˆ’KD(Jâˆ’1p)2=yâŠ¤udiâ‰¤0\\dot{H}_d = -K_D \\left( J^{-1} p \\right)^2 = y^\\top u_{di} \\leq 0\n\n\nu=âˆ’mglsin(q)âˆ’KP(qâˆ’qâ‹†)âˆ’KDqÌ‡\\boxed{u = -mgl\\sin(q) - K_P(q - q^\\star) - K_D \\dot{q}}\n\n\n\n\n\n\n\n\nConstraint on HdH_d\n\n\nÎ©âŠ¥(âˆ‡qHâˆ’âˆ‡qHd)=0\\begin{align*}\n\\Omega^\\perp (\\nabla_q H  - \\nabla_q H_d) = 0\n\\end{align*} where Î©âŠ¥Î©=0\\Omega^\\perp \\Omega = 0."
  },
  {
    "objectID": "dissertation-main/Slides/quarto/presentations/main.html#neuralpbc",
    "href": "dissertation-main/Slides/quarto/presentations/main.html#neuralpbc",
    "title": "main",
    "section": "NeuralPbc",
    "text": "NeuralPbc\n\n\n\n\n\nNeuralPbc Optimization Problem\n\n\nminimizeÎ¸J(Ï•,uÎ¸)=ğ”¼x0âˆˆğ’ŸN[â„“(Ï•(x0,u,T),u)],subject to[qÌ‡pÌ‡]=[0Iâˆ’I0][âˆ‡qHâˆ‡pH]+[0Î©]uÎ¸,uÎ¸=Î©â€ (âˆ‡qHâˆ’âˆ‡qHdÎ¸).\n\\begin{aligned}\n\\underset{\\theta}{\\text{minimize}} && J(\\phi, u^\\theta) &= \\mathbb{E}_{x_0 \\in \\mathcal{D}_N}[ \\ell( \\phi(x_0, u, T), u) ], \\\\\n\\text{subject to} &&\n\\begin{bmatrix}\n  \\dot{q} \\\\ \\dot{p}\n\\end{bmatrix} &=\n\\begin{bmatrix}\n  0 & I \\\\ -I & 0\n\\end{bmatrix}\n\\begin{bmatrix} \\nabla_q H \\\\ \\nabla_p H \\end{bmatrix} + \n\\begin{bmatrix}\n  0 \\\\ \\Omega\n\\end{bmatrix} u^{\\theta},\n\\\\\n&& u^\\theta &= \\Omega^{\\dagger}(\\nabla_q H  - \\nabla_q H_d^\\theta).\n\\end{aligned}\n\n\n\n\n\nParameterize HdH_d by a neural network HdÎ¸H_d^\\theta\nDesired performance characterized by â„“\\ell observed from trajectory Ï•\\phi\nApproximate solutions to the PDEs found via stochastic gradient descent"
  },
  {
    "objectID": "dissertation-main/Slides/quarto/presentations/main.html#bayesian-learning",
    "href": "dissertation-main/Slides/quarto/presentations/main.html#bayesian-learning",
    "title": "main",
    "section": "Bayesian Learning",
    "text": "Bayesian Learning\n\n\nObjective: Given finite dataset with inherent noise, we are in search of a regression model\n\n\n\n\n\nE.g. Recognizing handwritten digits from images\n\nnoise due to differences in individual handwriting\n\n\n\n\n\nBayesian learning provides stochastic models that do not overfit on the training data\n\nStochastic model: F(x;Î¸),Î¸âˆ¼P(Î¸|ğ”»)F(x;\\theta), \\theta \\sim P(\\theta | \\mathbb{D})"
  },
  {
    "objectID": "dissertation-main/Slides/quarto/presentations/main.html#robustness-via-bayesian-learning",
    "href": "dissertation-main/Slides/quarto/presentations/main.html#robustness-via-bayesian-learning",
    "title": "main",
    "section": "Robustness via Bayesian Learning",
    "text": "Robustness via Bayesian Learning\n\n\n\n\n\nNeuralPbc assumes a nominal model xÌ‡=f(x,u)\\dot{x} = f(x, u)\nThe trained controller must not overfit on the observations generated from the nominal model\n\n\n\n\n\n\n\n\n\nOur method: HdH_d is a Bayesian neural network\n\nachieves the performance objective for samples Î¸âˆ¼P(Î¸|ğ”»)\\theta \\sim P(\\theta | \\mathbb{D})\nsearches for ensemble of parameters that meet the desired performance P(Î¸âˆ£ğ”»)=P(ğ”»âˆ£Î¸)âlikelihoodP(Î¸)âpriorâˆ«Î¸P(ğ”»âˆ£Î¸â€²)P(Î¸â€²)dÎ¸â€²âŸevidence.\n  P(\\theta \\mid \\mathbb{D}) = \\frac{\\overbrace{P(\\mathbb{D} \\mid\n  \\theta)}^{\\text{likelihood}}\\overbrace{P(\\theta)}^{\\text{prior}}}\n  {\\underbrace{\\int_\\theta P(\\mathbb{D} \\mid \\theta^\\prime)P(\\theta^\\prime)\n  d\\theta^\\prime}_{\\text{evidence}}}."
  },
  {
    "objectID": "dissertation-main/Slides/quarto/presentations/main.html#training-stochastic-models",
    "href": "dissertation-main/Slides/quarto/presentations/main.html#training-stochastic-models",
    "title": "main",
    "section": "Training Stochastic Models",
    "text": "Training Stochastic Models\n\n\n\n\n\n\nBayesian Inference\n\n\nmaximizeP(Î¸|ğ”»)P(ğ”»|Î¸)P(Î¸),subject toÎ¸âˆ¼P(Î¸|ğ”»),ğ”»={(x1,y1),â€¦,(xN,yN)}.\n\\begin{aligned}\n\\underset{P(\\theta | \\mathbb{D})}{\\text{maximize}} &&& P(\\mathbb{D} | \\theta) P(\\theta), \\\\\n\\text{subject to} &&\n& \\theta \\sim P(\\theta | \\mathbb{D}), \\\\\n&& \\mathbb{D} &= \\{(x_1, y_1), \\dots, (x_N, y_N) \\}.\n\\end{aligned}\n\n\n\n\n\n\n\n\n\n\nBayesian Inference\n\n\nmaximizeP(Î¸|ğ”»)âˆj=1Nğ’©(âˆ¥F(xj;Î¸)âˆ’yjâˆ¥|0,s1)ğ’©(âˆ¥Î¸âˆ’Î¸0âˆ¥|0,s2),subject toÎ¸âˆ¼P(Î¸|ğ”»),ğ”»={(x1,y1),â€¦,(xN,yN)}.\n\\begin{aligned}\n\\underset{P(\\theta | \\mathbb{D})}{\\text{maximize}} && \\prod_{j=1}^{N} \\mathcal{N}&(\\| F(x_j; \\theta) -  y_j \\| \\; | \\; 0, s_1) \\mathcal{N}(\\| \\theta - \\theta_0 \\| \\; | \\; 0, s_2), \\\\\n\\text{subject to} &&\n& \\theta \\sim P(\\theta | \\mathbb{D}), \\\\\n&& \\mathbb{D} &= \\{(x_1, y_1), \\dots, (x_N, y_N) \\}.\n\\end{aligned}\n\n\n\n\n\n\n\n\n\n\nBayesian Inference\n\n\nmaximizezâ„’(ğ”»,z)=ğ”¼Î¸âˆ¼Q[ln(P(ğ”»âˆ£Î¸)P(Î¸))âˆ’ln(Q(Î¸;z))],subject toÎ¸âˆ¼Q(Î¸;z),ğ”»={(x1,y1),â€¦,(xN,yN)}.\n\\begin{aligned}\n\\underset{z}{\\text{maximize}} && \\mathcal{L}(\\mathbb{D},z) &= \\mathbb{E}_{\\theta \\sim Q} \\left[\\ln(P(\\mathbb{D} \\mid \\theta)P(\\theta)) - \\ln(Q(\\theta;z)) \\right], \\\\\n\\text{subject to} &&\n& \\theta \\sim Q(\\theta;z), \\\\\n&& \\mathbb{D} &= \\{(x_1, y_1), \\dots, (x_N, y_N) \\}.\n\\end{aligned}\n\n\n\n\n\n\n\n\n\nVariational Inference: approximates the posterior P(Î¸|ğ”»)P(\\theta | \\mathbb{D}) with a pre-selected distribution Q(Î¸;z)Q(\\theta; z)\nObjective: collect NÎ¸N_\\theta samples from the current posterior Q(Î¸;z)Q(\\theta; z) and maximize Elbo â„’(ğ”»,z)=ğ”¼Î¸âˆ¼Q[ln(P(ğ”»âˆ£Î¸)P(Î¸))âˆ’ln(Q(Î¸;z))]\n\\mathcal{L}(\\mathbb{D},z) = \\mathbb{E}_{\\theta \\sim Q} \\left[\\ln(P(\\mathbb{D} \\mid \\theta)P(\\theta)) - \\ln(Q(\\theta;z)) \\right]"
  },
  {
    "objectID": "dissertation-main/Slides/quarto/presentations/main.html#bayesian-neuralpbc-1",
    "href": "dissertation-main/Slides/quarto/presentations/main.html#bayesian-neuralpbc-1",
    "title": "main",
    "section": "Bayesian NeuralPbc",
    "text": "Bayesian NeuralPbc\n\n\n\n\n\n\nNeuralPbc Optimization Problem\n\n\nminimizeÎ¸J(Ï•,uÎ¸)=ğ”¼x0âˆˆğ’ŸN[â„“(Ï•(x0,u,T),u)],subject to[qÌ‡pÌ‡]=[0Iâˆ’I0][âˆ‡qHâˆ‡pH]+[0Î©]uÎ¸,uÎ¸=Î©â€ (âˆ‡qHâˆ’âˆ‡qHdÎ¸).\n\\begin{aligned}\n\\underset{\\theta}{\\text{minimize}} && J(\\phi, u^\\theta) &= \\mathbb{E}_{x_0 \\in \\mathcal{D}_N}[ \\ell( \\phi(x_0, u, T), u) ], \\\\\n\\text{subject to} &&\n\\begin{bmatrix}\n  \\dot{q} \\\\ \\dot{p}\n\\end{bmatrix} &=\n\\begin{bmatrix}\n  0 & I \\\\ -I & 0\n\\end{bmatrix}\n\\begin{bmatrix} \\nabla_q H \\\\ \\nabla_p H \\end{bmatrix} + \n\\begin{bmatrix}\n  0 \\\\ \\Omega\n\\end{bmatrix} u^{\\theta},\n\\\\\n&& u^\\theta &= \\Omega^{\\dagger}(\\nabla_q H  - \\nabla_q H_d^\\theta).\n\\end{aligned}\n\n\n\n\n\n\n\n\n\nBayesian NeuralPbc Optimization Problem\n\n\nminimizezJ(Ï•,uÎ¸)=ğ”¼x0âˆˆğ’ŸN[â„“(Ï•(x0,u,T),u)],subject to[qÌ‡pÌ‡]=[0Iâˆ’I0][âˆ‡qHâˆ‡pH]+[0Î©]uÎ¸,uÎ¸=Î©â€ (âˆ‡qHâˆ’âˆ‡qHdÎ¸),Î¸âˆ¼Q(Î¸;z).\n\\begin{aligned}\n    \\underset{z}{\\text{minimize}} && J(\\phi, u^\\theta) &= \\mathbb{E}_{x_0 \\in \\mathcal{D}_N}[ \\ell( \\phi(x_0, u, T), u) ], \\\\\n    \\text{subject to} &&\n    \\begin{bmatrix}\n    \\dot{q} \\\\ \\dot{p}\n    \\end{bmatrix} &=\n    \\begin{bmatrix}\n    0 & I \\\\ -I & 0\n    \\end{bmatrix}\n    \\begin{bmatrix} \\nabla_q H \\\\ \\nabla_p H \\end{bmatrix} + \n    \\begin{bmatrix}\n    0 \\\\ \\Omega\n    \\end{bmatrix} u^{\\theta},\n    \\\\\n    && u^\\theta &= \\Omega^{\\dagger}(\\nabla_q H  - \\nabla_q H_d^\\theta),\\\\\n    && \\theta &\\sim Q(\\theta; z).\n\\end{aligned} \n\n\n\n\n\n\n\n\nThe parameter zz of the posterior Q(Î¸;z)Q(\\theta;z) is inferred from running cost J(Ï•,uÎ¸)J(\\phi, u^\\theta)\nHdÎ¸H_d^\\theta is a Bayesian neural network (BNN)"
  },
  {
    "objectID": "dissertation-main/Slides/quarto/presentations/main.html#uncertainty-modeling",
    "href": "dissertation-main/Slides/quarto/presentations/main.html#uncertainty-modeling",
    "title": "main",
    "section": "Uncertainty Modeling",
    "text": "Uncertainty Modeling\n\nWe provide more structure to the variance of the Bayesian controllers\n\n\n\n\nBayesian NeuralPbc Optimization Problem\n\n\nminimizezJ(Ï•,uÎ¸)=ğ”¼x0âˆˆğ’ŸN[â„“(Ï•(x0,u,T),u)],subject toâ…†x=([âˆ’âˆ‡pHâˆ’âˆ‡qH]+[0Î©]uÎ¸(x))â…†t+âˆ‡xu(x)â…†Wt,uÎ¸=Î©â€ (âˆ‡qHâˆ’âˆ‡qHdÎ¸),Î¸âˆ¼Q(Î¸;z),psâˆ¼ğ’©(pÌ‚s,Ïƒp).\n\\begin{aligned}\n    \\underset{z}{\\text{minimize}} && J(\\phi, u^\\theta) &= \\mathbb{E}_{x_0 \\in \\mathcal{D}_N}[ \\ell( \\phi(x_0, u, T), u) ], \\\\\n    \\text{subject to} &&\n    \\dd x &= \\left(\n        \\begin{bmatrix}\\phantom{-}\\nabla_p H \\\\-\\nabla_q H \\end{bmatrix} + \\begin{bmatrix} 0 \\\\ \\Omega \\end{bmatrix} u^{\\theta}(x) \\right) \\dd t + \\nabla_x u(x) \\dd W_t, \\\\\n    && u^\\theta &= \\Omega^{\\dagger}(\\nabla_q H  - \\nabla_q H_d^\\theta),\\\\\n    && \\theta &\\sim Q(\\theta; z), \\\\\n    && p_s &\\sim \\mathcal{N}(\\hat{p}_s, \\sigma_p).\n\\end{aligned} \n\n\n\n\n\nObjective: maximize Elbo\n\nâ„’(J,z)=ğ”¼Î¸âˆ¼Q[ln(P(Jâˆ£Î¸)P(Î¸))âˆ’ln(Q(Î¸;z))]P(J|Î¸)=ğ’©(J|0,s).\\begin{gather*}\n  \\mathcal{L}(J,z) = \\mathbb{E}_{\\theta \\sim Q} \\left[\\ln(P(J \\mid \\theta)P(\\theta)) - \\ln(Q(\\theta;z)) \\right] \\\\ \n  P(J | \\theta) = \\mathcal{N}(J \\; | \\; 0, s).\n\\end{gather*}"
  },
  {
    "objectID": "dissertation-main/Slides/quarto/presentations/main.html#neuralpbc-hybrid-system",
    "href": "dissertation-main/Slides/quarto/presentations/main.html#neuralpbc-hybrid-system",
    "title": "main",
    "section": "NeuralPbc: Hybrid System",
    "text": "NeuralPbc: Hybrid System\n\n\n\n\n\n\nPassive Smooth System\n\n\nH(x(t1))â‰¤H(x(t0))+âˆ«t0t1s(u(t),y(t))dt\nH\\left(  x(t_1) \\right) \\leq  H\\left(  x(t_0) \\right) + \\int_{t_0}^{t_1} s(u(t), y(t)) \\, \\text{d}t\n\n\n\n\n\nÂ \n\n\n\n\nPassive Hybrid System\n\n\nH(x(t1))â‰¤H(x(t0))+âˆ«t0t1s(u(t),y(t))dtH(x+)â‰¤H(xâˆ’)\\begin{gather*}\nH\\left(  x(t_1) \\right) \\leq  H\\left(  x(t_0) \\right) + \\int_{t_0}^{t_1} s(u(t), y(t)) \\, \\text{d}t \\\\\nH(x^+) \\leq H(x^-)\n\\end{gather*}\n\n\n\n\n\n\n\n\n\nNeuralPbc for contact-rich system\n\n\nminimizeÎ¸J(Ï•,uÎ¸)=ğ”¼x0âˆˆğ’ŸN[â„“(Ï•(x0,u,T),u)],subject toM(q)â…†qÌ‡+h(q,qÌ‡,Î¸)â…†tâˆ’â…†R=0,uÎ¸=Î©â€ (âˆ‡qHâˆ’âˆ‡qHd).\\begin{aligned}\n    \\underset{\\theta}{\\textrm{minimize}} \n    & & J(\\phi, u^\\theta) &= \\mathbb{E}_{x_0 \\in \\mathcal{D}_N}[ \\ell( \\phi(x_0, u, T), u) ], \\\\%\n    \\textrm{subject to}\n    & & M(q) &\\dd \\dot{q} + h(q, \\dot{q}, \\theta)\\dd t - \\dd R  = 0,\\\\%\n    & & u^{\\theta} &= \\Omega^{\\dagger}(\\nabla_q H  - \\nabla_q H_d).%\n\\end{aligned}"
  },
  {
    "objectID": "dissertation-main/Slides/quarto/presentations/main.html#bayesian-neuralpbc-hybrid-system",
    "href": "dissertation-main/Slides/quarto/presentations/main.html#bayesian-neuralpbc-hybrid-system",
    "title": "main",
    "section": "Bayesian NeuralPbc: Hybrid System",
    "text": "Bayesian NeuralPbc: Hybrid System\n\n\n\nNeuralPbc for contact-rich system\n\n\nminimizezJ(Ï•,u)=ğ”¼x0âˆˆğ’ŸN[â„“(Ï•(x0,uÎ¸,T),uÎ¸)],subject toM(q)â…†qÌ‡+h(q,qÌ‡,Î¸)â…†tâˆ’â…†R=0,uÎ¸=Î©â€ (âˆ‡qHâˆ’âˆ‡qHdÎ¸),psâˆ¼ğ•Œ(pmin,pmax),Î¸âˆ¼Q(Î¸;z).\\begin{aligned}\n    \\underset{z}{\\textrm{minimize}} \n    & & & J(\\phi, u) = \\mathbb{E}_{x_0 \\in \\mathcal{D}_N}[\\ell(\\phi(x_0, u^\\theta, T), u^\\theta)], \\\\\n    \\textrm{subject to}\n    & & M(q) &\\dd \\dot{q} + h(q, \\dot{q}, \\theta)\\dd t - \\dd R  = 0,\\\\\n    & & u^{\\theta} &= \\Omega^{\\dagger}(\\nabla_q H  - \\nabla_q H_d^\\theta), \\\\\n    & & p_s &\\sim \\mathbb{U}(p_{min}, p_{max}), \\\\\n    & & \\theta &\\sim Q(\\theta; z).\n\\end{aligned}"
  },
  {
    "objectID": "dissertation-main/Slides/quarto/presentations/main.html#deterministic-vs.-bayesian",
    "href": "dissertation-main/Slides/quarto/presentations/main.html#deterministic-vs.-bayesian",
    "title": "main",
    "section": "Deterministic vs.Â Bayesian",
    "text": "Deterministic vs.Â Bayesian\n\n\n\n\n\n\n\n\n\n\n\nSubtracting rings from the wheel\n\ndecreases wheel mass\ndecreases wheel and pendulum inertia\nmoves the center of mass"
  },
  {
    "objectID": "dissertation-main/Slides/quarto/presentations/main.html#rimless-wheel",
    "href": "dissertation-main/Slides/quarto/presentations/main.html#rimless-wheel",
    "title": "main",
    "section": "Rimless Wheel",
    "text": "Rimless Wheel\n\n\nPerformance objective: achieve hip speed xÌ‡c*=1\\dot{x}_c^* = 1m/s JT=âˆ‘t=0Tâˆ¥xÌ‡c*âˆ’xÌ‡c(t;Î¸)âˆ¥\\begin{align*}\n  J_T = \\sum_{t=0}^{T} \\| \\dot{x}_c^* - \\dot{x}_c(t; \\theta) \\|\n\\end{align*}\nUncertainty in elevation under each spoke psâˆ¼ğ•Œ(0cm,2cm)\np_s \\sim \\mathbb{U}(0 \\textrm{cm}, 2\\textrm{cm})"
  },
  {
    "objectID": "dissertation-main/Slides/quarto/presentations/main.html#deterministic-vs-bayesian",
    "href": "dissertation-main/Slides/quarto/presentations/main.html#deterministic-vs-bayesian",
    "title": "main",
    "section": "Deterministic vs Bayesian",
    "text": "Deterministic vs Bayesian\n\n\n\n\n\n\n\n\npsâˆ¼ğ•Œ(0,pmax)pmax=[0,0.5,1,1.5,2]cmJT=âˆ‘t=0Tâˆ¥xÌ‡c*âˆ’xÌ‡c(t;Î¸)âˆ¥\\begin{align*}\np_s &\\sim \\mathbb{U}(0, p_{max})  \\\\\np_{max} &= [0, 0.5, 1, 1.5, 2] \\textrm{cm} \\\\\nJ_T &= \\sum_{t=0}^{T} \\| \\dot{x}_c^* - \\dot{x}_c(t; \\theta) \\|\n\\end{align*}"
  },
  {
    "objectID": "dissertation-main/Slides/quarto/presentations/main.html#conclusions-1",
    "href": "dissertation-main/Slides/quarto/presentations/main.html#conclusions-1",
    "title": "main",
    "section": "Conclusions",
    "text": "Conclusions\n\n\n\nMOE controller: multi-modal controller for multi-modal dynamics\nNeuralPbc + Bayesian inference = robust controller with stability properties\nFuture work\n\nmanipulation tasks\nmulti-modal controller in uncertain environment"
  },
  {
    "objectID": "dissertation-main/Slides/quarto/presentations/main.html#acknowledgments",
    "href": "dissertation-main/Slides/quarto/presentations/main.html#acknowledgments",
    "title": "main",
    "section": "Acknowledgments",
    "text": "Acknowledgments"
  },
  {
    "objectID": "dissertation-main/Slides/quarto/presentations/appendix_main.html#robust-control-of-contact-rich-robots-via-neural-bayesian-inference",
    "href": "dissertation-main/Slides/quarto/presentations/appendix_main.html#robust-control-of-contact-rich-robots-via-neural-bayesian-inference",
    "title": "main",
    "section": "Robust Control of Contact-Rich Robots via Neural Bayesian Inference",
    "text": "Robust Control of Contact-Rich Robots via Neural Bayesian Inference\n\n\nDoctoral Dissertation Defense\n\n\n\n\nCandidate:  Nardos AshenafiğŸ“  Electrical and Computer Engineering Department  Boise State University, Boise, Idaho, USA\n\n\nSupervisory Committee:  Aykut Satici, Ph.D.Â  John Chiasson, Ph.D.Â  Kurtis Cantley, Ph.D.Â  Hao Chen, Ph.D.Â  Arash Komaee, Ph.D."
  },
  {
    "objectID": "dissertation-main/Slides/quarto/presentations/appendix_main.html#publications-and-contributions",
    "href": "dissertation-main/Slides/quarto/presentations/appendix_main.html#publications-and-contributions",
    "title": "main",
    "section": "Publications and Contributions",
    "text": "Publications and Contributions\n\n\n\n\nPublished\n\nCCTA 2021: Cooperative Manipulation\nACC 2022: Bayesian NeuralPbc\nL-CSS 2022: Bayesian NeuralPbc\n\nCDC 2022\n\nArxiv 2022: Control Design via Bayesian Inference: Theoretical Justification of Robustness \n\n\n\n\n\nUpcoming Submissions\n\nTACON 2023: Control of Hybrid Dynamical Systems via Deep-net Mixture of Experts\nIJRR 2023: Data Driven Passivity-Based Control of the Rimless Wheel on Uneven Terrain"
  },
  {
    "objectID": "dissertation-main/Slides/quarto/presentations/appendix_main.html#contact-modeling",
    "href": "dissertation-main/Slides/quarto/presentations/appendix_main.html#contact-modeling",
    "title": "main",
    "section": "Contact Modeling",
    "text": "Contact Modeling\n\nObjective: accurately model contacts, impacts and Coulomb friction.\nE.g. Model of bouncing ball\n\n\n\n\n\ngN=ygÌ‡N=[01]âŸWN[xÌ‡yÌ‡]=:Î³N\\begin{align*}\n  g_N &= y \\\\\n  \\dot{g}_N &= \\underbrace{\\begin{bmatrix} 0 & 1 \\end{bmatrix}}_{W_N} \\begin{bmatrix}\n  \\dot{x} \\\\ \\dot{y}\n  \\end{bmatrix} =: \\gamma_N\n\\end{align*}\n\n\nÎ³N+=âˆ’ÏµNÎ³Nâˆ’\n\\gamma_N^+ = -\\epsilon_N \\gamma_N^-\n\n\n\n\nComplementarity Condition 0â‰¤Î¾NâŠ¥Î»Nâ‰¥0\n0 \\leq \\xi_N \\perp \\lambda_N \\geq 0"
  },
  {
    "objectID": "dissertation-main/Slides/quarto/presentations/appendix_main.html#moreaus-time-stepping",
    "href": "dissertation-main/Slides/quarto/presentations/appendix_main.html#moreaus-time-stepping",
    "title": "main",
    "section": "Moreauâ€™s Time-Stepping",
    "text": "Moreauâ€™s Time-Stepping\n\n\nCheck if gNâ‰¤0g_N \\leq 0 at t+Î”t2t + \\frac{\\Delta t}{2}\nSolve complementarity\n\n\n\n\n[m00m](qÌ‡+âˆ’qÌ‡âˆ’)âˆ’WNÎ»Nâˆ’[0mg]Î”t=0\\begin{align*}\n  \\begin{bmatrix}\n    m & 0 \\\\\n    0 & m\n  \\end{bmatrix} &(\\dot{q}^+ - \\dot{q}^-) - W_N \\lambda_N - \\begin{bmatrix}\n  0 \\\\ mg\n  \\end{bmatrix} \\Delta t = 0 \n\\end{align*}\n\n\nqÌ‡+=[m00m]âˆ’1[WNÎ»N+[0mg]Î”t]+qÌ‡âˆ’\\begin{align*}\n  \\dot{q}^+ &= \\begin{bmatrix}\n    m & 0 \\\\\n    0 & m\n  \\end{bmatrix}^{-1} \\left[W_N \\lambda_N + \\begin{bmatrix}\n  0 \\\\ mg\n  \\end{bmatrix} \\Delta t \\right] + \\dot{q}^- \n\\end{align*}\n\n\n\n\nÎ¾N=WNqÌ‡++ÏµNWNqÌ‡âˆ’\\begin{align*}\n  \\xi_N = W_N\\dot{q}^+ + \\epsilon_N W_N \\dot{q}^- \n\\end{align*}\n\n\nÎ¾N=WN[m00m]âˆ’1[WNÎ»N+[0mg]Î”t]+(1+ÏµN)WNqÌ‡âˆ’\\begin{align*}\n  \\xi_N = W_N\\begin{bmatrix}\n    m & 0 \\\\\n    0 & m\n  \\end{bmatrix}^{-1} \\left[W_N \\lambda_N + \\begin{bmatrix}\n  0 \\\\ mg\n  \\end{bmatrix} \\Delta t \\right] + (1 + \\epsilon_N) W_N \\dot{q}^-\n\\end{align*}\n\n\n\nComplementarity condition Î¾NÎ»N=0,Î¾Nâ‰¥0,Î»Nâ‰¥0\\begin{align*}\n    \\xi_N \\lambda_N = 0, \\;  \n    \\xi_N \\geq 0, \\lambda_N \\geq 0\n  \\end{align*}\n\n\n\nFor non-convex optimization, use Lemkeâ€™s algorithm"
  },
  {
    "objectID": "dissertation-main/Slides/quarto/presentations/appendix_main.html#complementarity-formulation",
    "href": "dissertation-main/Slides/quarto/presentations/appendix_main.html#complementarity-formulation",
    "title": "main",
    "section": "Complementarity Formulation",
    "text": "Complementarity Formulation\n\nFor potential contacts with gaps gNâ‰¤0g_N \\leq 0, the following holds.\n\n0â‰¤Î¾N(q,qÌ‡)âŠ¥Î»Nâ‰¥0,Î¾N(q,qÌ‡):=Î³N++ÏµNÎ³Nâˆ’,\\begin{align*}\n  \\begin{gathered}\n    0 \\leq \n      \\xi_N(q, \\dot{q}) \n    \\perp\n        \\lambda_N  \\geq 0, \\\\\n      \\xi_N(q, \\dot{q})  :=\n        \\gamma_N^+ + \\epsilon_N \\gamma_N^- ,\n  \\end{gathered}\n\\end{align*}"
  },
  {
    "objectID": "dissertation-main/Slides/quarto/presentations/appendix_main.html#linear-complementarity-problem-lcp",
    "href": "dissertation-main/Slides/quarto/presentations/appendix_main.html#linear-complementarity-problem-lcp",
    "title": "main",
    "section": "Linear Complementarity Problem (LCP)",
    "text": "Linear Complementarity Problem (LCP)\n\n\nObjective: pose the complementarity formulation as quadratic function over the contact forces\nDefine Î»R:=Î¼Î»N+Î»T,Î»L:=Î¼Î»Nâˆ’Î»T,\\begin{align*}\n\\lambda_R := \\mu \\lambda_N + \\lambda_T, \\\\\n\\lambda_L := \\mu \\lambda_N - \\lambda_T, \n\\end{align*}\nCorresponding complementarity is defined 0â‰¤(Î¾R(q,qÌ‡)Î¾L(q,qÌ‡))âŠ¥(Î»RÎ»L)â‰¥0,\\begin{equation*}\n\\begin{gathered}\n  0 \\leq \n  \\begin{pmatrix}\n    \\xi_R(q, \\dot{q}) \\\\\n    \\xi_L(q, \\dot{q})\n  \\end{pmatrix} \n  \\perp\n    \\begin{pmatrix}\n      \\lambda_R  \\\\\n      \\lambda_L\n    \\end{pmatrix} \\geq 0,\n  \\end{gathered}\n\\end{equation*}\nThese definitions help express Î¾N,Î¾R,Î¾L\\xi_N, \\xi_R, \\xi_L as affine functions of Î»N,Î»R,Î»L\\lambda_N, \\lambda_R, \\lambda_L\n\n(Î¾NÎ¾RÎ»L)=A(Î»NÎ»RÎ¾L)+b,\\begin{align*}\n  \\begin{pmatrix}\n    \\xi_N \\\\\n    \\xi_R \\\\\n    \\lambda_L\n  \\end{pmatrix} =\n      A\n    \\begin{pmatrix}\n      \\lambda_N \\\\\n      \\lambda_R \\\\\n      \\xi_L\n    \\end{pmatrix} + b, \n\\end{align*}"
  },
  {
    "objectID": "dissertation-main/Slides/quarto/presentations/appendix_main.html#lcp",
    "href": "dissertation-main/Slides/quarto/presentations/appendix_main.html#lcp",
    "title": "main",
    "section": "LCP",
    "text": "LCP\n\nWe substitute the affine functions into the complementarity formulation\n\n\n\n0â‰¤(Î¾N(q,qÌ‡)Î¾R(q,qÌ‡)Î¾L(q,qÌ‡))âŠ¥(Î»NÎ»RÎ»L)â‰¥0,\\begin{equation*}\n  \\begin{gathered}\n    0 \\leq \n    \\begin{pmatrix}\n      \\xi_N(q, \\dot{q}) \\\\\n      \\xi_R(q, \\dot{q}) \\\\\n      \\xi_L(q, \\dot{q})\n    \\end{pmatrix} \n    \\perp\n      \\begin{pmatrix}\n        \\lambda_N  \\\\\n        \\lambda_R  \\\\\n        \\lambda_L\n      \\end{pmatrix} \\geq 0,\n    \\end{gathered}\n\\end{equation*}\n\n\n0â‰¤[A(Î»NÎ»RÎ¾L)+b]âŠ¥(Î»NÎ»RÎ¾L)â‰¥0\\begin{align*}\n    0 \\leq \n    \\left[ A \\begin{pmatrix}\n      \\lambda_N \\\\\n      \\lambda_R \\\\\n      \\xi_L\n    \\end{pmatrix} + b \\right]\n    \\perp\n    \\begin{pmatrix}\n      \\lambda_N \\\\\n      \\lambda_R \\\\\n      \\xi_L\n    \\end{pmatrix} \\geq 0\n\\end{align*}\n\n\n\n\nThe LCP can be posed as a feasibility problem and solved for Î»N,Î»R,Î¾L\\lambda_N, \\lambda_R, \\xi_L\nIn the presence of friction, the LCP is a non-convex optimization problem\nWe use pivotting (basis-exchange) technique called Lemkeâ€™s algorithm to solve the LCP"
  },
  {
    "objectID": "dissertation-main/Slides/quarto/presentations/appendix_main.html#generalization-of-the-log-likelihood",
    "href": "dissertation-main/Slides/quarto/presentations/appendix_main.html#generalization-of-the-log-likelihood",
    "title": "main",
    "section": "Generalization of the log likelihood",
    "text": "Generalization of the log likelihood\n\nThe experts can take many forms. The likelihood can be generalized as\n\n\n\nln{P(ğ”»|Î¸,Ïˆ)}=âˆ‘j=1Nlnâˆ‘i=1NFğ’©(âˆ¥Fi(xj;Î¸i)âˆ’yjâˆ¥|0,s)Pi(xj,Ïˆ),\n  \\ln \\{P(\\mathbb{D} | \\theta, \\psi) \\} = \\sum_{j=1}^{N} \\ln \\sum_{i=1}^{N_F} \\mathcal{N} ( \\| F_i(x_j; \\theta_i) - y_j \\| \\; | \\; 0, s)  P_i(x_j, \\psi),\n\n\n\nln{P(ğ”»|Î¸,Ïˆ)}=âˆ‘j=1Nlnâˆ‘i=1NF12Ï€s2exp(âˆ’12âˆ¥Fi(xj;Î¸i)âˆ’yjâˆ¥2s2)Pi(xj,Ïˆ),\n  \\ln \\{P(\\mathbb{D} | \\theta, \\psi) \\} = \\sum_{j=1}^{N} \\ln \\sum_{i=1}^{N_F} \\frac{1}{\\sqrt{2 \\pi s^2}} \\exp \\left( -\\frac{1}{2}\\frac{ \\|F_i(x_j; \\theta_i) - y_j \\|^2}{s^2} \\right) P_i(x_j, \\psi),\n\n\n\n\n\nFor gradient-based techniques, we can extract the relevant parts and simplify the likelihood ln{P(ğ”»|Î¸,Ïˆ)}âˆğ•ƒ(ğ”»|Î¸,Ïˆ)=âˆ‘j=1Nâˆ‘i=1NFâˆ’âˆ¥Fi(xj;Î¸i)âˆ’yjâˆ¥2Pi(xj|Ïˆ).\n\\ln \\{P(\\mathbb{D} | \\theta, \\psi) \\} \\propto \\mathbb{L}(\\mathbb{D} | \\theta, \\psi) = \\sum_{j=1}^{N} \\sum_{i=1}^{N_F} - \\| F_i(x_j; \\theta_i) - y_j \\|^2 P_i(x_j | \\psi). \n\n\n\n\n\n\n\nLikelihood\n\n\nğ•ƒ(ğ”»|Î¸,Ïˆ)=âˆ‘j=1Nâˆ‘i=1NFâˆ’âˆ¥Fi(xj;Î¸i)âˆ’yjâˆ¥2Pi(xj|Ïˆ).\n\\mathbb{L}(\\mathbb{D} | \\theta, \\psi) = \\sum_{j=1}^{N} \\sum_{i=1}^{N_F} - \\| F_i(x_j; \\theta_i) - y_j \\|^2 P_i(x_j | \\psi)."
  },
  {
    "objectID": "dissertation-main/Slides/quarto/presentations/appendix_main.html#performance-objective",
    "href": "dissertation-main/Slides/quarto/presentations/appendix_main.html#performance-objective",
    "title": "main",
    "section": "Performance Objective",
    "text": "Performance Objective\n\n\n\n\nMinimum Trajectory Loss (MTL):\n\n\nAccumulated loss may not reflect desired behavior. E.g. Simple pendulum\n\n\n\nSimple pendulum needs to pump slowly, which would accumulate large cost\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMTL encourages trajectories to eventually lead to a minimum cost\n\ntmin=inft{â„“(x(t),u):x(t)âˆˆÏ•(x0,u,T)}ğ•ƒ(Ï•)=âˆ’â„“(x(tmin),u)Câˆ‘t=0tminPi(x(t)|Ïˆ)\\begin{align*}\n    \\begin{gathered}\n        t_{min} = \\underset{t}{\\textrm{inf}} \\; \\{ \\ell(x(t), u): x(t) \\in \\phi(x_0, u, T) \\}  \\\\\n        \\mathbb{L}(\\phi) = - \\frac{\\ell(x(t_{min}), u)}{C} \\sum_{t=0}^{t_{min}}P_i(x(t) | \\psi) \n    \\end{gathered} \n\\end{align*}"
  },
  {
    "objectID": "dissertation-main/Slides/quarto/presentations/appendix_main.html#stable-switching",
    "href": "dissertation-main/Slides/quarto/presentations/appendix_main.html#stable-switching",
    "title": "main",
    "section": "Stable Switching",
    "text": "Stable Switching\n\nGiven two unstable closed-loop systems\n\n\n\nxÌ‡=A1x=[0âˆ’120]x,xÌ‡=A2x=[0âˆ’210]x,\\begin{align*}\n    \\dot{x} = A_1x = \\begin{bmatrix} 0 & -1 \\\\ 2 & 0 \\end{bmatrix} x, \\; \\;\n    \\dot{x} = A_2x = \\begin{bmatrix} 0 & -2 \\\\ 1 & 0 \\end{bmatrix} x,\n\\end{align*} find stable switching system that converges to x*=(0,0)x^*=(0, 0)\n\n\nMaximum number of state partitions set to 4\n\n\n\n\n\n\n\n\n\n\nThe gating network ğ(x|Ïˆ)\\mathbf{P}(x | \\psi) is a fully-connected neural net with 4 outputs\nThere are 4 experts with parameters Î¸i\\theta_i Fi(Î¸i)={0,Î¸i>12,1,Î¸iâ‰¤12,\\begin{align*}\n  F_i(\\theta_i) = \\begin{cases}\n     0, & \\theta_i > \\frac{1}{2}, \\\\\n     1, & \\theta_i \\leq \\frac{1}{2},\n  \\end{cases}\n\\end{align*}\nObjective: learn (Ïˆ,Î¸)(\\psi, \\theta) that minimize the accumulated loss"
  },
  {
    "objectID": "dissertation-main/Slides/quarto/presentations/appendix_main.html#training-progress",
    "href": "dissertation-main/Slides/quarto/presentations/appendix_main.html#training-progress",
    "title": "main",
    "section": "Training progress",
    "text": "Training progress\n\n\n\n\n\nÂ  Control input (purple â†’xÌ‡=A1x\\rightarrow \\dot{x} = A_1x, yellow â†’xÌ‡=A2x\\rightarrow \\dot{x} = A_2 x) Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  State partition\n\n\n\n\n\n\n\nÂ  Control input (purple â†’xÌ‡=A1x\\rightarrow \\dot{x} = A_1x, yellow â†’xÌ‡=A2x\\rightarrow \\dot{x} = A_2 x) Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  State partition\n\n\n\n\n\n\n\nÂ  Control input (purple â†’xÌ‡=A1x\\rightarrow \\dot{x} = A_1x, yellow â†’xÌ‡=A2x\\rightarrow \\dot{x} = A_2 x) Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  State partition\n\n\n\n\n\n\n\nÂ  Control input (purple â†’xÌ‡=A1x\\rightarrow \\dot{x} = A_1x, yellow â†’xÌ‡=A2x\\rightarrow \\dot{x} = A_2 x) Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  State partition"
  },
  {
    "objectID": "dissertation-main/Slides/quarto/presentations/appendix_main.html#passive-system-example",
    "href": "dissertation-main/Slides/quarto/presentations/appendix_main.html#passive-system-example",
    "title": "main",
    "section": "Passive System Example",
    "text": "Passive System Example\n\n\n\n\n\n\nKirchoffâ€™s law\nv=Ri+1Câˆ«0ti(Ï„)dÏ„+Ldidtviâˆ’Ri2=ddt(12C(âˆ«0ti(Ï„)dÏ„)2âŸğ’±+12Li2âŸğ’¯)\n\\begin{aligned}\nv &= Ri + \\frac{1}{C} \\int_{0}^{t} i(\\tau) \\, \\text{d}\\tau + L \\frac{\\text{d} i}{\\text{d} t} \\\\\nvi - Ri^2 &= \\frac{\\text{d}}{\\text{d} t} \\left( \n  \\underbrace{\\frac{1}{2C} \\left( \\int_{0}^{t} i(\\tau)\\, \\text{d} \\tau \\right)^2}_{\\mathcal{V}} + \n  \\underbrace{\\frac{1}{2} Li^2}_{\\mathcal{T}}  \n\\right)\n\\end{aligned}\n\n\n\nLet H=ğ’±+ğ’¯H = \\mathcal{V} + \\mathcal{T}, integrate to obtain\nH(t)âŸavailableâˆ’H(0)âŸinitial=âˆ«0tv(Ï„)i(Ï„)dÏ„âŸsuppliedâˆ’âˆ«0tRi2(Ï„)dÏ„âŸdissipated<âˆ«0tv(Ï„)i(Ï„)dÏ„\n\\underbrace{H(t)}_{\\textrm{available}} -\n\\underbrace{H(0)}_{\\textrm{initial}} \n= \n\\underbrace{\\int_{0}^{t} v(\\tau)i(\\tau)\\, \\text{d} \\tau}_{\\textrm{supplied}} - \n\\underbrace{\\int_{0}^{t} Ri^2(\\tau)\\, \\text{d} \\tau}_{\\textrm{dissipated}}\n<\n\\int_{0}^{t} v(\\tau) i(\\tau) \\, \\text{d} \\tau"
  },
  {
    "objectID": "dissertation-main/Slides/quarto/presentations/appendix_main.html#uncertainty-in-predictions",
    "href": "dissertation-main/Slides/quarto/presentations/appendix_main.html#uncertainty-in-predictions",
    "title": "main",
    "section": "Uncertainty in Predictions",
    "text": "Uncertainty in Predictions\n\nThe uncertainty associated with each prediction is given by\n\n\n\n\nUncertainty in predictions\n\n\nÎ£Fâˆ£x,ğ”»=1NÎ¸âˆ’1âˆ‘Î¸âˆ¼P(Î¸;z)âˆ¥F(x;Î¸)âˆ’FÌ‚(x)âˆ¥2.\\begin{align*}\n  \\Sigma_{F \\mid x,\\mathbb{D}} = \\frac{1}{N_{\\theta}-1} \\sum_{\\theta \\sim P(\\theta;z)} \\| F(x; \\theta) - \\hat{F}(x)\\| ^2.\n\\end{align*} where FÌ‚(x)\\hat{F}(x) is the marginalized prediction given by FÌ‚(x)=1NÎ¸âˆ‘Î¸âˆ¼P(Î¸;z)F(x;Î¸),\\begin{align*}\n  \\hat{F}(x) = \\frac{1}{N_{\\theta}} \\sum_{\\theta \\sim P(\\theta;z)} F(x; \\theta),\n\\end{align*}"
  },
  {
    "objectID": "dissertation-main/Slides/quarto/presentations/appendix_main.html#training-stochastic-models",
    "href": "dissertation-main/Slides/quarto/presentations/appendix_main.html#training-stochastic-models",
    "title": "main",
    "section": "Training Stochastic Models",
    "text": "Training Stochastic Models\n\n\n\n\n\n\n\n\nExpectation Maximization\n\n\nmaximizeP(Î¸|ğ”»)P(ğ”»|Î¸)=âˆj=1Nğ’©(âˆ¥F(xj;Î¸)âˆ’yjâˆ¥|0,s),subject toÎ¸âˆ¼P(Î¸|ğ”»),ğ”»={(x1,y1),â€¦,(xN,yN)}.\n\\begin{aligned}\n\\underset{P(\\theta | \\mathbb{D})}{\\text{maximize}} && P(\\mathbb{D} | \\theta)  &= \\prod_{j=1}^{N} \\mathcal{N}(\\| F(x_j; \\theta) -  y_j \\| \\; | \\; 0, s), \\\\\n\\text{subject to} &&\n& \\theta \\sim P(\\theta | \\mathbb{D}), \\\\\n&& \\mathbb{D} &= \\{(x_1, y_1), \\dots, (x_N, y_N) \\}.\n\\end{aligned}\n\n\n\n\n\n\n\n\n\n\n\nExpectation Maximization\n\n\nmaximizeP(Î¸|ğ”»)P(ğ”»|Î¸)=âˆj=1N12Ï€s2exp(âˆ’12s2âˆ¥F(xj;Î¸)âˆ’yjâˆ¥2),subject toÎ¸âˆ¼P(Î¸|ğ”»),ğ”»={(x1,y1),â€¦,(xN,yN)}.\n\\begin{aligned}\n\\underset{P(\\theta| \\mathbb{D})}{\\text{maximize}} && P(\\mathbb{D} | \\theta)  &= \\prod_{j=1}^{N} \\frac{1}{\\sqrt{2 \\pi s^2}}\\exp(-\\frac{1}{2s^2}\\| F(x_j; \\theta) -  y_j \\|^2), \\\\\n\\text{subject to} &&\n& \\theta \\sim P(\\theta| \\mathbb{D}), \\\\\n&& \\mathbb{D} &= \\{(x_1, y_1), \\dots, (x_N, y_N) \\}.\n\\end{aligned}\n\n\n\n\n\n\n\n\n\n\n\nExpectation Maximization\n\n\nmaximizezP(ğ”»|Î¸)=âˆj=1N12Ï€s2exp(âˆ’12s2âˆ¥F(xj;Î¸)âˆ’yjâˆ¥2),subject toÎ¸âˆ¼Q(Î¸;z),ğ”»={(x1,y1),â€¦,(xN,yN)}.\n\\begin{aligned}\n\\underset{z}{\\text{maximize}} && P(\\mathbb{D} | \\theta)  &= \\prod_{j=1}^{N} \\frac{1}{\\sqrt{2 \\pi s^2}}\\exp(-\\frac{1}{2s^2}\\| F(x_j; \\theta) -  y_j \\|^2), \\\\\n\\text{subject to} &&\n& \\theta \\sim Q(\\theta;z), \\\\\n&& \\mathbb{D} &= \\{(x_1, y_1), \\dots, (x_N, y_N) \\}.\n\\end{aligned}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExpectation maximization is prone to overfitting\n\nReduces accuracy of predictions\nReports near-zero prediction uncertainty (overconfident)\n\nSolution: enforce variance on the posterior"
  },
  {
    "objectID": "dissertation-main/Slides/quarto/presentations/appendix_main.html#bias-variance-trade-off",
    "href": "dissertation-main/Slides/quarto/presentations/appendix_main.html#bias-variance-trade-off",
    "title": "main",
    "section": "Bias-Variance Trade-Off",
    "text": "Bias-Variance Trade-Off\n\n\nPrior distribution plays the role of a regularization term\n\n\n\n\n\nBayesian Inference\n\n\nmaximizezP(ğ”»|Î¸)P(Î¸),subject toÎ¸âˆ¼Q(Î¸;z),ğ”»={(x1,y1),â€¦,(xN,yN)}.\n\\begin{aligned}\n\\underset{z}{\\text{maximize}} &&& P(\\mathbb{D} | \\theta) P(\\theta), \\\\\n\\text{subject to} &&\n& \\theta \\sim Q(\\theta;z), \\\\\n&& \\mathbb{D} &= \\{(x_1, y_1), \\dots, (x_N, y_N) \\}.\n\\end{aligned}\n\n\n\n\n\n\n\n\n\nPrior distribution can be\n\nInformed: allows us to inject prior knowledge\nUninformed: starts randomly but every so often gets updated by the posterior"
  },
  {
    "objectID": "dissertation-main/Slides/quarto/presentations/appendix_main.html#bias-variance-trade-off-1",
    "href": "dissertation-main/Slides/quarto/presentations/appendix_main.html#bias-variance-trade-off-1",
    "title": "main",
    "section": "Bias-Variance Trade-Off",
    "text": "Bias-Variance Trade-Off\n\n\nPrior distribution plays the role of a regularization term\n\n\n\n\n\n\nBayesian Inference\n\n\nmaximizeP(Î¸|ğ”»)P(ğ”»|Î¸)P(Î¸),subject toÎ¸âˆ¼P(Î¸|ğ”»),ğ”»={(x1,y1),â€¦,(xN,yN)}.\n\\begin{aligned}\n\\underset{P(\\theta | \\mathbb{D})}{\\text{maximize}} &&& P(\\mathbb{D} | \\theta) P(\\theta), \\\\\n\\text{subject to} &&\n& \\theta \\sim P(\\theta | \\mathbb{D}), \\\\\n&& \\mathbb{D} &= \\{(x_1, y_1), \\dots, (x_N, y_N) \\}.\n\\end{aligned}\n\n\n\n\n\n\n\n\n\n\n\nRegularization via Prior Distribution\n\n\nP(ğ”»|Î¸)P(Î¸)=âˆj=1Nğ’©(âˆ¥F(xj;Î¸)âˆ’yjâˆ¥|0,s1)ğ’©(âˆ¥Î¸âˆ’Î¸0âˆ¥|0,s2)\nP(\\mathbb{D} | \\theta) P(\\theta) =  \\prod_{j=1}^{N} \\mathcal{N}(\\| F(x_j; \\theta) -  y_j \\| \\; | \\; 0, s_1) \\mathcal{N}(\\| \\theta - \\theta_0 \\| \\; | \\; 0, s_2)\n P(ğ”»|Î¸)P(Î¸)=âˆj=1N12Ï€s1s2exp(âˆ’12s12âˆ¥F(xj;Î¸)âˆ’yjâˆ¥2)exp(âˆ’12s22âˆ¥Î¸âˆ’Î¸0âˆ¥2)\nP(\\mathbb{D} | \\theta) P(\\theta) =  \\prod_{j=1}^{N} \\frac{1}{2 \\pi s_1s_2}\\exp(-\\frac{1}{2s_1^2}\\| F(x_j; \\theta) -  y_j \\|^2)\\exp(-\\frac{1}{2s_2^2}\\| \\theta - \\theta_0 \\|^2)\n lnP(ğ”»|Î¸)P(Î¸)=lnN2Ï€s1s2+âˆ‘j=1Nâˆ’12s12âˆ¥F(xj;Î¸)âˆ’yjâˆ¥2âˆ’12s22âˆ¥Î¸âˆ’Î¸0âˆ¥2\n\\ln P(\\mathbb{D} | \\theta) P(\\theta) = \\ln{\\frac{N}{2 \\pi s_1s_2}} + \\sum_{j=1}^{N} -\\frac{1}{2s_1^2}\\| F(x_j; \\theta) -  y_j \\|^2 - \\frac{1}{2s_2^2}\\| \\theta - \\theta_0 \\|^2\n\n\n\n\n\n\n\n\n\n\n\nBayesian Inference\n\n\nmaximizeP(Î¸|ğ”»)P(ğ”»|Î¸)P(Î¸),subject toÎ¸âˆ¼P(Î¸|ğ”»),ğ”»={(x1,y1),â€¦,(xN,yN)}.\n\\begin{aligned}\n\\underset{P(\\theta | \\mathbb{D})}{\\text{maximize}} &&& P(\\mathbb{D} | \\theta) P(\\theta), \\\\\n\\text{subject to} &&\n& \\theta \\sim P(\\theta | \\mathbb{D}), \\\\\n&& \\mathbb{D} &= \\{(x_1, y_1), \\dots, (x_N, y_N) \\}.\n\\end{aligned}\n\n\n\n\n\n\n\n\n\n\n\nPrior distribution can be\n\nInformed: allows us to inject prior knowledge\nUninformed: starts randomly but every so often gets updated by the posterior"
  },
  {
    "objectID": "dissertation-main/Slides/quarto/presentations/appendix_main.html#estimating-posterior-distribution",
    "href": "dissertation-main/Slides/quarto/presentations/appendix_main.html#estimating-posterior-distribution",
    "title": "main",
    "section": "Estimating Posterior Distribution",
    "text": "Estimating Posterior Distribution\n\n\n\n\nBayesian Inference\n\n\nmaximizezP(ğ”»|Î¸)P(Î¸),subject toÎ¸âˆ¼Q(Î¸;z),ğ”»={(x1,y1),â€¦,(xN,yN)}.\n\\begin{aligned}\n\\underset{z}{\\text{maximize}} &&& P(\\mathbb{D} | \\theta) P(\\theta), \\\\\n\\text{subject to} &&\n& \\theta \\sim Q(\\theta;z), \\\\\n&& \\mathbb{D} &= \\{(x_1, y_1), \\dots, (x_N, y_N) \\}.\n\\end{aligned}\n\n\n\n\n\n\nVariational Inference: approximates the posterior P(Î¸|ğ”»)P(\\theta | \\mathbb{D}) with a pre-selected distribution Q(Î¸;z)Q(\\theta; z)\nObjective: collect NÎ¸N_\\theta samples from the current posterior Q(Î¸;z)Q(\\theta; z) and maximize Elbo â„’(ğ”»,z)=ğ”¼Î¸âˆ¼Q[ln(P(ğ”»âˆ£Î¸;z)P(Î¸))âˆ’ln(Q(Î¸;z))].\n\\mathcal{L}(\\mathbb{D},z) = \\mathbb{E}_{\\theta \\sim Q} \\left[\\ln(P(\\mathbb{D} \\mid \\theta;z)P(\\theta)) - \\ln(Q(\\theta;z)) \\right]."
  },
  {
    "objectID": "dissertation-main/Slides/quarto/presentations/appendix_main.html#bias-variance-tradeoff",
    "href": "dissertation-main/Slides/quarto/presentations/appendix_main.html#bias-variance-tradeoff",
    "title": "main",
    "section": "Bias-Variance Tradeoff",
    "text": "Bias-Variance Tradeoff\n\n\n\nBias-Variance Tradeoff\n\n\nh(x)=sin(x)ğ’Ÿ=h(x)+Ïµi,Ïµiâˆ¼ğ’©(0,Î´)y=y(x;ğ’Ÿ)ğ”¼ğ’Ÿ[(yâˆ’h)2]=(ğ”¼ğ’Ÿ[yâˆ’h])2âŸbias2+ğ”¼ğ’Ÿ[yâˆ’ğ”¼ğ’Ÿ(y)2]âŸvariance\n\\begin{aligned}\nh(x) &= \\sin(x) \\\\\n\\mathcal{D} &= {h(x)+\\epsilon_i, \\epsilon_i \\sim \\mathcal{N}(0, \\delta)} \\\\\ny &= y(x; \\mathcal{D}) \\\\\n\\mathbb{E}_{\\mathcal{D}}[(y-h)^2] &= {\\underbrace{(\\mathbb{E}_{\\mathcal{D}}[y-h])^2}_{\\text{bias}^2}} + {\\underbrace{\\mathbb{E}_{\\mathcal{D}}[y - \\mathbb{E}_{\\mathcal{D}}(y)^2]}_{\\text{variance}}}\n\\end{aligned}\n\n\n\n\n\nFinding deterministic solution under noise has low bias and high variance (overfits)"
  },
  {
    "objectID": "dissertation-main/Slides/quarto/presentations/appendix_main.html#bayesian-learning",
    "href": "dissertation-main/Slides/quarto/presentations/appendix_main.html#bayesian-learning",
    "title": "main",
    "section": "Bayesian Learning",
    "text": "Bayesian Learning\n\nP(Î¸âˆ£ğ”»)=P(ğ”»âˆ£Î¸)âlikelihoodP(Î¸)âpriorâˆ«Î¸P(ğ”»âˆ£Î¸â€²)P(Î¸â€²)dÎ¸â€²âŸevidenceâ‰ˆQ(Î¸;z)âŸVI.\nP(\\theta \\mid \\mathbb{D}) = \\frac{\\overbrace{P(\\mathbb{D} \\mid\n\\theta)}^{\\text{likelihood}}\\overbrace{P(\\theta)}^{\\text{prior}}}\n{\\underbrace{\\int_\\theta P(\\mathbb{D} \\mid \\theta^\\prime)P(\\theta^\\prime)\nd\\theta^\\prime}_{\\text{evidence}}} \\underbrace{\\approx Q(\\theta;\nz)}_{\\text{VI}}.\n\n\n\n\n\n\n\n\n\n\nKL-divergence and ELBO\n\n\nDKL=ğ”¼Î¸âˆ¼Q[logQ(Î¸;z)P(Î¸âˆ£ğ”»)]=logP(ğ”»)âˆ’ğ”¼Î¸âˆ¼Q[logP(ğ”»âˆ£Î¸)P(Î¸)Q(Î¸;z)]â„’(ğ”»;z)=ğ”¼Î¸âˆ¼Q[logP(ğ”»âˆ£Î¸)P(Î¸)âˆ’logQ(Î¸;z)]\n\\begin{aligned}\nD_{\\text{KL}} &= \\mathbb{E}_{\\theta \\sim Q}\\left[ \\log \\frac{Q(\\theta;\nz)}{P(\\theta \\mid \\mathbb{D})}\\right] \\\\\n&= \\log P(\\mathbb{D}) - \\mathbb{E}_{\\theta \\sim Q}\\left[ \\log\n\\frac{P(\\mathbb{D} \\mid \\theta) P(\\theta)}{Q(\\theta; z)} \\right] \\\\\n\\mathcal{L}(\\mathbb{D}; z) &= \\mathbb{E}_{\\theta \\sim Q}\\left[ \\log\nP(\\mathbb{D} \\mid \\theta) P(\\theta) - \\log Q(\\theta; z) \\right]\n\\end{aligned}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPrediction through marginalization\n\n\nFÌ‚(x)=1Nâˆ‘Î¸âˆ¼QF(x;Î¸).\n\\begin{aligned}\n\\hat{F}(x) &= \\frac{1}{N}\\sum_{\\theta \\sim Q} F(x; \\theta).\n\\end{aligned}"
  },
  {
    "objectID": "dissertation-main/Slides/quarto/presentations/appendix_main.html#training-procedure",
    "href": "dissertation-main/Slides/quarto/presentations/appendix_main.html#training-procedure",
    "title": "main",
    "section": "Training Procedure",
    "text": "Training Procedure\n\n\n\nStart from initial parameters zz\nSample initial states x0âˆˆğ’ŸNx_0 \\in \\mathcal{D}_N\nGenerate trajectories Ï•(x0,u,T)\\phi(x_0, u, T) using current parameters Î¸âˆ¼Q(Î¸;z)uÎ¸=Î©â€ (âˆ‡qHâˆ’âˆ‡qHd)\\begin{gather*}\n\\theta \\sim Q(\\theta; z) \\\\\nu^\\theta = \\Omega^{\\dagger}(\\nabla_q H  - \\nabla_q H_d)\n\\end{gather*}\nAssign a running cost â„“\\ell to the trajectories based on performance J(Ï•,uÎ¸)=ğ”¼x0âˆˆğ’ŸN[â„“(Ï•(x0,u,T),u)]P(J|Î¸)=ğ’©(J|0,s)â„’(J,z)=ln(P(Jâˆ£Î¸)P(Î¸))âˆ’ln(Q(Î¸;z))\\begin{gather*}\nJ(\\phi, u^\\theta) = \\mathbb{E}_{x_0 \\in \\mathcal{D}_N}[ \\ell( \\phi(x_0, u, T), u) ] \\\\\nP(J | \\theta)  = \\mathcal{N}(J | \\; 0, s) \\\\\n\\mathcal{L}(J,z) = \\ln(P(J \\mid \\theta)P(\\theta)) - \\ln(Q(\\theta;z)) \n\\end{gather*}\nUpdate parameters zz to maximize Elbo zâ†z+Î±iâˆ‚â„’âˆ‚z\\begin{align*}\nz \\leftarrow z + \\alpha_i \\frac{\\partial \\mathcal{L}}{\\partial z}\n\\end{align*}"
  },
  {
    "objectID": "dissertation-main/Slides/quarto/presentations/appendix_main.html#neuralidapbc-main-problem",
    "href": "dissertation-main/Slides/quarto/presentations/appendix_main.html#neuralidapbc-main-problem",
    "title": "main",
    "section": "NeuralIdaPbc Main Problem",
    "text": "NeuralIdaPbc Main Problem\n\nminimizeÎ¸J(Î¸)=âˆ¥Î©âŠ¥{âˆ‡qHâˆ’MdÎ¸Mâˆ’1âˆ‡qHdÎ¸+J2Î¸(MdÎ¸)âˆ’1p}âˆ¥2subject toHdÎ¸=12pâŠ¤(MdÎ¸)âˆ’1p+VdÎ¸(q)MdÎ¸(q)=(MdÎ¸(q))âŠ¤â‰»0J2Î¸(q,p)=âˆ’(J2Î¸(q,p))âŠ¤qâ‹†=argminqVdÎ¸(q)\\begin{aligned} \\underset{\\theta}{\\text{minimize}} && J(\\theta) &= \\left\\lVert \\Omega^{\\bot} \\left\\{ \\nabla_{q} H - M_{d}^{\\theta}M^{-1} \\nabla_{q} H_{d}^{\\theta} + J_{2}^{\\theta} \\left(M_{d}^{\\theta}\\right)^{-1} p \\right\\} \\right\\rVert^2  \\\\ \\text{subject to}  && H_d^{\\theta} &= \\frac{1}{2} p^{\\top} \\left( M_{d}^{\\theta} \\right)^{-1} p + V_{d}^{\\theta}(q) \\\\ && M_d^{\\theta}(q) &= \\left(M_d^{\\theta}(q)\\right)^\\top \\succ 0 \\\\ && J_{2}^{\\theta}(q,p) &= -\\left(J_{2}^{\\theta}(q,p)\\right)^\\top \\\\ && q^\\star &= \\underset{q}{\\arg \\min} \\, V_{d}^{\\theta} (q) \\end{aligned}\n\n\n\n\n\n\nNeuralIdaPbc\n\n\n\nSolve nonlinear PDEs using neural networks and SoS polynomials\nSurrogates of MdM_d, J2J_2, VdV_d are constrained by construction\n\n\n\n\n\n\n\n\n\n\nPinn\n\n\n\nSolve nonlinear PDEs using neural networks\nSolution surrogates are constrained via penalty term in loss function"
  },
  {
    "objectID": "dissertation-main/Slides/quarto/presentations/appendix_main.html#optimal-control-under-uncertainty",
    "href": "dissertation-main/Slides/quarto/presentations/appendix_main.html#optimal-control-under-uncertainty",
    "title": "main",
    "section": "Optimal Control under Uncertainty",
    "text": "Optimal Control under Uncertainty\n\n\n\n\n\nOptimal Control for a Linear System\n\n\nÎ£:{xÌ‡=psx+u,u(x)=Î¸x,x(0)=1.\n\\Sigma: \\quad\n\\begin{cases}\n  \\dot{x} &= p_s x + u, \\\\\n  u(x) &= \\theta x, \\\\\n  x(0) &= 1.\n\\end{cases}\n\n\n\n\nx(t)=e(ps+Î¸)t\n  x(t) = e^{(p_s+\\theta)t}\n\n\n\nPerformance Index: ğ’¥=âˆ«0T(12cx(t)2+12ru(t)2)dt\n\\mathcal{J} = \\int_0^T \\left( \\frac{1}{2}cx(t)^2 + \\frac{1}{2}ru(t)^2  \\right)dt\n\n\n\n\n\n\nğ’¥âˆ=âˆ’14c+rÎ¸2ps+Î¸\n\\mathcal{J}_\\infty = -\\frac{1}{4}\\frac{c+r\\theta^2}{p_s+\\theta}\n\n\n\n\nÎ¸â‹†=âˆ’psâˆ’ps2+cr\\theta^\\star = -p_s -\\sqrt{p_s^2+\\frac{c}{r}}"
  },
  {
    "objectID": "dissertation-main/Slides/quarto/presentations/appendix_main.html#optimal-control-under-uncertainty-1",
    "href": "dissertation-main/Slides/quarto/presentations/appendix_main.html#optimal-control-under-uncertainty-1",
    "title": "main",
    "section": "Optimal Control under Uncertainty",
    "text": "Optimal Control under Uncertainty\n\nParameter uncertainty: psâˆ¼ğ’©(pÌ‚s,Ïƒp)p_s \\sim \\mathcal{N}(\\hat{p}_s, \\sigma_p).\n\n\n\n\n\nDeterministic\n\n\ng(ps):=âˆ’psâˆ’ps2+crÎ¸â‹†=g(pÌ‚s)\\begin{align*}\ng(p_s) &:= -p_s -\\sqrt{p_s^2+\\frac{c}{r}} \\\\\n\\theta^\\star &= g(\\hat{p}_s)\n\\end{align*}\n\n\n\n\nÂ \n\n\n\n\nProbabilistic\n\n\nfÎ¸â‹†(Î¸â‹†)=fp(gâˆ’1(Î¸â‹†))|ddÎ¸gâˆ’1(Î¸â‹†)|,=1Ïƒp2Ï€(12(1+crÎ¸â‹†2))exp{âˆ’12Ïƒp2(c2rÎ¸â‹†âˆ’Î¸â‹†2âˆ’pÌ‚s)2}\n\\begin{aligned}\nf_{\\theta^\\star}(\\theta^\\star) &= f_p\\left(g^{-1}(\\theta^\\star)\\right)\n        \\left| \\frac{d}{d\\theta}g^{-1}(\\theta^\\star) \\right|, \\\\ \n&= \\frac{1}{\\sigma_p \\sqrt{2\\pi}}\\left( \\\n\\frac{1}{2}\\left(1+\\frac{c}{r{\\theta^\\star}^2}\\right) \\right) \\exp{\\left\\{ -\\frac{1}{2\\sigma_p^2}\\left( \\frac{c}{2r\\theta^\\star} -\n\\frac{\\theta^\\star}{2} - \\hat{p}_s  \\right)^2  \\right\\} }\n\\end{aligned}\n\n\n\n\n\n\n\n\n(c,r)=(100,1)(c, r) = (100, 1)"
  },
  {
    "objectID": "dissertation-main/Slides/quarto/presentations/appendix_main.html#system-parameter-and-measurement-uncertainties",
    "href": "dissertation-main/Slides/quarto/presentations/appendix_main.html#system-parameter-and-measurement-uncertainties",
    "title": "main",
    "section": "System Parameter and Measurement Uncertainties",
    "text": "System Parameter and Measurement Uncertainties\n\n\n\n\n\nModel of measurement noise\n\n\nÎ£:{â…†x(t)=(ps+Î¸)x(t)â…†t+Î¸Ïƒâ…†Wt,x(0)=1,\n\\Sigma: \\quad\n  \\begin{cases} \n    \\dd x(t) = (p_s+\\theta)x(t) \\; \\dd t + \\theta\\sigma \\; \\dd W_t, \\\\ x(0) = 1,\n  \\end{cases} \n x(t)=e(ps+Î¸)t+Î¸Ïƒâˆ«0te(ps+Î¸)(tâˆ’s)dWs.\n x(t) = e^{(p_s+\\theta)t} + \\theta\\sigma \\int_0^t e^{(p_s+\\theta)(t-s)}dW_s.\n\n\n\n\n\nÂ \n\n\n\n\nPerformance Index\n\n\nğ’¥=âˆ«0T(12cx(t)2+12ru(t)2)dt,(c,r)=(1,1),T=pÌ‚s=3.\\begin{align*}\n\\mathcal{J} &= \\int_0^T \\left( \\frac{1}{2}cx(t)^2 + \\frac{1}{2}ru(t)^2  \\right)dt,\\\\\n(c, r) &= (1, 1), \\\\\nT &= \\hat{p}_s = 3. \n\\end{align*}\n\n\n\n\n\n\nWW Wiener process, measurement error given by ğ’©(x,Ïƒ)\\mathcal{N}(x, \\sigma)\nLeft figure: optimal parameter Î¸*\\theta^*, Right: minimal cost ğ”¼[ğ’¥]=ğ”¼ps[ğ”¼W[ğ’¥âˆ£ps]]\\mathbb{E}[\\mathcal{J}] = \\mathbb{E}_{p_s}\\left[\\mathbb{E}_W\\left[\\mathcal{J} \\mid p_s \\right]\\right]"
  },
  {
    "objectID": "dissertation-main/Slides/quarto/presentations/contents/bl_background.html",
    "href": "dissertation-main/Slides/quarto/presentations/contents/bl_background.html",
    "title": "main",
    "section": "",
    "text": "Objective: Given finite dataset with inherent noise, we are in search of a regression model\n\n\n\n\n\nE.g. Recognizing handwritten digits from images\n\nnoise due to differences in individual handwriting\n\n\n\n\n\nBayesian learning provides stochastic models that do not overfit on the training data\n\nStochastic model: \\(F(x;\\theta), \\theta \\sim P(\\theta | \\mathbb{D})\\)"
  },
  {
    "objectID": "dissertation-main/Slides/quarto/presentations/contents/bl_background.html#robustness-via-bayesian-learning",
    "href": "dissertation-main/Slides/quarto/presentations/contents/bl_background.html#robustness-via-bayesian-learning",
    "title": "main",
    "section": "Robustness via Bayesian Learning",
    "text": "Robustness via Bayesian Learning\n\n\n\n\n\nNeuralPbc assumes a nominal model \\(\\dot{x} = f(x, u)\\)\nThe trained controller must not overfit on the observations generated from the nominal model\n\n\n\n\n\n\n\n\n\nOur method: \\(H_d\\) is a Bayesian neural network\n\nachieves the performance objective for samples \\(\\theta \\sim P(\\theta | \\mathbb{D})\\)\nsearches for ensemble of parameters that meet the desired performance \\[\n  P(\\theta \\mid \\mathbb{D}) = \\frac{\\overbrace{P(\\mathbb{D} \\mid\n  \\theta)}^{\\text{likelihood}}\\overbrace{P(\\theta)}^{\\text{prior}}}\n  {\\underbrace{\\int_\\theta P(\\mathbb{D} \\mid \\theta^\\prime)P(\\theta^\\prime)\n  d\\theta^\\prime}_{\\text{evidence}}}.\n\\]"
  },
  {
    "objectID": "dissertation-main/Slides/quarto/presentations/contents/bl_background.html#training-stochastic-models",
    "href": "dissertation-main/Slides/quarto/presentations/contents/bl_background.html#training-stochastic-models",
    "title": "main",
    "section": "Training Stochastic Models",
    "text": "Training Stochastic Models\n\n\n\n\n\n\n\n\n\nBayesian Inference\n\n\n\n\\[\n\\begin{aligned}\n\\underset{P(\\theta | \\mathbb{D})}{\\text{maximize}} &&& P(\\mathbb{D} | \\theta) P(\\theta), \\\\\n\\text{subject to} &&\n& \\theta \\sim P(\\theta | \\mathbb{D}), \\\\\n&& \\mathbb{D} &= \\{(x_1, y_1), \\dots, (x_N, y_N) \\}.\n\\end{aligned}\n\\]\n\n\n\n\n\n\n\n\n\n\n\nBayesian Inference\n\n\n\n\\[\n\\begin{aligned}\n\\underset{P(\\theta | \\mathbb{D})}{\\text{maximize}} && \\prod_{j=1}^{N} \\mathcal{N}&(\\| F(x_j; \\theta) -  y_j \\| \\; | \\; 0, s_1) \\mathcal{N}(\\| \\theta - \\theta_0 \\| \\; | \\; 0, s_2), \\\\\n\\text{subject to} &&\n& \\theta \\sim P(\\theta | \\mathbb{D}), \\\\\n&& \\mathbb{D} &= \\{(x_1, y_1), \\dots, (x_N, y_N) \\}.\n\\end{aligned}\n\\]\n\n\n\n\n\n\n\n\n\n\n\nBayesian Inference\n\n\n\n\\[\n\\begin{aligned}\n\\underset{z}{\\text{maximize}} && \\mathcal{L}(\\mathbb{D},z) &= \\mathbb{E}_{\\theta \\sim Q} \\left[\\ln(P(\\mathbb{D} \\mid \\theta)P(\\theta)) - \\ln(Q(\\theta;z)) \\right], \\\\\n\\text{subject to} &&\n& \\theta \\sim Q(\\theta;z), \\\\\n&& \\mathbb{D} &= \\{(x_1, y_1), \\dots, (x_N, y_N) \\}.\n\\end{aligned}\n\\]\n\n\n\n\n\n\n\nVariational Inference: approximates the posterior \\(P(\\theta | \\mathbb{D})\\) with a pre-selected distribution \\(Q(\\theta; z)\\)\nObjective: collect \\(N_\\theta\\) samples from the current posterior \\(Q(\\theta; z)\\) and maximize Elbo \\[\n\\mathcal{L}(\\mathbb{D},z) = \\mathbb{E}_{\\theta \\sim Q} \\left[\\ln(P(\\mathbb{D} \\mid \\theta)P(\\theta)) - \\ln(Q(\\theta;z)) \\right]\n\\]"
  },
  {
    "objectID": "dissertation-main/Slides/quarto/presentations/contents/frontmatter.html",
    "href": "dissertation-main/Slides/quarto/presentations/contents/frontmatter.html",
    "title": "main",
    "section": "",
    "text": "Doctoral Dissertation Defense\n\n\n\n\nCandidate:  Nardos Ashenafi:mortar_board:  Electrical and Computer Engineering Department  Boise State University, Boise, Idaho, USA\n\n\nSupervisory Committee:  Aykut Satici, Ph.D.Â  John Chiasson, Ph.D.Â  Kurtis Cantley, Ph.D.Â  Hao Chen, Ph.D.Â  Arash Komaee, Ph.D."
  },
  {
    "objectID": "dissertation-main/Slides/quarto/presentations/contents/frontmatter.html#publications-and-contributions",
    "href": "dissertation-main/Slides/quarto/presentations/contents/frontmatter.html#publications-and-contributions",
    "title": "main",
    "section": "Publications and Contributions",
    "text": "Publications and Contributions\n\n\n\n\nPublished\n\nCCTA 2021: Cooperative Manipulation\nACC 2022: Bayesian NeuralPbc\nL-CSS 2022: Bayesian NeuralPbc\n\nCDC 2022\n\nArxiv 2022: Control Design via Bayesian Inference: Theoretical Justification of Robustness \n\n\n\n\n\n\nUpcoming Submissions\n\nTACON 2023: Control of Hybrid Dynamical Systems via Deep-net Mixture of Experts\nIJRR 2023: Data Driven Passivity-Based Control of the Rimless Wheel on Uneven Terrain"
  },
  {
    "objectID": "dissertation-main/Slides/quarto/presentations/contents/pbc_background.html#dissipativity",
    "href": "dissertation-main/Slides/quarto/presentations/contents/pbc_background.html#dissipativity",
    "title": "main",
    "section": "Dissipativity",
    "text": "Dissipativity\n\n\n\nA dynamical system \\[\n\\Sigma: \\quad\n\\begin{cases}\n\\dot{x} &= f(x,u) \\\\\ny &= g(x,u)\n\\end{cases}\n\\quad x \\in \\mathcal{X} \\subset \\mathbb{R}^{2m}, \\, u \\in \\mathcal{U} \\subset \\mathbb{R}^{n}\n\\] is dissipative with respect to some supply rate \\(s\\) if there exists a storage function \\(H: \\mathcal{X} \\to \\mathbb{R}^{+}\\) such that \\[\nH\\left(  x(t_1) \\right) \\leq  H\\left(  x(t_0) \\right) + \\int_{t_0}^{t_1} s(u(t), y(t)) \\, \\text{d}t\n\\] for all \\(x(t_0) = x_0\\), all input \\(u\\), and all \\(t_1 \\geq t_0\\)\nIt is passive if \\(s = u^{\\top} y\\)"
  },
  {
    "objectID": "dissertation-main/Slides/quarto/presentations/contents/pbc_background.html#stability-of-passive-systems",
    "href": "dissertation-main/Slides/quarto/presentations/contents/pbc_background.html#stability-of-passive-systems",
    "title": "main",
    "section": "Stability of Passive Systems",
    "text": "Stability of Passive Systems\n\n\n\\[\n\\Sigma: \\quad\n\\begin{cases}\n  \\dot{x} &= f(x,u) && f(0,0) = 0, \\\\\n  y &= g(x,u) && g(0,0) = 0.\n\\end{cases}\n\\]\n\\[\\begin{gather*}\nu^{\\top} y \\geq \\dot{H} = \\frac{\\partial H}{\\partial x} f(x,u), \\\\\n\\quad H \\geq 0,\\quad y \\equiv 0 \\implies x \\equiv 0.\n\\end{gather*}\\]\n\n\n\n\n\n\n\nLemma (Khalil, 2002)\n\n\n\nThe origin of \\(\\Sigma\\) is:\n\nstable if \\(\\Sigma\\) is passive,\nasymptotically stable if \\(\\Sigma\\) is output strictly passive (\\(s = u^\\top y - \\delta \\lVert y \\rVert^2, \\; \\delta > 0\\))."
  },
  {
    "objectID": "dissertation-main/Slides/quarto/presentations/contents/pbc_background.html#simple-pendulum",
    "href": "dissertation-main/Slides/quarto/presentations/contents/pbc_background.html#simple-pendulum",
    "title": "main",
    "section": "Simple Pendulum",
    "text": "Simple Pendulum\n\n\n\n\n\n\n\n\nEnergy Shaping\n\n\n\n\\(H(q,p) = \\frac{1}{2} J^{-1} p^2 + mgl (1 - \\cos q)\\)\n\\[\n\\begin{bmatrix} \\dot{q} \\\\ \\dot{p} \\end{bmatrix} =\n\\begin{bmatrix} \\phantom{-}0 & 1 \\\\ -1 & 0 \\end{bmatrix}\n\\begin{bmatrix} \\nabla_q H_{\\phantom{d}} \\\\ \\nabla_p H_{\\phantom{d}} \\end{bmatrix} +\n\\begin{bmatrix} 0 \\\\ \\Omega \\end{bmatrix} u_\\phantom{di},\n\\qquad y = \\dot{q}\n\\]\n\nChoose \\(u = u_{es} + u_{di}\\) that transforms system into a passive one with \\(x^\\star = (q^\\star, 0)\\) \n\n\n\\(\\Omega u_{es} = \\nabla_q H - \\nabla_q H_d , \\quad \\Omega u_{di} = -\\Omega K_D \\Omega^\\top \\nabla_p H_d\\)\n\n\n\n\\[\n\\begin{bmatrix} \\dot{q} \\\\ \\dot{p} \\end{bmatrix} =\n\\begin{bmatrix} \\phantom{-}0 & 1 \\\\ -1 & 0 \\end{bmatrix}\n\\begin{bmatrix} \\nabla_q H_d \\\\ \\nabla_p H_d \\end{bmatrix} +\n\\begin{bmatrix} 0 \\\\ \\Omega \\end{bmatrix} u_{di},\n\\qquad y = \\dot{q}\n\\]\n\n\n\\[\n\\begin{bmatrix} \\dot{q} \\\\ \\dot{p} \\end{bmatrix} =\n\\begin{bmatrix} \\phantom{-}0 & 1 \\\\ -1 & -\\Omega K_D \\Omega^\\top \\end{bmatrix}\n\\begin{bmatrix} \\nabla_q H_d \\\\ \\nabla_p H_d \\end{bmatrix},\n\\qquad y = \\dot{q}\n\\]"
  },
  {
    "objectID": "dissertation-main/Slides/quarto/presentations/contents/pbc_background.html#simple-pendulum-1",
    "href": "dissertation-main/Slides/quarto/presentations/contents/pbc_background.html#simple-pendulum-1",
    "title": "main",
    "section": "Simple Pendulum",
    "text": "Simple Pendulum\n\n\n\n\n\n\n\nControl Synthesis via PBC\n\n\n\nChoose \\(u = u_{es} + u_{di}\\) that transforms system into a passive one with \\(x^\\star = (q^\\star, 0)\\)\n\\(\\Omega u_{es} = \\nabla_q H - \\nabla_q H_d , \\quad \\Omega u_{di} = -\\Omega K_D \\Omega^\\top \\nabla_p H_d\\)\n\\[\n\\begin{bmatrix} \\dot{q} \\\\ \\dot{p} \\end{bmatrix} =\n\\begin{bmatrix} \\phantom{-}0 & 1 \\\\ -1 & -\\Omega K_D \\Omega^\\top \\end{bmatrix}\n\\begin{bmatrix} \\nabla_q H_d \\\\ \\nabla_p H_d \\end{bmatrix},\n\\qquad y = \\dot{q}\n\\]\n\n\\(H_d(q,p) = \\frac{1}{2} J^{-1} p^2 + V_d(q), \\quad V_d(q) = \\frac{1}{2} K_{P} \\left( q - q^\\star \\right)^2\\)\n\n\n\n\\(\\dot{H}_d = -K_D \\left( J^{-1} p \\right)^2 = y^\\top u_{di} \\leq 0\\)\n\n\n\\(\\boxed{u = -mgl\\sin(q) - K_P(q - q^\\star) - K_D \\dot{q}}\\)\n\n\n\n\n\n\n\n\n\n\nConstraint on \\(H_d\\)\n\n\n\n\\[\\begin{align*}\n\\Omega^\\perp (\\nabla_q H  - \\nabla_q H_d) = 0\n\\end{align*}\\] where \\(\\Omega^\\perp \\Omega = 0\\)."
  },
  {
    "objectID": "dissertation-main/Slides/quarto/presentations/contents/pbc_background.html#neuralpbc",
    "href": "dissertation-main/Slides/quarto/presentations/contents/pbc_background.html#neuralpbc",
    "title": "main",
    "section": "NeuralPbc",
    "text": "NeuralPbc\n\n\n\n\n\n\n\n\nNeuralPbc Optimization Problem\n\n\n\n\\[\n\\begin{aligned}\n\\underset{\\theta}{\\text{minimize}} && J(\\phi, u^\\theta) &= \\mathbb{E}_{x_0 \\in \\mathcal{D}_N}[ \\ell( \\phi(x_0, u, T), u) ], \\\\\n\\text{subject to} &&\n\\begin{bmatrix}\n  \\dot{q} \\\\ \\dot{p}\n\\end{bmatrix} &=\n\\begin{bmatrix}\n  0 & I \\\\ -I & 0\n\\end{bmatrix}\n\\begin{bmatrix} \\nabla_q H \\\\ \\nabla_p H \\end{bmatrix} +\n\\begin{bmatrix}\n  0 \\\\ \\Omega\n\\end{bmatrix} u^{\\theta},\n\\\\\n&& u^\\theta &= \\Omega^{\\dagger}(\\nabla_q H  - \\nabla_q H_d^\\theta).\n\\end{aligned}\n\\]\n\n\n\nParameterize \\(H_d\\) by a neural network \\(H_d^\\theta\\)\nDesired performance characterized by \\(\\ell\\) observed from trajectory \\(\\phi\\)\nApproximate solutions to the PDEs found via stochastic gradient descent"
  },
  {
    "objectID": "dissertation-main/Slides/quarto/presentations/contents/bl_results.html",
    "href": "dissertation-main/Slides/quarto/presentations/contents/bl_results.html",
    "title": "main",
    "section": "",
    "text": "Subtracting rings from the wheel\n\ndecreases wheel mass\ndecreases wheel and pendulum inertia\nmoves the center of mass\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPerformance objective: achieve hip speed \\(\\dot{x}_c^* = 1\\)m/s \\[\\begin{align*}\n  J_T = \\sum_{t=0}^{T} \\| \\dot{x}_c^* - \\dot{x}_c(t; \\theta) \\|\n\\end{align*}\\]\nUncertainty in elevation under each spoke \\[\np_s \\sim \\mathbb{U}(0 \\textrm{cm}, 2\\textrm{cm})\n\\]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\[\\begin{align*}\np_s &\\sim \\mathbb{U}(0, p_{max})  \\\\\np_{max} &= [0, 0.5, 1, 1.5, 2] \\textrm{cm} \\\\\nJ_T &= \\sum_{t=0}^{T} \\| \\dot{x}_c^* - \\dot{x}_c(t; \\theta) \\|\n\\end{align*}\\]\n\n\n\n\n\n\n\n\n\n\n\n\n\nMOE controller: multi-modal controller for multi-modal dynamics\nNeuralPbc + Bayesian inference = robust controller with stability properties\nFuture work\n\nmanipulation tasks\nmulti-modal controller in uncertain environment"
  },
  {
    "objectID": "dissertation-main/Slides/quarto/presentations/contents/moe_background.html#mixture-of-experts-moe-old-faithful",
    "href": "dissertation-main/Slides/quarto/presentations/contents/moe_background.html#mixture-of-experts-moe-old-faithful",
    "title": "main",
    "section": "Mixture of Experts (MOE): Old Faithful",
    "text": "Mixture of Experts (MOE): Old Faithful\n\nObjective: learn two expert Gaussian models that represent dataset \\(\\mathbb{D} = \\{(x_1, y_1), \\dots, (x_N, y_N) \\}\\)\n\n\n\n\n\nThe experts are chosen as \\[\\begin{align*}\nF(x;\\theta) &= \\{\\mathcal{N}_1(\\mu_1, \\sigma_1), \\mathcal{N}_2(\\mu_2, \\sigma_2)\\} \\\\\n\\theta &= \\{(\\mu_1, \\sigma_1), (\\mu_2, \\sigma_2) \\}\n\\end{align*}\\]\n\nPrediction is a weighted-average of experts\n\n\n\n\n\n\n\n\n\n\n\nThe gating network is a neural net \\(\\mathbf{P}(x | \\psi) = [P_1(x | \\psi), P_2(x | \\psi) ]\\)\n\nDivides the input space into partitions\n\n\n\n\n\nExpectation Maximization: maximizes log likelihood \\[\n\\ln \\{P(\\mathbb{D} | \\theta, \\psi) \\} = \\sum_{j=1}^{N} \\ln \\sum_{i=1}^{N_F} \\frac{1}{\\sqrt{2 \\pi \\sigma_i^2}} \\exp \\left( -\\frac{1}{2}\\frac{(y_j - \\mu_i)^2}{\\sigma_i^2} \\right) P_i(x_j, \\psi)\n\\]"
  },
  {
    "objectID": "dissertation-main/Slides/quarto/presentations/contents/moe_results.html",
    "href": "dissertation-main/Slides/quarto/presentations/contents/moe_results.html",
    "title": "main",
    "section": "",
    "text": "Notice LQR fails due to the impact from the wall\nMOE controller training\n\nthere are three deep-net experts \\(F_i(x;\\theta_i)\\)\nthe gating network is also a neural net\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe contact-aware MOE controller\n\nleverages the impacts from the wall\nswitches to a policy that rapidly brakes to assist in the catching process\n\n\n\n\n\n\n\n\n\n\n \n\n\nWe provide a data-driven control design that automatically learns several policies and the necessary switching scheme\nThe framework leverages the switching controllers to stabilize the multi-modal dynamical system\nThe gating network successsfully parameterizes the control-switching conditionals that achieves the desired performance"
  },
  {
    "objectID": "dissertation-main/Slides/quarto/presentations/contents/bl_justification.html",
    "href": "dissertation-main/Slides/quarto/presentations/contents/bl_justification.html",
    "title": "main",
    "section": "",
    "text": "Optimal Control for a Linear System\n\n\n\n\\[\n\\Sigma: \\quad\n\\begin{cases}\n  \\dot{x} &= p_s x + u, \\\\\n  u(x) &= \\theta x, \\\\\n  x(0) &= 1.\n\\end{cases}\n\\]\n\n\n\\[\n  x(t) = e^{(p_s+\\theta)t}\n\\]\n\n\nPerformance Index: \\[\n\\mathcal{J} = \\int_0^T \\left( \\frac{1}{2}cx(t)^2 + \\frac{1}{2}ru(t)^2  \\right)dt\n\\]\n\n\n\n\n\n\\[\n\\mathcal{J}_\\infty = -\\frac{1}{4}\\frac{c+r\\theta^2}{p_s+\\theta}\n\\]\n\n\n\n\\(\\theta^\\star = -p_s -\\sqrt{p_s^2+\\frac{c}{r}}\\)\n\n\n\n\n\n\n\nParameter uncertainty: \\(p_s \\sim \\mathcal{N}(\\hat{p}_s, \\sigma_p)\\).\n\n\n\n\n\n\n\n\nDeterministic\n\n\n\n\\[\\begin{align*}\ng(p_s) &:= -p_s -\\sqrt{p_s^2+\\frac{c}{r}} \\\\\n\\theta^\\star &= g(\\hat{p}_s)\n\\end{align*}\\]\n\n\n\nÂ \n\n\n\n\n\n\n\nProbabilistic\n\n\n\n\\[\n\\begin{aligned}\nf_{\\theta^\\star}(\\theta^\\star) &= f_p\\left(g^{-1}(\\theta^\\star)\\right)\n        \\left| \\frac{d}{d\\theta}g^{-1}(\\theta^\\star) \\right|, \\\\\n&= \\frac{1}{\\sigma_p \\sqrt{2\\pi}}\\left( \\\n\\frac{1}{2}\\left(1+\\frac{c}{r{\\theta^\\star}^2}\\right) \\right) \\exp{\\left\\{ -\\frac{1}{2\\sigma_p^2}\\left( \\frac{c}{2r\\theta^\\star} -\n\\frac{\\theta^\\star}{2} - \\hat{p}_s  \\right)^2  \\right\\} }\n\\end{aligned}\n\\]\n\n\n\n\n\n\n\\((c, r) = (100, 1)\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nModel of measurement noise\n\n\n\n\\[\n\\Sigma: \\quad\n  \\begin{cases}\n    \\dd x(t) = (p_s+\\theta)x(t) \\; \\dd t + \\theta\\sigma \\; \\dd W_t, \\\\ x(0) = 1,\n  \\end{cases}\n\\] \\[\nx(t) = e^{(p_s+\\theta)t} + \\theta\\sigma \\int_0^t e^{(p_s+\\theta)(t-s)}dW_s.\n\\]\n\n\n\nÂ \n\n\n\n\n\n\n\nPerformance Index\n\n\n\n\\[\\begin{align*}\n\\mathcal{J} &= \\int_0^T \\left( \\frac{1}{2}cx(t)^2 + \\frac{1}{2}ru(t)^2  \\right)dt,\\\\\n(c, r) &= (1, 1), \\\\\nT &= \\hat{p}_s = 3.\n\\end{align*}\\]\n\n\n\n\n\n\\(W\\) Wiener process, measurement error given by \\(\\mathcal{N}(x, \\sigma)\\)\nLeft figure: optimal parameter \\(\\theta^*\\), Right: minimal cost \\(\\mathbb{E}[\\mathcal{J}] = \\mathbb{E}_{p_s}\\left[\\mathbb{E}_W\\left[\\mathcal{J} \\mid p_s \\right]\\right]\\)"
  },
  {
    "objectID": "dissertation-main/Slides/quarto/presentations/contents/moe_methods.html",
    "href": "dissertation-main/Slides/quarto/presentations/contents/moe_methods.html",
    "title": "main",
    "section": "",
    "text": "Objective: learn contact-aware mixture of experts controller and a gating network\n\n\n\n\nAll the experts and the gating network are given by neural nets\nWe pose the search over the parameters \\(\\psi, \\theta\\) as the following optimization problem\n\n\n\n\n\n\n\nOptimization Problem\n\n\n\n\\[\\begin{align*}\n    \\begin{aligned}\n        \\underset{\\psi, \\theta}{\\textrm{minimize}}\n        & & & \\int_0^T \\ell (x(t),u) \\dd t , \\\\%\n        \\textrm{subject to}\n        & & & M(q) \\dd \\dot{q} + h(x; \\psi, \\theta)\\dd t - \\dd R  = 0,\\\\%\n        & & & u = \\{F_i(x; \\theta_i) \\; | \\; i  \\sim \\text{Categorical} (\\mathbf{P}(x| \\psi)) \\}.\n    \\end{aligned}\n\\end{align*}\\]\n\n\n\n\n\n\n\n\n\nTraining procedure:\n\nStart from initial parameters \\((\\psi, \\theta)\\)\nSample initial state \\(x_0\\)\nGenerate trajectories \\(\\phi(x_0, u, T)\\) using current parameters \\[\\begin{gather*}\ni  \\sim \\text{Categorical} (\\mathbf{P}(x| \\psi)) \\\\\nu(x; \\psi, \\theta) = F_i(x; \\theta_i) \\\\\nM(q) \\dd \\dot{q} + h(x; \\psi, \\theta) \\dd t - \\dd R  = 0 \\text{ (Moreau's time stepping)}\n\\end{gather*}\\]\nAssign a running cost \\(\\ell\\) to the trajectories based on performance\nUpdate parameters \\((\\psi, \\theta)\\) to minimize running cost\n\n\n\n\n\n\n\n\\[\\begin{align*}\n    \\begin{aligned}\n        \\underset{\\psi, \\theta}{\\textrm{minimize}}\n        & & & \\int_0^T \\ell (x(t),u) \\dd t , \\\\%\n        \\textrm{subject to}\n        & & & M(q) \\dd \\dot{q} + h(x; \\psi, \\theta)\\dd t - \\dd R  = 0,\\\\%\n        & & & u = \\{F_i(x; \\theta_i) \\; | \\; i  \\sim \\text{Categorical} (\\mathbf{P}(x| \\psi)) \\}.\n    \\end{aligned}\n\\end{align*}\\]\n\n\nAccumulated loss: total quadratic loss from desired state \\(x^*\\) \\[\\begin{gather*}\n\\ell(x, u) = \\frac{1}{2}(x - x^*)^\\top \\mathcal{Q} (x - x^*) + \\frac{1}{2} u^\\top \\mathcal{R} u \\\\\n\\mathcal{Q} \\succ 0, \\mathcal{R} \\succeq 0\n\\end{gather*}\\]\n\n\n\nThe corresponding likelihood function is\n\n\n\n\\[\n\\ln \\{P(\\mathbb{D} | \\theta, \\psi) \\} = \\sum_{j=1}^{N} \\ln \\sum_{i=1}^{N_F} \\frac{1}{\\sqrt{2 \\pi \\sigma_i^2}} \\exp \\left( -\\frac{1}{2}\\frac{(y_j - \\mu_i)^2}{\\sigma_i^2} \\right) P_i(x_j, \\psi)\n\\]\n\n\n\\[\n\\ln \\{P(\\phi | \\theta, \\psi) \\} = \\sum_{t=0}^{T} \\ln \\sum_{i=1}^{N_F} \\frac{1}{\\sqrt{2 \\pi s^2}} \\exp \\left( -\\frac{1}{2}\\frac{\\ell (x(t+\\Delta t), F_i )^2}{s^2} \\right) P_i(x(t), \\psi)\n\\]\n\n\n\n\n\nObjective: meet performance for various initial states"
  },
  {
    "objectID": "dissertation-main/Slides/quarto/presentations/contents/bl_methods.html",
    "href": "dissertation-main/Slides/quarto/presentations/contents/bl_methods.html",
    "title": "main",
    "section": "",
    "text": "NeuralPbc Optimization Problem\n\n\n\n\\[\n\\begin{aligned}\n\\underset{\\theta}{\\text{minimize}} && J(\\phi, u^\\theta) &= \\mathbb{E}_{x_0 \\in \\mathcal{D}_N}[ \\ell( \\phi(x_0, u, T), u) ], \\\\\n\\text{subject to} &&\n\\begin{bmatrix}\n  \\dot{q} \\\\ \\dot{p}\n\\end{bmatrix} &=\n\\begin{bmatrix}\n  0 & I \\\\ -I & 0\n\\end{bmatrix}\n\\begin{bmatrix} \\nabla_q H \\\\ \\nabla_p H \\end{bmatrix} +\n\\begin{bmatrix}\n  0 \\\\ \\Omega\n\\end{bmatrix} u^{\\theta},\n\\\\\n&& u^\\theta &= \\Omega^{\\dagger}(\\nabla_q H  - \\nabla_q H_d^\\theta).\n\\end{aligned}\n\\]\n\n\n\n\n\n\n\n\n\n\nBayesian NeuralPbc Optimization Problem\n\n\n\n\\[\n\\begin{aligned}\n    \\underset{z}{\\text{minimize}} && J(\\phi, u^\\theta) &= \\mathbb{E}_{x_0 \\in \\mathcal{D}_N}[ \\ell( \\phi(x_0, u, T), u) ], \\\\\n    \\text{subject to} &&\n    \\begin{bmatrix}\n    \\dot{q} \\\\ \\dot{p}\n    \\end{bmatrix} &=\n    \\begin{bmatrix}\n    0 & I \\\\ -I & 0\n    \\end{bmatrix}\n    \\begin{bmatrix} \\nabla_q H \\\\ \\nabla_p H \\end{bmatrix} +\n    \\begin{bmatrix}\n    0 \\\\ \\Omega\n    \\end{bmatrix} u^{\\theta},\n    \\\\\n    && u^\\theta &= \\Omega^{\\dagger}(\\nabla_q H  - \\nabla_q H_d^\\theta),\\\\\n    && \\theta &\\sim Q(\\theta; z).\n\\end{aligned}\n\\]\n\n\n\n\n\n\nThe parameter \\(z\\) of the posterior \\(Q(\\theta;z)\\) is inferred from running cost \\(J(\\phi, u^\\theta)\\)\n\\(H_d^\\theta\\) is a Bayesian neural network (BNN)\n\n\n\n\n\n\nWe provide more structure to the variance of the Bayesian controllers\n\n\n\n\n\n\n\nBayesian NeuralPbc Optimization Problem\n\n\n\n\\[\n\\begin{aligned}\n    \\underset{z}{\\text{minimize}} && J(\\phi, u^\\theta) &= \\mathbb{E}_{x_0 \\in \\mathcal{D}_N}[ \\ell( \\phi(x_0, u, T), u) ], \\\\\n    \\text{subject to} &&\n    \\dd x &= \\left(\n        \\begin{bmatrix}\\phantom{-}\\nabla_p H \\\\-\\nabla_q H \\end{bmatrix} + \\begin{bmatrix} 0 \\\\ \\Omega \\end{bmatrix} u^{\\theta}(x) \\right) \\dd t + \\nabla_x u(x) \\dd W_t, \\\\\n    && u^\\theta &= \\Omega^{\\dagger}(\\nabla_q H  - \\nabla_q H_d^\\theta),\\\\\n    && \\theta &\\sim Q(\\theta; z), \\\\\n    && p_s &\\sim \\mathcal{N}(\\hat{p}_s, \\sigma_p).\n\\end{aligned}\n\\]\n\n\n\nObjective: maximize Elbo\n\n\\[\\begin{gather*}\n  \\mathcal{L}(J,z) = \\mathbb{E}_{\\theta \\sim Q} \\left[\\ln(P(J \\mid \\theta)P(\\theta)) - \\ln(Q(\\theta;z)) \\right] \\\\\n  P(J | \\theta) = \\mathcal{N}(J \\; | \\; 0, s).\n\\end{gather*}\\]\n\n\n\n\n\n\n\n\n\n\n\n\nPassive Smooth System\n\n\n\n\\[\nH\\left(  x(t_1) \\right) \\leq  H\\left(  x(t_0) \\right) + \\int_{t_0}^{t_1} s(u(t), y(t)) \\, \\text{d}t\n\\]\n\n\n\nÂ \n\n\n\n\n\n\n\nPassive Hybrid System\n\n\n\n\\[\\begin{gather*}\nH\\left(  x(t_1) \\right) \\leq  H\\left(  x(t_0) \\right) + \\int_{t_0}^{t_1} s(u(t), y(t)) \\, \\text{d}t \\\\\nH(x^+) \\leq H(x^-)\n\\end{gather*}\\]\n\n\n\n\n\n\n\n\n\n\n\nNeuralPbc for contact-rich system\n\n\n\n\\[\\begin{aligned}\n    \\underset{\\theta}{\\textrm{minimize}}\n    & & J(\\phi, u^\\theta) &= \\mathbb{E}_{x_0 \\in \\mathcal{D}_N}[ \\ell( \\phi(x_0, u, T), u) ], \\\\%\n    \\textrm{subject to}\n    & & M(q) &\\dd \\dot{q} + h(q, \\dot{q}, \\theta)\\dd t - \\dd R  = 0,\\\\%\n    & & u^{\\theta} &= \\Omega^{\\dagger}(\\nabla_q H  - \\nabla_q H_d).%\n\\end{aligned}\\]\n\n\n\n\n\n\n\n\n\n\n\n\nNeuralPbc for contact-rich system\n\n\n\n\\[\\begin{aligned}\n    \\underset{z}{\\textrm{minimize}}\n    & & & J(\\phi, u) = \\mathbb{E}_{x_0 \\in \\mathcal{D}_N}[\\ell(\\phi(x_0, u^\\theta, T), u^\\theta)], \\\\\n    \\textrm{subject to}\n    & & M(q) &\\dd \\dot{q} + h(q, \\dot{q}, \\theta)\\dd t - \\dd R  = 0,\\\\\n    & & u^{\\theta} &= \\Omega^{\\dagger}(\\nabla_q H  - \\nabla_q H_d^\\theta), \\\\\n    & & p_s &\\sim \\mathbb{U}(p_{min}, p_{max}), \\\\\n    & & \\theta &\\sim Q(\\theta; z).\n\\end{aligned}\\]"
  },
  {
    "objectID": "dissertation-main/Slides/quarto/presentations/contents/justification.html",
    "href": "dissertation-main/Slides/quarto/presentations/contents/justification.html",
    "title": "main",
    "section": "",
    "text": "Why does Bayesian Learning result in more robust controllers?\n\n\n\n\n\nScalar control system\nUncertain drift vector field: \\(p \\sim \\mathcal{N}(\\hat{p}, \\sigma_p^2)\\).\nNo measurement uncertainty\n\n\n\n\n\n\n\\[\n\\Sigma: \\quad\n\\begin{cases}\n  \\dot{x} &= px + u, \\\\\n  u(x) &= \\theta x, \\\\\n  x(0) &= 1.\n\\end{cases}\n\\] \\[\n  x(t) = e^{(p+\\theta)t}.\n\\]\n\n\nÂ \n\n\n\n\n\n\n\n\n\n\n\n\n\\[\n\\Sigma: \\quad\n\\begin{cases}\n  \\dot{x} &= px + u, \\\\\n  u(x) &= \\theta x, \\\\\n  x(0) &= 1.\n\\end{cases}\n\\] \\[\n  x(t) = e^{(p+\\theta)t}.\n\\]\n\n\nÂ \n\n\n\n\n\nQuadratic performance index\n\n\\(q \\geq 0\\), \\(r > 0\\)\n\n\\(T\\): control horizon\n\n\n\n\\[\n\\mathcal{J} = \\int_0^T \\left( \\frac{1}{2}qx(t)^2 + \\frac{1}{2}ru(t)^2  \\right)dt.\n\\]\n\n\n\n\n\n\n\n\n\\[\n\\mathcal{J} = \\int_0^T \\left( \\frac{1}{2}qx(t)^2 + \\frac{1}{2}ru(t)^2  \\right)dt.\n\\] \\[\n\\mathcal{J}_{T \\to \\infty} = -\\frac{1}{4}\\frac{q+r \\theta^2}{p+\\theta}.\n\\]\n\n\nÂ \n\n\n\n\nSolve for \\(\\theta\\) that minimizes \\(\\mathcal{J}_\\infty\\): \\(\\theta^\\star = g(p) := -p -\\sqrt{p^2+\\frac{q}{r}}\\).\n\n\n\n\n\n\n\n\n\nDeterministic\n\n\n\n\\(\\theta^\\star = g(\\hat{p}) := -\\hat{p} -\\sqrt{\\hat{p}^2+\\frac{q}{r}}\\)\n\n\n\nÂ \n\n\n\n\n\n\n\nProbabilistic\n\n\n\n\\[\n\\begin{aligned}\nf_{\\theta^\\star}(\\theta^\\star) &= \\frac{1}{\\sigma_p \\sqrt{2\\pi}}\\left( \\\n\\frac{1}{2}\\left(1+\\frac{q}{r{\\theta^\\star}^2}\\right) \\right) \\\\\n&\\exp{\\left\\{ -\\frac{1}{2\\sigma_p^2}\\left( \\frac{q}{2r\\theta^\\star} -\n\\frac{\\theta^\\star}{2} - \\hat{p}  \\right)^2  \\right\\} }\n\\end{aligned}\n\\]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDeterministic\n\n\n\n\\(\\theta^\\star = g(\\hat{p}) := -\\hat{p} -\\sqrt{\\hat{p}^2+\\frac{q}{r}}\\)\n\n\n\nÂ \n\n\n\n\n\n\n\nProbabilistic\n\n\n\n\\[\n\\begin{aligned}\nf_{\\theta^\\star}(\\theta^\\star) &= \\frac{1}{\\sigma_p \\sqrt{2\\pi}}\\left( \\\n\\frac{1}{2}\\left(1+\\frac{q}{r{\\theta^\\star}^2}\\right) \\right) \\\\\n&\\exp{\\left\\{ -\\frac{1}{2\\sigma_p^2}\\left( \\frac{q}{2r\\theta^\\star} -\n\\frac{\\theta^\\star}{2} - \\hat{p}  \\right)^2  \\right\\} }\n\\end{aligned}\n\\]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSame control system with measurement noise: \\(x \\sim \\mathcal{N}(x, \\sigma^2)\\).\n\n\n\n\\[\n\\Sigma: \\quad\n\\begin{cases}\n  dx(t) &= (p+\\theta)x(t) dt + \\theta \\sigma dW_t, \\\\\n  x(0) &= 1.\n\\end{cases}\n\\]\n\n\n\\[\nx(t) = e^{(p+\\theta)t} + \\theta \\sigma \\int_0^t e^{(p+\\theta)(t-s)}dW_s.\n\\]\n\n\n\n\n\n\n\n\n\nLemma\n\n\n\nThe conditional expectation \\(\\mathbb{E}[\\mathcal{J} \\mid p]\\) of the performance index given the system parameter \\(p\\) is\n\\[\n\\mathbb{E}[\\mathcal{J} \\mid p] =\n-\\frac{1}{4}\\frac{q+r\\theta^2}{p+\\theta}\\left[ \\theta^2 \\sigma^2 T +\n\\left(1-e^{2 T (p+\\theta)}\\right) \\left(1+\\frac{1}{2}\\frac{\\theta^2\n\\sigma^2}{p+\\theta}\\right) \\right]\n\\]\n\n\n\n\n\n\n\n\n\n\\[\n\\mathbb{E}[\\mathcal{J} \\mid p] =\n-\\frac{1}{4}\\frac{q+r\\theta^2}{p+\\theta}\\left[ \\theta^2 \\sigma^2 T +\n\\left(1-e^{2 T (p+\\theta)}\\right) \\left(1+\\frac{1}{2}\\frac{\\theta^2\n\\sigma^2}{p+\\theta}\\right) \\right]\n\\]\n\n\n\n\n\n\n\n\nProof\n\n\n\nSubstituting the solution of the SDE into the performance measure yields\n\\[\n\\begin{aligned} \\mathcal{J} =\n        & -\\frac{1}{4}\\frac{q+r\\theta^2}{p+\\theta}\\left(1 +\n        e^{2T(p+\\theta)}\\right) +\n        (q+r\\theta^2)\\theta\\sigma \\int_0^T\n        e^{(p+\\theta)t} \\int_0^t e^{(p+\\theta)(t-s)}dW_s\n        dt \\; + \\\\ &\\frac{1}{2}(q+r\\theta^2)\\theta^2\n        \\sigma^2 \\int_0^T \\left( \\int_0^t\n        e^{(p+\\theta)(t-s)} dW_s  \\right)^2 dt\n\\end{aligned}\n\\]\nThe conditional expectation of this quantity given the system parameter \\(p\\) under the distribution induced by the Wiener process may be computed in closed-form using Ito calculus.\n\\[\n\\begin{aligned}\n\\mathbb{E}_W\\left[\\mathcal{J} \\mid p \\right] &= -\\frac{1}{4}\\frac{q+r\\theta^2}{p+\\theta}\\left(1 - e^{2T(p+\\theta)}\\right) +\n        (q+r\\theta^2)\\theta\\sigma\\int_0^Te^{(p+\\theta)t}\\mathbb{E}_W\\left[\\int_0^t\n        e^{(p+\\theta)(t-s)} dW_s~\\Big\\rvert p\\right] dt + \\\\\n        &\\frac{1}{2}(q+r\\theta)^2\\theta^2\\sigma^2\\int_0^T\\mathbb{E}_W\\left[\\left(\\int_0^t\n        e^{(p+\\theta)(t-s)} dW_s \\right)^2~\\bigg\\rvert p\\right] dt \\\\\n        &=-\\frac{1}{4}\\frac{q+r\\theta^2}{p+\\theta}\\left(1 -\n        e^{2T(p+\\theta)}\\right) +\n        \\frac{1}{2}(q+r\\theta^2)\\theta^2\\sigma^2\\int_0^T\\left(\\int_0^t\n        e^{2(p+\\theta)(t-s)} ds \\right) dt \\\\\n        &=-\\frac{1}{4}\\frac{q+r\\theta^2}{p+\\theta}\\left(1 - e^{2T(p+\\theta)}\\right) +\n        \\frac{1}{2}(q+r\\theta^2)\\theta^2\\sigma^2\\int_0^T\n        -\\frac{1}{2(p+\\theta)}\\left(1 - e^{2T(p+\\theta)}\\right) dt \\\\\n        &=-\\frac{1}{4}\\frac{q+r\\theta^2}{p+\\theta} \\left[ \\theta^2 \\sigma^2 T +\n        \\left(1 - e^{2T(p+\\theta)}\\right) \\left(1 +\n        \\frac{1}{2}\\frac{\\theta^2\\sigma^2}{p+\\theta}\\right)\\right].\n\\end{aligned}\n\\]\n\n:orange_square:\n\n\n\n\n\n\n\n\n\n\n\nOptimal controller \\(|\\theta^\\star|\\) minimizing \\(\\mathbb{E}\\mathcal{J}\\)\n\n\n\nMinimal expected cost \\(\\mathbb{E}\\mathcal{J}\\)\n\n\n\n\n\n\n\n\n\n\nOptimal controller \\(|\\theta^\\star|\\) minimizing \\(\\mathbb{E}\\mathcal{J}\\)\n\n\n\n\n\nMinimal expected cost \\(\\mathbb{E}\\mathcal{J}\\)\n\n\n\n\n\nOptimal control parameter a nontrivial function of \\(\\sigma\\) and \\(\\sigma_p\\).\nBayesian learning strikes the right trade-off."
  },
  {
    "objectID": "dissertation-main/Slides/quarto/presentations/contents/introduction.html",
    "href": "dissertation-main/Slides/quarto/presentations/contents/introduction.html",
    "title": "main",
    "section": "",
    "text": "exhibit both continuous state flow and discrete state transitions\n\n\n\n\nE.g. Room temperature control, contact-rich robots\n\n\n\n\nWe tackle two main challenges in the control of contact-rich robots\n\n\n\n\n\n\n\n\nWalking machines\n\n\n\n\n\n\n\n\nManipulators"
  },
  {
    "objectID": "dissertation-main/Slides/quarto/presentations/contents/introduction.html#challenge-1-mode-changes",
    "href": "dissertation-main/Slides/quarto/presentations/contents/introduction.html#challenge-1-mode-changes",
    "title": "main",
    "section": "Challenge 1: Mode Changes",
    "text": "Challenge 1: Mode Changes\n\n\n\n\n\n\n\n\n\n\nContacts cause mode changes\nEach mode has distinct dynamics\nSwitching control does not scale well\nIt is difficult to parameterize the switching condition"
  },
  {
    "objectID": "dissertation-main/Slides/quarto/presentations/contents/introduction.html#challenge-1-proposed-method",
    "href": "dissertation-main/Slides/quarto/presentations/contents/introduction.html#challenge-1-proposed-method",
    "title": "main",
    "section": "Challenge 1: Proposed Method",
    "text": "Challenge 1: Proposed Method\n \n\nOur method uses data-driven technique to automatically learn a mixture of expert controller and the switching conditionals\n\n\n\nWe infer contact-aware controllers by training on trajectories generated from contact models\n\nContact-aware controllers minimize the adverse effects of contacts or leverage the potential contacts to their advantage"
  },
  {
    "objectID": "dissertation-main/Slides/quarto/presentations/contents/introduction.html#challenge-2-operating-under-uncertain-conditions",
    "href": "dissertation-main/Slides/quarto/presentations/contents/introduction.html#challenge-2-operating-under-uncertain-conditions",
    "title": "main",
    "section": "Challenge 2: Operating under Uncertain Conditions",
    "text": "Challenge 2: Operating under Uncertain Conditions"
  },
  {
    "objectID": "dissertation-main/Slides/quarto/presentations/contents/introduction.html#challenge-2-existing-methods",
    "href": "dissertation-main/Slides/quarto/presentations/contents/introduction.html#challenge-2-existing-methods",
    "title": "main",
    "section": "Challenge 2: Existing Methods",
    "text": "Challenge 2: Existing Methods\n\n\n\n\n\nReinforcement learning \n\n\nÂ \n\n\n\nStrengths\n\nMore general\nUnknown dynamics OK\n\nWeaknesses\n\nSample complexity\nStability guarantees?\n\n\n\n\n\n\n\n\n\n\nBayesian Neural Passivity-based Control \n\n\nÂ \n\n\n\nStrengths\n\nStability guarantees\nClosed-form policy\nReasons about model uncertainties"
  },
  {
    "objectID": "main.html#mixture-of-experts-moe-old-faithful",
    "href": "main.html#mixture-of-experts-moe-old-faithful",
    "title": "main",
    "section": "Mixture of Experts (MOE): Old Faithful",
    "text": "Mixture of Experts (MOE): Old Faithful\n\nObjective: learn two expert Gaussian models that represent dataset ğ”»={(x1,y1),â€¦,(xN,yN)}\\mathbb{D} = \\{(x_1, y_1), \\dots, (x_N, y_N) \\}\n\n\n\n\n\nThe experts are chosen as F(x;Î¸)={ğ’©1(Î¼1,Ïƒ1),ğ’©2(Î¼2,Ïƒ2)}Î¸={(Î¼1,Ïƒ1),(Î¼2,Ïƒ2)}\\begin{align*}\nF(x;\\theta) &= \\{\\mathcal{N}_1(\\mu_1, \\sigma_1), \\mathcal{N}_2(\\mu_2, \\sigma_2)\\} \\\\\n\\theta &= \\{(\\mu_1, \\sigma_1), (\\mu_2, \\sigma_2) \\}\n\\end{align*}\n\nPrediction is a weighted-average of experts\n\n\n\n\n\n\n\n\n\n\n\nThe gating network is a neural net ğ(x|Ïˆ)=[P1(x|Ïˆ),P2(x|Ïˆ)]\\mathbf{P}(x | \\psi) = [P_1(x | \\psi), P_2(x | \\psi) ]\n\nDivides the input space into partitions\n\n\n\n\n\nExpectation Maximization: maximizes log likelihood ln{P(ğ”»|Î¸,Ïˆ)}=âˆ‘j=1Nlnâˆ‘i=1NF12Ï€Ïƒi2exp(âˆ’12(yjâˆ’Î¼i)2Ïƒi2)Pi(xj,Ïˆ)\n\\ln \\{P(\\mathbb{D} | \\theta, \\psi) \\} = \\sum_{j=1}^{N} \\ln \\sum_{i=1}^{N_F} \\frac{1}{\\sqrt{2 \\pi \\sigma_i^2}} \\exp \\left( -\\frac{1}{2}\\frac{(y_j - \\mu_i)^2}{\\sigma_i^2} \\right) P_i(x_j, \\psi)"
  },
  {
    "objectID": "main.html#mixture-of-experts-controller-1",
    "href": "main.html#mixture-of-experts-controller-1",
    "title": "main",
    "section": "Mixture of Experts Controller",
    "text": "Mixture of Experts Controller\n\n\n\nObjective: learn contact-aware mixture of experts controller and a gating network\n\n\n\n\nAll the experts and the gating network are given by neural nets\nWe pose the search over the parameters Ïˆ,Î¸\\psi, \\theta as the following optimization problem\n\n\n\n\nOptimization Problem\n\n\nminimizeÏˆ,Î¸âˆ«0Tâ„“(x(t),u)â…†t,subject toM(q)â…†qÌ‡+h(x;Ïˆ,Î¸)â…†tâˆ’â…†R=0,u={Fi(x;Î¸i)|iâˆ¼Categorical(ğ(x|Ïˆ))}.\\begin{align*}\n    \\begin{aligned}\n        \\underset{\\psi, \\theta}{\\textrm{minimize}} \n        & & & \\int_0^T \\ell (x(t),u) \\dd t , \\\\%\n        \\textrm{subject to}\n        & & & M(q) \\dd \\dot{q} + h(x; \\psi, \\theta)\\dd t - \\dd R  = 0,\\\\%\n        & & & u = \\{F_i(x; \\theta_i) \\; | \\; i  \\sim \\text{Categorical} (\\mathbf{P}(x| \\psi)) \\}.\n    \\end{aligned}\n\\end{align*}"
  },
  {
    "objectID": "main.html#training",
    "href": "main.html#training",
    "title": "main",
    "section": "Training",
    "text": "Training\n\n\n\nTraining procedure:\n\nStart from initial parameters (Ïˆ,Î¸)(\\psi, \\theta)\nSample initial state x0x_0\nGenerate trajectories Ï•(x0,u,T)\\phi(x_0, u, T) using current parameters iâˆ¼Categorical(ğ(x|Ïˆ))u(x;Ïˆ,Î¸)=Fi(x;Î¸i)M(q)â…†qÌ‡+h(x;Ïˆ,Î¸)â…†tâˆ’â…†R=0 (Moreauâ€™s time stepping)\\begin{gather*}\ni  \\sim \\text{Categorical} (\\mathbf{P}(x| \\psi)) \\\\\nu(x; \\psi, \\theta) = F_i(x; \\theta_i) \\\\\nM(q) \\dd \\dot{q} + h(x; \\psi, \\theta) \\dd t - \\dd R  = 0 \\text{ (Moreau's time stepping)}\n\\end{gather*}\nAssign a running cost â„“\\ell to the trajectories based on performance\nUpdate parameters (Ïˆ,Î¸)(\\psi, \\theta) to minimize running cost"
  },
  {
    "objectID": "main.html#performance-objective",
    "href": "main.html#performance-objective",
    "title": "main",
    "section": "Performance Objective",
    "text": "Performance Objective\n\nminimizeÏˆ,Î¸âˆ«0Tâ„“(x(t),u)â…†t,subject toM(q)â…†qÌ‡+h(x;Ïˆ,Î¸)â…†tâˆ’â…†R=0,u={Fi(x;Î¸i)|iâˆ¼Categorical(ğ(x|Ïˆ))}.\\begin{align*}\n    \\begin{aligned}\n        \\underset{\\psi, \\theta}{\\textrm{minimize}} \n        & & & \\int_0^T \\ell (x(t),u) \\dd t , \\\\%\n        \\textrm{subject to}\n        & & & M(q) \\dd \\dot{q} + h(x; \\psi, \\theta)\\dd t - \\dd R  = 0,\\\\%\n        & & & u = \\{F_i(x; \\theta_i) \\; | \\; i  \\sim \\text{Categorical} (\\mathbf{P}(x| \\psi)) \\}.\n    \\end{aligned}\n\\end{align*}\n\n\nAccumulated loss: total quadratic loss from desired state x*x^* â„“(x,u)=12(xâˆ’x*)âŠ¤ğ’¬(xâˆ’x*)+12uâŠ¤â„›uğ’¬â‰»0,â„›â‰½0\\begin{gather*}\n\\ell(x, u) = \\frac{1}{2}(x - x^*)^\\top \\mathcal{Q} (x - x^*) + \\frac{1}{2} u^\\top \\mathcal{R} u \\\\\n\\mathcal{Q} \\succ 0, \\mathcal{R} \\succeq 0\n\\end{gather*}\n\n\n\nThe corresponding likelihood function is\n\n\n\nln{P(ğ”»|Î¸,Ïˆ)}=âˆ‘j=1Nlnâˆ‘i=1NF12Ï€Ïƒi2exp(âˆ’12(yjâˆ’Î¼i)2Ïƒi2)Pi(xj,Ïˆ)\n\\ln \\{P(\\mathbb{D} | \\theta, \\psi) \\} = \\sum_{j=1}^{N} \\ln \\sum_{i=1}^{N_F} \\frac{1}{\\sqrt{2 \\pi \\sigma_i^2}} \\exp \\left( -\\frac{1}{2}\\frac{(y_j - \\mu_i)^2}{\\sigma_i^2} \\right) P_i(x_j, \\psi)\n\n\n\nln{P(Ï•|Î¸,Ïˆ)}=âˆ‘t=0Tlnâˆ‘i=1NF12Ï€s2exp(âˆ’12â„“(x(t+Î”t),Fi)2s2)Pi(x(t),Ïˆ)\n\\ln \\{P(\\phi | \\theta, \\psi) \\} = \\sum_{t=0}^{T} \\ln \\sum_{i=1}^{N_F} \\frac{1}{\\sqrt{2 \\pi s^2}} \\exp \\left( -\\frac{1}{2}\\frac{\\ell (x(t+\\Delta t), F_i )^2}{s^2} \\right) P_i(x(t), \\psi)"
  },
  {
    "objectID": "main.html#state-sampling",
    "href": "main.html#state-sampling",
    "title": "main",
    "section": "State Sampling",
    "text": "State Sampling\nObjective: meet performance for various initial states"
  },
  {
    "objectID": "main.html#cartpole-with-wall-barriers",
    "href": "main.html#cartpole-with-wall-barriers",
    "title": "main",
    "section": "Cartpole with wall barriers",
    "text": "Cartpole with wall barriers\n\n\n\n\n\nNotice LQR fails due to the impact from the wall\nMOE controller training\n\nthere are three deep-net experts Fi(x;Î¸i)F_i(x;\\theta_i)\nthe gating network is also a neural net"
  },
  {
    "objectID": "main.html#results",
    "href": "main.html#results",
    "title": "main",
    "section": "Results",
    "text": "Results\n\nThe contact-aware MOE controller\n\nleverages the impacts from the wall\nswitches to a policy that rapidly brakes to assist in the catching process"
  },
  {
    "objectID": "main.html#conclusions",
    "href": "main.html#conclusions",
    "title": "main",
    "section": "Conclusions",
    "text": "Conclusions\n \n\n\nWe provide a data-driven control design that automatically learns several policies and the necessary switching scheme\nThe framework leverages the switching controllers to stabilize the multi-modal dynamical system\nThe gating network successsfully parameterizes the control-switching conditionals that achieves the desired performance"
  }
]