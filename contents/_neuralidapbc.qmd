# <span style="font-variant:small-caps;">NeuralIdaPbc</span> {visibility="uncounted"}
<!-- ###################################################################### -->

Solving matching PDEs with neural networks


## Motivation {auto-animate="true"}
<!-- ###################################################################### -->

<span style="font-variant:small-caps;">NeuralPbc</span> is flexible, but guaranteeing stability is hard

Additional structure of <span style="font-variant:small-caps;">IdaPbc</span> facilitates stability analysis


<!-- :::: {.r-stack} -->

<!-- ::: {.fragment .fade-out fragment-index=0} -->
$$ \begin{bmatrix} \dot{q} \\ \dot{p} \end{bmatrix} = \begin{bmatrix}0 & I \\ -I & 0\end{bmatrix} \begin{bmatrix} \nabla_q H \\ \nabla_p H  \end{bmatrix} + \begin{bmatrix} 0 \\ G \end{bmatrix} u $$
<!-- ::: -->

Closed-loop port-Hamiltonian dynamics:

<!-- ::: {.fragment .fade-in fragment-index=0} -->
$$
\begin{bmatrix} \dot{q} \\ \dot{p} \end{bmatrix}
=
\begin{bmatrix}0 & M^{-1}M_d \\ -M_dM^{-1} & J_2(q,p) - GK_vG^\top\end{bmatrix}
\begin{bmatrix} \nabla_q H_d \\ \nabla_p H_d \end{bmatrix}
$$
<!-- ::: -->
<!-- :::: -->

$H_d = \frac{1}{2} p^{\top} M_d(q)^{-1} p + V_d(q),\, M_d \succ 0$

::: {.notes}
- Further structure not only facilitates stability analysis but also restricts the search to a pd matrix $M_d$ and $V_d$.
- This search may be performed solely on the configuration space.
:::


## <span style="font-variant:small-caps;">IdaPbc</span> Background {auto-animate="true"}
<!-- ###################################################################### -->

$$ \begin{bmatrix} \dot{q} \\ \dot{p} \end{bmatrix} = \begin{bmatrix}0 & M^{-1}M_d \\ -M_dM^{-1} & J_2(q,p) - GK_vG^\top\end{bmatrix} \begin{bmatrix} \nabla_q H_d \\ \nabla_p H_d \end{bmatrix} $$

$H_d = \frac{1}{2} p^{\top} M_d(q)^{-1} p + V_d(q),\, M_d \succ 0$

:::: {layout-ncol="2"}

::: {.callout}
## Stability results

$$\begin{aligned}\dot{H}_d &= \left( \nabla_p H_d \right)^{\top} \left(-G K_v G^{\top}\right) \nabla_p H_d \\ &\leq -\lambda_{\textrm{min}} \{ K_v \} \left\| \left( \nabla_p H_d \right)^{\top} G \right\|^2 \leq 0 \end{aligned}$$

With $q^\star = \arg \min V_d(q)$, we have $x \to x^\star = (q^\star, 0)$
:::

::: {.fragment .fade-left}
::: {.callout}
## Control synthesis

Choose $u = u_{es} + u_{di}$ where
$$
\begin{aligned} 
Gu_{es} &= \nabla_{q} H - M_{d}M^{-1} \nabla_{q} H_{d} \\
&\quad\; + J_{2} M_{d}^{-1} p \phantom{\nabla_{p}^{\top}} \\
u_{di} &= -K_v G^\top \nabla_p H_d \phantom{\left\|\left(\nabla_p\right)^{\top} \right\|^2} 
\end{aligned}
$$
:::
:::

::::

## <span style="font-variant:small-caps;">IdaPbc</span> via Optimization {transition=slide-out}
<!-- ###################################################################### -->

:::: {layout="[-10, 100, -10]"}
::: {.callout}
$$
\begin{aligned}
\underset{M_d,\,J_2,\,V_d}{\text{minimize}} && 0 &  \\
\text{subject to} &&
0 &= G^{\bot}\left\{ \nabla_{q} H - M_{d}M^{-1} \nabla_{q} H_{d} + J_{2} M_{d}^{-1} p  \right\}
\\
&& H_d &= \frac{1}{2} p^{\top} M_d(q)^{-1} p + V_d(q)
\\
&& M_d &= M_d^\top \succ 0
\\
&& J_2 &= -J_2^\top
\\
&& q^\star &= \underset{q}{\arg \min} \, V_d(q)
\end{aligned}
$$
:::
::::

<center>*Infinite-dimensional*---closed-form solution is difficult</center>

## <span style="font-variant:small-caps;">NeuralIdaPbc</span> 
<!-- ###################################################################### -->

![](assets/nn-pbc-struct-frame-05.png){fig-align="center"}


## <span style="font-variant:small-caps;">NeuralIdaPbc</span> Problem Statement  {transition="fade-in zoom-out"}
<!-- ###################################################################### -->

:::: {layout="[-10, 100, -10]"}
::: {.callout}
$$
\begin{aligned}
\underset{\theta}{\text{minimize}} && J(\theta) &= \left\lVert G^{\bot} \left\{ \nabla_{q} H - M_{d}^{\theta}M^{-1} \nabla_{q} H_{d}^{\theta} + J_{2}^{\theta} \left(M_{d}^{\theta}\right)^{-1} p \right\} \right\rVert^2  \\
\text{subject to} 
&& H_d^{\theta} &= \frac{1}{2} p^{\top} \left( M_{d}^{\theta} \right)^{-1} p + V_{d}^{\theta}(q)
\\
&& M_d^{\theta}(q) &= \left(M_d^{\theta}(q)\right)^\top \succ 0
\\
&& J_{2}^{\theta}(q,p) &= -\left(J_{2}^{\theta}(q,p)\right)^\top
\\
&& q^\star &= \underset{q}{\arg \min} \, V_{d}^{\theta} (q)
\end{aligned}
$$
:::
::::

:::: {layout="[100,-5,90]"}
::: {.incremental}
* Finite-dimensional search
* Sample configuration space
:::
::: {.incremental}
* Controller $u$ is a continuous function of $J$
:::
::::


## <span style="font-variant:small-caps;">NeuralIdaPbc</span> Constraints
<!-- ###################################################################### -->


::: {.fragment .highlight-red fragment-index=0}
$$M_d^{\theta} = \left(M_d^{\theta}\right)^{\top} \succ 0$$
:::

::: {.fragment .semi-fade-out fragment-index=0}
$$J_{2}^{\theta} = -\left(J_{2}^{\theta}\right)^{\top}$$

$$q^\star = \underset{q}{\arg \min} \, V_{d}^{\theta} (q)$$
:::

::: {.fragment .fade-up fragment-index=0}
::: {.callout}
## Positive-definiteness of the desired mass matrix

* Cholesky decomposition $M_d^\theta(q) = L_{\theta}(q) L_{\theta}^{\top}(q)$
* Components of the lower-triangular matrix $L_\theta(q)$ are outputs of a neural network
:::
:::



## <span style="font-variant:small-caps;">NeuralIdaPbc</span> Constraints {visibility="uncounted"}
<!-- ###################################################################### -->

::: {.fragment .semi-fade-out fragment-index=0}
$$M_d^{\theta} = \left(M_d^{\theta}\right)^{\top} \succ 0$$
:::

::: {.fragment .highlight-red fragment-index=0}
$$J_{2}^{\theta} = -\left(J_{2}^{\theta}\right)^{\top}$$
:::

::: {.fragment .semi-fade-out fragment-index=0}
$$q^\star = \underset{q}{\arg \min} \, V_{d}^{\theta} (q)$$
:::

::: {.fragment .fade-up fragment-index=0}
::: {.callout}
## Skew symmetry of $J_2^\theta(q,p)$

* Decompose a square matrix into symmetric and skew-symmetric parts 
$$J_2^\theta(q,p) = A_{\theta}(q,p) -  A_{\theta}^{\top}(q,p)$$

* Components of the square matrix $A_\theta(q,p)$ are output of a neural network
:::
:::


## <span style="font-variant:small-caps;">NeuralIdaPbc</span> Constraints {visibility="uncounted"}
<!-- ###################################################################### -->

::: {.fragment .semi-fade-out fragment-index=0}
$$M_d^{\theta} = \left(M_d^{\theta}\right)^{\top} \succ 0$$
$$J_{2}^{\theta} = -\left(J_{2}^{\theta}\right)^{\top}$$
:::

::: {.fragment .highlight-red fragment-index=0}
$$q^\star = \underset{q}{\arg \min} \, V_{d}^{\theta} (q)$$
:::

::: {.fragment .fade-up fragment-index=0}
::: {.callout}
## Boundedness of $V_d^\theta$

* $V_d^\theta(q)$ bounded from below with isolated minimum at $q^\star$
<!-- * If $V_d$ is convex, only need first order condition $\nabla V_d^\theta(q^\star) = 0$ -->
* Parameterize $V_d^\theta$ by a *sums-of-square (SoS) polynomial*
* $V_d^\theta(q) > 0,\, q \neq q^\star$ 
:::
:::

## <span style="font-variant:small-caps;">SoS</span> Decomposition
<!-- ###################################################################### -->

::: {.callout-tip icon="false"}
## Theorem (Choi, 1995)

A polynomial $P \in \mathbb{R}[x]$ of degree $2d$ has a SoS decomposition  $\Leftrightarrow$ $\exists Q \succ 0$ such that, with $\mu(x) = \begin{bmatrix} 1 & x_1 & \cdots & x_n & x_1 x_2 & \cdots & x_n^d\end{bmatrix}$, we have $P(x) = \mu(x)^\top Q \mu(x)$

<!-- $$P(x) = \mu^\top(x) Q \mu(x)$$ -->
:::

::: {.callout-note icon="false"}

## Example
$$\begin{aligned} x_1^2 + 2x_1^2x_2 + 5x_1^2x_2^2 + 4x_1x_2^2 + x_2^2  &= \mu(x)^{\top} \begin{pmatrix} 1 & 1 & 0 \\ 1 & 5 & 2 \\ 0 & 2 & 1 \end{pmatrix} \mu(x) \\ &= \mu(x)^{\top} \begin{pmatrix} 1 & 0 & 0 \\ 1 & 2 & 0 \\ 0 & 1 & 0 \end{pmatrix} \begin{pmatrix}   1 & 0 & 0 \\ 1 & 2 & 0 \\ 0 & 1 & 0 \end{pmatrix}^{\top} \mu(x) \end{aligned} $$

:::

##
<!-- ###################################################################### -->

<br/>

:::: {.r-stack}

![](assets/nn-pbc-struct-frame-00.png){.fragment .fade-out fragment-index=0}

![](assets/nn-pbc-struct-frame-01.png){.fragment .fade-in-then-out fragment-index=0}

![](assets/nn-pbc-struct-frame-02.png){.fragment .fade-in-then-out fragment-index=1}

![](assets/nn-pbc-struct-frame-03.png){.fragment .fade-in-then-out fragment-index=2}

![](assets/nn-pbc-struct-frame-04.png){.fragment .fade-in-then-out fragment-index=3}

![](assets/nn-pbc-struct-frame-05.png){.fragment .fade-in-then-out fragment-index=4}


::::

## <span style="font-variant:small-caps;">NeuralIdaPbc</span> Experiments
<!-- ###################################################################### -->
Followed the experiments performed in <span style="font-variant:small-caps;">IdaPbc</span> paper[^idapbc]

[^idapbc]: R. Ortega, M. W. Spong, F. Gómez-Estern, and G. Blankenstein, “Stabilization
of a class of underactuated mechanical systems via interconnection and damping assignment,” IEEE transactions on automatic control, vol. 47, no. 8, pp.
1218–1233, 2002.

* Inertia-wheel pendulum (IWP)
* Ball-beam system

## {background-video="contents/assets/iwp-firefox.mp4" background-size="contain" background-video-loop="true" background-video-muted="true"}
<!-- ###################################################################### -->


## Simulated IWP experiments
<!-- ###################################################################### -->

:::: {.r-stack}
![](assets/idapbc-iwp-evolution.png){.fragment .fade-out fragment-index=0}

![](assets/idapbc-contours.png){.fragment .fade-in-then-out fragment-index=0}

<!-- ![](assets/compare_uru.png){.fragment .fade-in fragment-index=1} -->

::: {.fragment .fade-in fragment-index=1}

<center>Comparison of control effort expenditure</center>

<span style="font-variant:small-caps;">NeuralPbc</span> | <span style="font-variant:small-caps;">NeuralIdaPbc</span> | <span style="font-variant:small-caps;">IdaPbc</span>
:---:|:---:|:---:
![](assets/compare_uRu_neuralpbc.svg) | ![](assets/compare_uRu_neuralidapbc.svg){width=90%} | ![](assets/compare_uRu_idapbc.svg){width=93%}
:::

::::


## Deterministic vs. Bayesian Training {.smaller}
<!-- ###################################################################### -->

:::: {.columns}

::: {.column width="60%"}

::: {.fragment}
Performance metric: $\mathcal{J} = \int_0^T \left( \frac{1}{2}qx(t)^2 + \frac{1}{2}ru(t)^2  \right)dt$.
:::

&nbsp;

::: {.fragment}
Simulated dynamics  

$$
\begin{aligned}
dx &= \begin{bmatrix}
\dot{q}_1 \\ \dot{q_2} \\ \frac{1}{I_1}\left(m g l \sin{q_1} - u^\theta -
b_1\dot{q}_1\right) \\ \frac{1}{I_2}\left(u^\theta -b_2 \dot{q}_2 \right)
\end{bmatrix} dt \\
&+ \nabla_xu^\theta(x) \sigma dW_t.
\end{aligned}
$$
:::

:::

::: {.column width="40%"}

![](assets/iwp.svg){width=50%}

![](assets/bandplot.svg){width=90%}


:::

::::


## {background-video="contents/assets/iwp-cut-firefox.mp4" background-size="contain" background-video-loop="true" background-video-muted="true"}
<!-- ###################################################################### -->


## Deterministic vs. Bayesian Training
<!-- ###################################################################### -->

:::: {.columns}

::: {.column width="50%"}



:::

::: {.column width="50%" layout-valign="center"}

![](assets/four-rings.jpg){width=80%}

![](assets/idapbc_bar.svg){width=90%}


:::

::::


## Ball-beam experiments
<!-- ###################################################################### -->

::: {.r-stack}
![](assets/ball-beam.svg){.fragment .fade-out fragment-index=0}

::: {.fragment .fade-in fragment-index=0}
::: {layout="[100,85]" layout-valign="center"}
![](assets/ball_beam-Vd-contour.svg)

![](assets/ball_beam-evolution.svg)
:::
:::
:::
