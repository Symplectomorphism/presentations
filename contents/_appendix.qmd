# Appendix {visibility="uncounted"}

## Theoretical Justification {visibility="uncounted"}
Why does Bayesian Learning result in more robust controllers?

## System Parameter Uncertainty {auto-animate="true" visibility="uncounted"}
<!-- ###################################################################### -->

::: {.fragment data-fragment-index=0}
* Scalar control system 
* Uncertain drift vector field: $p \sim
\mathcal{N}(\hat{p}, \sigma_p^2)$.
* No measurement uncertainty
:::

::: {data-id="system" .fragment data-fragment-index=1}

::: {layout="[100,-5,60]" layout-valign="center"}
$$
\Sigma: \quad
\begin{cases}
  \dot{x} &= px + u, \\
  u(x) &= \theta x, \\
  x(0) &= 1.
\end{cases}
$$
$$
  x(t) = e^{(p+\theta)t}.
$$
:::
:::



## Performance Index {auto-animate="true" visibility="uncounted"}
<!-- ###################################################################### -->


::: {data-id="system"}

::: {layout="[100,-5,60]" layout-valign="center"}
$$
\Sigma: \quad
\begin{cases}
  \dot{x} &= px + u, \\
  u(x) &= \theta x, \\
  x(0) &= 1.
\end{cases}
$$
$$
  x(t) = e^{(p+\theta)t}.
$$
:::
:::

::: {.fragment data-fragment-index=0}

Quadratic performance index

- $q \geq 0$, $r > 0$  
- $T$: control horizon
:::

::: {.fragment data-fragment-index=0, data-id="perf"}
$$
\mathcal{J} = \int_0^T \left( \frac{1}{2}qx(t)^2 + \frac{1}{2}ru(t)^2  \right)dt.
$$
:::


## Infinite-Horizon Best Performance {auto-animate="true" visibility=uncounted}
<!-- ###################################################################### -->

::: {layout="[100,-5,60]" layout-valign="center" .fragment data-fragment-index=0 data-id="perf"}
$$
\mathcal{J} = \int_0^T \left( \frac{1}{2}qx(t)^2 + \frac{1}{2}ru(t)^2  \right)dt.
$$
$$
\mathcal{J}_{T \to \infty} = -\frac{1}{4}\frac{q+r \theta^2}{p+\theta}.
$$
:::

::: {.fragment data-fragment-index=1}

Solve for $\theta$ that minimizes $\mathcal{J}_\infty$: $\theta^\star = g(p) :=
-p -\sqrt{p^2+\frac{q}{r}}$.

:::

::: {layout="[100,-5,60]" layout-valign="center" .fragment data-fragment-index=2 data-id="opt-sol"}

::: {.callout-note icon=false}
## Deterministic

$\theta^\star = g(\hat{p}) := -\hat{p} -\sqrt{\hat{p}^2+\frac{q}{r}}$

:::

::: {.callout-note icon=false}
## Probabilistic

$$
\begin{aligned}
f_{\theta^\star}(\theta^\star) &= \frac{1}{\sigma_p \sqrt{2\pi}}\left( \
\frac{1}{2}\left(1+\frac{q}{r{\theta^\star}^2}\right) \right) \\
&\exp{\left\{ -\frac{1}{2\sigma_p^2}\left( \frac{q}{2r\theta^\star} -
\frac{\theta^\star}{2} - \hat{p}  \right)^2  \right\} }
\end{aligned}
$$

:::

:::


## Infinite-Horizon Best Performance {auto-animate="true" visibility="uncounted"}
<!-- ###################################################################### -->


:::: {layout="[100,-5,60]" layout-valign="center" .fragment data-fragment-index=0 data-id="opt-sol"}

::: {.callout-note icon=false}
## Deterministic
$\theta^\star = g(\hat{p}) := -\hat{p} -\sqrt{\hat{p}^2+\frac{q}{r}}$
:::

::: {.callout-note icon=false}
## Probabilistic
$$
\begin{aligned}
f_{\theta^\star}(\theta^\star) &= \frac{1}{\sigma_p \sqrt{2\pi}}\left( \
\frac{1}{2}\left(1+\frac{q}{r{\theta^\star}^2}\right) \right) \\
&\exp{\left\{ -\frac{1}{2\sigma_p^2}\left( \frac{q}{2r\theta^\star} -
\frac{\theta^\star}{2} - \hat{p}  \right)^2  \right\} }
\end{aligned}
$$
:::
::::

::: {.r-stack}
![](contents/assets/optimal-dist_1.svg){.fragment data-fragment-index=1}

![](contents/assets/optimal-dist_2.svg){.fragment data-fragment-index=2}

![](contents/assets/optimal-dist_3.svg){.fragment data-fragment-index=3}
:::

---

### Parameter Uncertainty and Measurement Noise {auto-animate="true" visibility="uncounted"}
<!-- ###################################################################### -->

::: {.fragment data-fragment-index=0}
Same control system with measurement noise: $x \sim \mathcal{N}(x, \sigma^2)$.
:::

::: {data-id="stoc-system" .fragment data-fragment-index=1}

::: {layout-valign="center"}
$$
\Sigma: \quad
\begin{cases}
  dx(t) &= (p+\theta)x(t) dt + \theta \sigma dW_t, \\
  x(0) &= 1.
\end{cases}
$$
:::
::: {layout-valign="center"}
$$
x(t) = e^{(p+\theta)t} + \theta \sigma \int_0^t e^{(p+\theta)(t-s)}dW_s.
$$
:::
:::

::: {.fragment data-fragment-index=2 data-id="lemma"}
::: {.callout-tip icon=false}
## Lemma

The conditional expectation $\mathbb{E}[\mathcal{J} \mid p]$ of the performance
index given the system parameter $p$ is

$$
\mathbb{E}[\mathcal{J} \mid p] =
-\frac{1}{4}\frac{q+r\theta^2}{p+\theta}\left[ \theta^2 \sigma^2 T +
\left(1-e^{2 T (p+\theta)}\right) \left(1+\frac{1}{2}\frac{\theta^2
\sigma^2}{p+\theta}\right) \right]
$$
:::
:::


## Conditional Expectation {auto-animate="true" visibility="uncounted" .smaller }
<!-- ###################################################################### -->

::: {.fragment data-fragment-index=2 data-id="lemma"}
$$
\mathbb{E}[\mathcal{J} \mid p] =
-\frac{1}{4}\frac{q+r\theta^2}{p+\theta}\left[ \theta^2 \sigma^2 T +
\left(1-e^{2 T (p+\theta)}\right) \left(1+\frac{1}{2}\frac{\theta^2
\sigma^2}{p+\theta}\right) \right]
$$
:::

::: {.fragment data-fragment-index=3 data-id="proof"}
::: {.callout-warning icon=false}
## Proof

Substituting the solution of the SDE into the performance measure yields

$$
\begin{aligned} \mathcal{J} =
        & -\frac{1}{4}\frac{q+r\theta^2}{p+\theta}\left(1 +
        e^{2T(p+\theta)}\right) + 
        (q+r\theta^2)\theta\sigma \int_0^T
        e^{(p+\theta)t} \int_0^t e^{(p+\theta)(t-s)}dW_s
        dt \; + \\ &\frac{1}{2}(q+r\theta^2)\theta^2
        \sigma^2 \int_0^T \left( \int_0^t
        e^{(p+\theta)(t-s)} dW_s  \right)^2 dt 
\end{aligned}
$$

The conditional expectation of this quantity given the system parameter $p$
under the distribution induced by the Wiener process may be computed in
closed-form using Ito calculus.

$$
\begin{aligned} 
\mathbb{E}_W\left[\mathcal{J} \mid p \right] &= -\frac{1}{4}\frac{q+r\theta^2}{p+\theta}\left(1 - e^{2T(p+\theta)}\right) +
        (q+r\theta^2)\theta\sigma\int_0^Te^{(p+\theta)t}\mathbb{E}_W\left[\int_0^t
        e^{(p+\theta)(t-s)} dW_s~\Big\rvert p\right] dt + \\
        &\frac{1}{2}(q+r\theta)^2\theta^2\sigma^2\int_0^T\mathbb{E}_W\left[\left(\int_0^t
        e^{(p+\theta)(t-s)} dW_s \right)^2~\bigg\rvert p\right] dt \\
        &=-\frac{1}{4}\frac{q+r\theta^2}{p+\theta}\left(1 -
        e^{2T(p+\theta)}\right) + 
        \frac{1}{2}(q+r\theta^2)\theta^2\sigma^2\int_0^T\left(\int_0^t
        e^{2(p+\theta)(t-s)} ds \right) dt \\ 
        &=-\frac{1}{4}\frac{q+r\theta^2}{p+\theta}\left(1 - e^{2T(p+\theta)}\right) + 
        \frac{1}{2}(q+r\theta^2)\theta^2\sigma^2\int_0^T
        -\frac{1}{2(p+\theta)}\left(1 - e^{2T(p+\theta)}\right) dt \\ 
        &=-\frac{1}{4}\frac{q+r\theta^2}{p+\theta} \left[ \theta^2 \sigma^2 T +
        \left(1 - e^{2T(p+\theta)}\right) \left(1 +
        \frac{1}{2}\frac{\theta^2\sigma^2}{p+\theta}\right)\right]. 
\end{aligned}
$$

<div style="text-align: right"> :orange_square: </div>

:::
:::


## Optimal Controller {auto-animate="true" auto-animate-easing="ease-in-out" visibility="uncounted"}
<!-- ###################################################################### -->


::: {.r-stack layout-valign="center"}
![](contents/assets/optimal_ctrl.svg){width="80%" .fragment data-fragment-index=0 data-id="opt-ctrl"}

<div style="vertical-align: bottom" class="fragment" data-fragment-index="0">Optimal controller $|\theta^\star|$ minimizing $\mathbb{E}\mathcal{J}$</div>

![](contents/assets/optimal_cost.svg){width="80%" .fragment data-fragment-index=1 data-id="opt-cost"}

<div style="vertical-align: bottom" class="fragment" data-fragment-index="1">Minimal expected cost $\mathbb{E}\mathcal{J}$</div>

:::


## Optimal Controller {auto-animate="true" auto-animate-easing="ease-in-out" visibility="uncounted"}
<!-- ###################################################################### -->


::: r-hstack
![Optimal controller $|\theta^\star|$ minimizing $\mathbb{E}\mathcal{J}$](contents/assets/optimal_ctrl.svg){.fragment data-fragment-index=0 data-id="opt-ctrl"}

![Minimal expected cost $\mathbb{E}\mathcal{J}$](contents/assets/optimal_cost.svg){.fragment data-fragment-index=0 data-id="opt-cost"}
:::

::: {.incremental .fragment data-fragment-index=1}
* Optimal control parameter a nontrivial function of $\sigma$ and $\sigma_p$.
* Bayesian learning strikes the right trade-off.
:::



<!-- Appendix from earlier -->




## <span style="font-variant:small-caps;">NeuralPbc</span> Publications {visibility="uncounted"}
<!-- ###################################################################### -->

This work is published in ISER 2020[^iser], CCTA 2021[^ccta]

[^iser]: W. Sirichotiyakul and A. C. Satici, “Data-driven design of energy-shaping controllers for swing-up control of underactuated robots,” in International Symposium on Experimental Robotics. Springer, 2020, pp. 323-333.

[^ccta]: W. Sirichotiyakul and A. C. Satici, “Combining energy-shaping control of dynamical systems with data-driven approaches,” in 2021 IEEE Conference on Control Technology and Applications (CCTA). IEEE, 2021, pp. 1121-1127. 

## <span style="font-variant:small-caps;">NeuralPbc</span> Publications {visibility="uncounted"}
<!-- ###################################################################### -->

This work also provides a foundation for an ongoing research that investigate the improvement of robustness properties of <span style="font-variant:small-caps;">NeuralPbc</span>[^acc]<sup>,</sup>[^css]

[^acc]: W. Sirichotiyakul, N. A. Ashenafi, and A. C. Satici, “Robust Data-Driven Passivity-Based Control of Underactuated Systems via Neural Approximators and Bayesian Inference,” in 2022 American Control Conference, ACC. IEEE, Accepted for publication January 2022.

[^css]: N. A. Ashenafi, W. Sirichotiyakul, and A. C. Satici, “Robust Passivity-Based Control of Underactuated Systems via Neural Approximators and Bayesian In ference,” in 2022 Conference on Decision and Control, CDC. IEEE. (Submitted for review March 2022).


## <span style="font-variant:small-caps;">NeuralIdaPbc</span> Publications {visibility="uncounted"}
<!-- ###################################################################### -->

This work is published in the International Journal of Control[^ijc]

[^ijc]: W. Sirichotiyakul and A. C. Satici, “Data-Driven Passivity-Based Control of Underactuated Mechanical Systems via Interconnection and Damping Assignment,” in International Journal of Control. (Accepted for publication March 2022)

\ 

<span style="font-variant:small-caps;">NeuralIdaPbc</span> is the basis for an ongoing research that investigate the improvement of robustness properties[^tacon]

[^tacon]: W. Sirichotiyakul, N. A. Ashenafi, and A. C. Satici, “Robust Interconnection and Damping Assignment Passivity-Based Control via Neural Bayesian Inference,” in IEEE Transactions on Automatic Control. (Submitted for review April 2022)


## `DiffEqFlux.jl` Demo {visibility="uncounted"}
<!-- ###################################################################### -->

Learning $\dot{x} = f(x)$ where $f$ is a neural network

Regress on MSE between trajectory of $f$ and data

:::: {.r-stack}
![](contents/assets/diffeqflux_1.png){.fragment .fade-out fragment-index=0}

![](contents/assets/diffeqflux_2.gif){.fragment .fade-in fragment-index=0}
::::


## <span style="font-variant:small-caps;">NeuralIdaPbc</span> Main Problem {.smaller visibility="uncounted"}
<!-- ###################################################################### -->

$$\begin{aligned} \underset{\theta}{\text{minimize}} && J(\theta) &= \left\lVert G^{\bot} \left\{ \nabla_{q} H - M_{d}^{\theta}M^{-1} \nabla_{q} H_{d}^{\theta} + J_{2}^{\theta} \left(M_{d}^{\theta}\right)^{-1} p \right\} \right\rVert^2  \\ \text{subject to}  && H_d^{\theta} &= \frac{1}{2} p^{\top} \left( M_{d}^{\theta} \right)^{-1} p + V_{d}^{\theta}(q) \\ && M_d^{\theta}(q) &= \left(M_d^{\theta}(q)\right)^\top \succ 0 \\ && J_{2}^{\theta}(q,p) &= -\left(J_{2}^{\theta}(q,p)\right)^\top \\ && q^\star &= \underset{q}{\arg \min} \, V_{d}^{\theta} (q) \end{aligned}$$

::::: {.fragment}
:::: {.columns}

::: {.column width=49%}

::: {.callout-tip icon="false"}
## <span style="font-variant:small-caps;">NeuralIdaPbc</span>

- Solve nonlinear PDEs using neural networks and SoS polynomials
- Surrogates of $M_d$, $J_2$, $V_d$ are constrained *by construction*

:::

:::

::: {.column width=2%} 

:::

::: {.column width=49%}
::: {.callout-tip icon="false"}
## <span style="font-variant:small-caps;">Pinn</span>

- Solve nonlinear PDEs using neural networks
- Solution surrogates are constrained via penalty term in loss function


:::
:::

::::
:::::


## <span style="font-variant:small-caps;">SoS</span> Polynomials {visibility="uncounted"}
<!-- ###################################################################### -->

Is $p(x)$ nonnegative for all $x$?
$$p(x) = 4x_1^2 + x_1x_2 - 4x_2^2 - 2.1x_1^4 + 4x_2^4 + \frac{1}{3}x_1^6 + 1.0316\;$$

::: {.fragment}
$$\begin{aligned} p(x) = &\left(0.116x_1^2 + 0.01x_1x_2 - 2x_2^2 + 1.015\right)^2 \\ & + \; \left(-0.569x_1^3 + 1.938x_1 + 0.244x_2\right)^2 \\ & + \; \left(0.224x_1^2 + 0.666x_1x_2 + 0.029x_2^2 + 0.026\right)^2 \\ & + \; \left(-0.188x_1^2 + 0.063x_1x_2 - 0.006x_2^2 + 0.009\right)^2 \\ & + \; \left(0.099x_1^3 + 0.029x_1 + 0.004x_2\right)^2 + \left(0.009x_1^2x_2\right)^2 \end{aligned}$$
::: 
